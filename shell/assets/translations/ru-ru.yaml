##############################
# Special stuff
##############################
generic:
  add: Добавить
  all: Все
  and: ' и '
  back: Назад
  cancel: Отменить
  clear: Очистить
  clearAll: Очистить Все
  close: Закрыть
  comingSoon: Скоро
  comma: ', '
  copy: Скопировать
  create: Создать
  created: Создано
  customize: Настроить
  dashboard: Дашборд
  default: По умолчанию
  disabled: Отключено
  done: Готово
  enabled: Включено
  id: ID
  ignored: Игнорируется
  invalidCron: Некорректное расписание cron
  imagePullPolicy:
    always: Всегда
    ifNotPresent: Если отсутствует
    never: Никогда
  labels: Лэйблы
  labelsAndAnnotations: Лэйблы и Примечания
  links: Ссылки
  loading: Загрузка&hellip;
  members: Пользователи
  na: н/д
  name: Имя
  never: Никогда
  none: Ничего
  notFound: Не найдено
  number: '{prefix}{value, number}{suffix}'
  notification:
    title:
      succeed: Успешно
      info: Информация
      warning: Предупреждение
      error: Ошибка
  ok: OK
  overview: Обзор
  plusMore: "+ еще {n}"
  readFromFile: Читать из файла
  readFromFolder: Читать из папки
  reload: Перезагрузить
  register: Регистрация
  remove: Удалить
  addCatalog: Добавить каталог
  resource: |-
    {count, plural,
    one {ресурс}
    other {ресурсов}
    }
  resourceCount: |-
    {count, plural,
    one  {1 ресурс}
    other {# ресурсов}
    }
  save: Сохранить
  showAdvanced: Показать расширенные
  hideAdvanced: Скрыть расширенные
  techPreview: Превью
  type: Тип
  unknown: Неизвестный
  provisioning: '—'
  key: Ключ
  value: Значение
  yes: Да
  no: Нет
  units:
    time:
      5s: 5с
      10s: 10с
      30s: 30с
      1m: 1м
      5m: 5м
      15m: 15м
      30m: 30м
      1h: 1ч
      2h: 2ч
      6h: 6ч
      1d: 1д
      7d: 7д
      30d: 30д
  completed: Завершено
  enable: Включить
  disable: Выключить
  experimental: Экспериментальный

  deprecated: Устаревший
  placeholder: "пример {text}"
  moreInfo: Больше информации
  selectors:
    label: Список
    matchingResources:
      matchesSome: |-
        {matched, plural,
          =0 {Совпадений 0 из {total, number}}
          =1 {Совпадений 1 из {total, number}: "{sample}"}
          other {Совпадений {matched, number} из {total, number}, включая "{sample}"}
        }

locale:
  en-us: English
  zh-hans: 简体中文
  ru-ru: Русский
  none: (None)

nav:
  backToRancher: Управление кластером
  clusterTools: Инструменты кластера
  kubeconfig:
    download: Скачать KubeConfig
    copy: Скопировать KubeConfig в буфер обмена
    options: Настройки KubeConfig
  import: Импортировать YAML
  home: Главная
  shell: Консоль Kubectl
  shellShortcut: Консоль Kubectl {key}
  support: |-
    {hasSupport, select,
      true {Поддержка}
      other {Получить поддержку}
    }
  restoreSnapshot: Восстановить из снапшота
  rotateCertificates: Обновить сертификаты
  rotateEncryptionKeys: Обновить ключи шифрования
  saveAsRKETemplate: Сохранить как шаблон RKE
  takeSnapshot: Сделать снэпшот
  group:
    cluster: Кластер
    inUse: Дополнительные ресурсы
    policy: Политики
    rbac: RBAC
    serviceDiscovery: Обзор сервиса
    starred: Избранное
    storage: Хранилище
    workload: Рабочие процессы
    monitoring: Мониторинг
    advanced: Продвинутые
    RKE1Configuration: Конфигурация RKE1
    admission: Допуски
    apps: Приложения
    clusterProvisioning: Управление кластером
    core: Основное
    legacy: Легаси
    API: API
    Coordination: Координация
    Discovery: Обнаружение
    Fleet: Fleet
    K3s: K3s
    Networking: Сеть
    Rancher: Rancher
    RBAC: RBAC
    Scheduling: Планирование
    Storage: Хранилище
  ns:
    all: Все пространства имен
    clusterLevel: Только ресурсы кластера
    namespace: "{name}"
    namespaced: Только ресурсы пространства имен
    orphan: Не в проекте
    project: "Проект: {name}"
    system: Только системные пространства имен
    user: Только пользовательские пространства имен
  apps: Приложения
  categories:
    explore: Обзор кластера
    multiCluster: Глобальные приложения
    legacy: Устаревшие приложения
    configuration: Конфигурация
  search:
    placeholder: Начните писать для поиска кластера
    noResults: Не найдено кластеров
  resourceSearch:
    label: Поиск ресурсов
    toolTip: Поиск ресурсов {key}
    placeholder: Начните писать для поиска ресурса...
  header:
    setLoginPage: Установить как страницу входа
    restoreCards: Восстановить скрытые карточки
  userMenu:
    preferences: Настройки
    accountAndKeys: Аккаунт и API ключи
    logOut: Выйти
  failWhale:
    reload: Перезагрузить
    separator: или

product:
  apps: Приложения
  auth: Пользователи и аутентификация
  backup: Резервные копии Rancher
  cis: CIS Бенчмарк
  ecm: Управление кластером
  explorer: Обзор кластера
  fleet: Беспрерывная доставка
  longhorn: Longhorn
  manager: Управление кластером
  gatekeeper: OPA Gatekeeper
  istio: Istio
  logging: Логирование
  settings: Глобальные настройки
  clusterManagement: Управление кластером
  monitoring: Мониторинг
  mcapps: Глобальные настройки
  neuvector: NeuVector
  harvesterManager: Управление виртуализацией
  rancher: Rancher
  legacy: Legacy
  uiplugins: Расширения
  elemental: Управление ОС
  plugins: Plugins

suffix:
  percent: "%"
  milliCpus: несколько CPU
  cores: Ядра
  cpus: CPU
  gpus: GPU
  ib: Б
  mib: МБ
  gb: ГБ
  revisions: |-
    {count, plural,
      =1 { Ревизия }
      other { Ревизии }
    }
  seconds: |-
    {count, plural,
      =1 { Секунда }
      other { Секунд }
    }
  sec: Сек
  times: |-
    {count, plural,
      =1 { Раз }
      other { Раза }
    }

##############################
# Components & Pages
##############################
about:
  title: Информация
  versions:
    title: Версии
    component: Компонент
    version: Версия
    cli: CLI
    helm: Helm
    machine: Машина
    rancher: Rancher
    releaseNotes: 'Смотреть заметки к релизу'
  os:
    mac: macOS
    windows: Windows
    linux: Linux
  downloadImageList:
    title: Списки образов
  downloadCLI:
    title: CLI Загрузки
  diagnostic:
    title: Диагностика
    checkboxTooltip: Дополните диагностические данные временем отклика для 10 основных ресурсов. Это может занять некоторое время
    checkboxLabel: Выполнить дополнительные запросы
    systemInformation:
      subtitle: Системная информация
      browser: Браузер
      browserInfo: "User Agent: {userAgent}, Язык: {language}, Cookies включены: {cookieEnabled}"
      system: Система
      jsMemory: Javascript Память
      deviceMemory: "Память устройства: {deviceMemory}"
      hardwareConcurrency: "Аппаратный параллелизм: {hardwareConcurrency}"
      os: "ОС: {platform}"
      memJsHeapLimit: "Лимит Heap: {jsHeapSizeLimit}"
      memTotalJsHeapSize: "Итоговый размер Heap: {totalJSHeapSize}"
      memUsedJsHeapSize: "Используемый размер Heap: {usedJSHeapSize}"
    logs:
      subtitle: Последние логи
    resourceCounts: |-
      {count, plural,
        one { Счетчики ресурсов по кластерам ({count} кластер)}
        other { Счетчики ресурсов по кластерам ({count} кластеры)}
      }
    modal:
      title: Время запросов еще не сгенерировано.
      body: Сгенерируйте время запросов для более детальной информации.

accountAndKeys:
  title: Аккаунт и API ключи
  account:
    title: Аккаунт
    change: Изменить пароль
  apiKeys:
    title: API ключи
    notAllowed: У вас нет прав для управления API ключами
    apiEndpoint: "API endpoint:"
    add:
      description:
        label: Описание
        placeholder: Введите дополнительное описание, которое поможет вам отличать этот ключ API.
      label: Создать API ключ
      expiry:
        label: Автоматическое истечение
        options:
          never: Никогда
          day: Один день от текущего момента
          month: Один месяц от текущего момента
          year: Один год от текущего момента
          custom: Свой вариант
          maximum: "{value} - Максимально допустимое значение"
      customExpiry:
        options:
          minute: Минут
          hour: Часов
          day: Дней
          month: Месяцев
          year: Лет
        scope: Области
        noScope: Без областей
      info:
        accessKey: Ключ доступа
        secretKey: Секретный ключ
        bearerToken: Bearer токен
        saveWarning: Сохраните ключи выше! Это единственный раз, когда вы сможете их увидеть. Если вы его потеряете, вам нужно будет создать новый ключ API.
        keyCreated: Новый API ключ был создан
        bearerTokenTip: "Ключ доступа и секретный ключ могут быть отправлены в качестве имени пользователя и пароля для базовой аутентификации HTTP для авторизации запросов. Вы также можете объединить их для использования в качестве Bearer токена:"
        ttlLimitedWarning: Срок действия этого ключа API был сокращен из-за конфигурации системы.

addClusterMemberDialog:
  title: Добавить пользователя в кластер

addonConfigConfirmation:
  title: Сброс конфигурации аддонов
  body: Изменение версии Kubernetes может привести к сбросу значений конфигурации надстройки. Вы должны убедиться, что значения соответствуют ожидаемым, прежде чем продолжить.

addProjectMemberDialog:
  title: Добавить пользователя в проект

authConfig:
  accessMode:
    label: 'Настройте, кто может иметь возможность входить в систему и использовать {vendor}'
    required: Ограничить доступ только авторизованным пользователям и группам
    restricted: 'Разрешить участникам кластеров и проектов, а также авторизованным пользователям и группам'
    unrestricted: Разрешить любому пользователю
  allowedPrincipalIds:
    title: Авторизованные пользователи и группы
  associatedWarning: 'Примечание. Пользователь {provider}, под которым вы аутентифицируетесь, будет использован как альтернативный способ входа в систему с пользователем {vendor}, под которым вы в настоящее время вошли как <code>{username}</code>; все привязки глобальных разрешений, проектов и ролей кластера этого пользователя {vendor} также будут применяться к пользователю {provider}.'
  github:
    clientId:
      label: ID Клиента
    clientSecret:
      label: Секретный ключ клиента
    form:
      app:
        label: Наименование приложения
        value: 'Все, что вам хочется, к примеру. Мой {vendor}'
      callback:
        label: callback URL для авторизации
      description:
        label: Описание приложения
        value: 'Не обязательно, можно оставить пустым'
      homepage:
        label: URL домашней страницы
      instruction: 'Заполните форму этими значениями:'
      prefix:
        1: <li><a href="{baseUrl}/settings/developers" target="_blank" rel="noopener noreferrer nofollow">Кликните сюда</a> перейти к настройкам приложения GitHub в новом окне.</li>
        2: <li>Кликните на вкладку "OAuth Apps".</li>
        3: <li>Кликните на кнопку "New OAuth App".</li>
      suffix:
        1: <li>Кликните "Register application"</li>
        2: <li>Скопируйте и вставьте ID клиента и секретный ключ клиента только что созданного приложения OAuth в поля ниже.</li>
    host:
      label: GitHub Enterprise хост
      placeholder: например github.mycompany.example
    target:
      label: Какую версию GitHub вы хотите использовать?
      private: Частная установка GitHub Enterprise
      public: Публичный GitHub.com
    table:
      server: Сервер
      clientId: ID Клиента
  googleoauth:
    adminEmail: Email администратора
    domain: Домен
    oauthCredentials:
      label: Учетные данные OAuth
      tip: Учетные данные OAuth в формате JSON можно найти в консоли разработчиков Google API.
    serviceAccountCredentials:
      label: Учетные данные сервисной учетной записи
      tip: Учетные данные служебной учетной записи JSON можно найти в разделе служебных учетных записей консоли разработчиков Google API.
    steps:
      1:
        title: 'Кликните <a href="https://console.developers.google.com/apis/credentials" target="_blank" rel="noopener noreferrer nofollow">здесь</a> чтобы открыть настройки приложений в новом окне'
        body:
          1: Войдите в ваш аккаунт. Перейдите в "APIs & Services" и затем выберите "OAuth consent screen".
          2: 'Авторизованные домены:'
          3: 'Ссылка на главную страницу приложения: '
          4: 'В разделе "Области действия API Google", включите "email", "profile" и "openid".'
          5: 'Кликните на "Save".'
        topPrivateDomain: 'Лучший частный домен:'
      2:
        title: 'Перейдите на вкладку «Учетные данные», чтобы создать идентификатор клиента OAuth.'
        body:
          1: 'В списке "Create Credentials" выберите "OAuth clientID" и затем "Web application".'
          2: 'Авторизованные источники Javascript:'
          3: 'Разрешенные URI перенаправления:'
          4: 'Кликните "Create", затем кликните на кнопку "Download JSON".'
          5: 'Загрузите скачанный JSON файл в поле учетных данных OAuth.'
      3:
        title: 'Создать учетные данные сервисной учетной записи'
        introduction: 'Пройдите <a href="{docsBase}/admin-settings/authentication/google/#3-creating-service-account-credentials" target="_blank" rel="noopener noreferrer nofollow">сюда</a> для получения инструкции:'
        body:
          1: Создать сервисную учетную запись.
          2: Сгенерировать ключ для сервисного аккаунта.
          3: Добавить учетную запись службы в качестве клиента OAuth в свой домен Google.
  ldap:
    freeipa: Настроить сервер FreeIPA
    activedirectory: Настроить аккаунт Active Directory
    openldap: Настроить сервер OpenLDAP
    defaultLoginDomain:
      label: Домен для входа по умолчанию
      placeholder: например mycompany
      hint: Этот домен будет использоваться, если пользователь войдет в систему, не указав его.
    cert: Сертификат
    disabledStatusBitmask: Битовая маска отключенного состояния
    groupDNAttribute: Аттрибут группы DN
    groupMemberMappingAttribute: Аттрибут сопоставления группы пользователя
    groupMemberUserAttribute: Атрибут пользователя члена группы
    groupSearchBase:
      label: Начальный запрос групп
      placeholder: 'ou=groups,dc=mycompany,dc=com'
    hostname:
      label: Имя хоста/IP
      placeholder: например server1,server2
      hint: Несколько серверов можно указать в виде списка, разделенного запятыми.
    loginAttribute: Аттрибут логина
    nameAttribute: Аттрибут имени
    nestedGroupMembership:
      label: Членство во вложенной группе
      options:
        direct: Искать только прямое членство в группах
        nested: Поиск прямого и вложенного членства в группах
    objectClass: Класс объекта
    password: Пароль
    port: Порт
    customizeSchema: Настроить схему
    users: Пользователи
    groups: Группы
    searchAttribute: Атрибут поиска
    searchFilter: Фильтр поиска
    serverConnectionTimeout: Время ожидания подключения к серверу
    serviceAccountDN: Отличительное имя сервисной учетной записи
    serviceAccountPassword: Пароль сервисной учетной записи
    serviceAccountInfo: '{vendor} требуется учетная запись службы, которая имеет доступ только для чтения ко всем доменам, которые смогут войти в систему, чтобы мы могли определить, к каким группам принадлежит пользователь, когда он делает запрос с помощью ключа API.'
    starttls:
      label: Запустить TLS
      tip: Обновляет незашифрованные соединения, оборачивая их TLS в процессе соединения. Нельзя использовать вместе с TLS.
    tls: TLS
    userEnabledAttribute: Включенный пользователем атрибут
    userMemberAttribute: Атрибут члена пользователя
    userSearchBase:
      label: Начальный запрос пользователей
      placeholder: 'например ou=users,dc=mycompany,dc=com'
    username: Имя пользователя
    usernameAttribute: Атрибут имени пользователя
    table:
      server: Сервер
      clientId: ID клиента
  saml:
    entityID: Поле Entity ID
    UID: Поле UID
    adfs: Настроить аккаунт AD FS
    api: '{vendor} API Host'
    cert:
      label: Сертификат
      placeholder: Вставьте сертификат, начинающийся с  -----BEGIN CERTIFICATE-----
    displayName: Отображаемое имя
    groups: Группы
    key:
      label: Приватный ключ
      placeholder: Вставьте приватный ключ, обычно начинается с -----BEGIN RSA PRIVATE KEY-----
    keycloak: Настроить аккаунт Keycloak
    metadata:
      label: Метаданные XML
      placeholder: Вставьте в IDP метаданные XML
    okta: Настроить аккаунт Okta
    ping: Настроить аккаунт Ping
    shibboleth: Настроить аккаунт Shibboleth
    showLdap: Настроить OpenLDAP сервер
    userName: Поле имени пользователя
  azuread:
    tenantId: ID жильца
    applicationId: ID приложения
    endpoint: endpoint
    graphEndpoint: Graph endpoint
    tokenEndpoint: Token endpoint
    authEndpoint: Auth endpoint
    reply:
      info: 'Перед началом этой настройки Azure AD требуется URL-адрес из белого списка для вашего сервера Rancher. Убедитесь, что указанный ниже URL-адрес задан в разделе URL-адрес ответа вашего портала Azure. Обратите внимание, что распространение URL-адреса из белого списка может занять до 5 минут.'
      label: URL ответа
    updateEndpoint:
      button: Обновить endpoint
      banner:
        message: 'Аутентификацию Azure AD необходимо обновить: она использует API Azure Graph, поддержка которого будет прекращена в конце 2022 года.'
        linkText: 'Обновите здесь'
      modal:
        title: Вы уверены? Это обновление необратимо.
        body: '<p><b>Возможно, вам потребуется внести некоторые дополнительные изменения</b>. Убедитесь, что в приложении Azure AD есть Directory.Read.All.<b>Application</b> разрешение добавлено в Microsoft Graph.<br> Если какие-либо endpoint'ы были настроены при настройке проверки подлинности Azure AD в Rancher, они не будут обновляться автоматически.</p>'
  oidc:
    oidc: Настроить аккаунт OIDC
    keycloakoidc: Настроить аккаунт Keycloak OIDC
    rancherUrl: Rancher URL
    clientId: ID клиента
    clientSecret: Secret клиента
    customEndpoint:
      label: Endpoint'ы
      custom: Уточнить
      standard: Сгенерировать
    keycloak:
      url: Keycloak URL
      realm: Область Keycloak
    issuer: Эмитент
    authEndpoint: Endpoint авторизации
    cert:
      label: Сертификат
      placeholder: Вставьте сертификат, начинающийся с -----BEGIN CERTIFICATE-----
    key:
      label: Приватный ключ
      placeholder: Вставьте приватный ключ, обычно начинается с -----BEGIN RSA PRIVATE KEY-----
  stateBanner:
    disabled: '{provider} как провайдер авторизации сейчас выключен.'
    enabled: '{provider} как провайдер авторизации сейчас включен.'
  testAndEnable: Протестировать и включить авторизацию
  noneEnabled: Локальная аутентификация всегда включена, но вы можете выбрать другого дополнительного провайдера аутентификации из показанных ниже.
  localEnabled: '{vendor} настроен на разрешение доступа к учетным записям в своей локальной базе данных.'
  manageLocal: Управлять аккаунтами

authGroups:
  actions:
    refresh: Обновить членство в группе
    assignRoles: Назначение глобальных ролей
  assignEdit:
    assignTitle: Назначить глобальные роли группе

assignTo:
  title: |-
    {count, plural,
      =1 { Назначить кластер к&hellip; }
      other { Назначить {count} кластеров к&hellip; }
    }
  labelsTitle: |-
    {count, plural,
      =1 { Назначить кластер к&hellip; }
      other { Назначить {count} кластеров к&hellip; }
    }
  workspace: Рабочее пространство

asyncButton:
  apply:
    action: Применить
    success: Применено
    waiting: Применяем&hellip;
  continue:
    action: Продолжить
    success: Сохранено
    waiting: Сохраняем&hellip;
  copy:
    action: Кликните для копирования
    success: Скопировано!
  create:
    action: Создать
    success: Создано
    waiting: Создание&hellip;
  default:
    action: Действие
    error: Ошибка
    success: Успех
    waiting: Ожидание
  delete:
    action: Удалить
    success: Удалено
    waiting: Удаление&hellip;
  disable:
    action: Выключить
    success: Выключено
    waiting: Выключение&hellip;
  activate:
    action:  Активировать
    waiting: Активация&hellip;
    success: Активировано
  deactivate:
    action:  Деактивировать
    waiting: Деактивация&hellip;
    success: Деактивировано
  diagnostic:
    action: Скачать диагностический пакет
    success: Сохранение
    waiting: Загрузка&hellip;
  done:
    action: Завершить
    success: Сохранено
    waiting: Сохранение&hellip;
  download:
    action: Скачать
    success: Сохранение
    waiting: Скачивание&hellip;
  drain:
    action: Освободить
    success: Освобождено
    waiting: Освобождение&hellip;
  edit:
    action: Сохранить
    success: Сохранено
    waiting: Сохранение&hellip;
  enable:
    action: Включить
    success: Включено
    waiting: Включение&hellip;
  finish:
    action: Завершить
    success: Завершено
    waiting: Завершение&hellip;
  import:
    action: Импорт
    success: Импортировано
    waiting: Импортирование&hellip;
  install:
    action: Установить
    success: Установлено
    waiting: Установка&hellip;
  load:
    action: Загрузить
    success: Загружено
    waiting: Загрузка&hellip;
  pause:
    action: Приостановить оркестрацию
    success: Оркестрация приостановлена
    waiting: Приостановка оркестрации
    description: Новые версии не будут развернуты, так как оркестровка временно приостановлена. Чтобы развернуть новые версии, возобновите оркестровку.
  refresh:
    action: ''
    actionIcon: обновить
    error: ''
    errorIcon: ошибка
    success: ''
    successIcon: галочка
    waiting: ''
    waitingIcon: обновить
  remove:
    action: Удалить
    success: Удалено
    waiting: Удаление&hellip;
  restore:
    action: Восстановить
    waiting: Восстановление&hellip;
    success: Восстановлено
  resume:
    action: Возобновить оркестрацию
    success: Оркестрация возобновлена
    waiting: Возобновление оркестрации
  rollback:
    action: Откатиться
    success: Откачено
    waiting: Откатываем рабочее пространство
  rotate:
    action: Ротация
    waiting: Выполнение ротации&hellip;
    success: Ротация выполнена
  run:
    action: Запустить
    waiting: Запуск&hellip;
    success: Завершено
  snapshot:
    action: Создать снэпшот
    waiting: Снэпшот создан&hellip;
    success: Создание снэпшота
  timing:
    action: Сгенерировать время ответа
    waiting: Генерация&hellip;
    success: Время ответа сгенерировано
  uninstall:
    action: Удалить
    success: Удалено
    waiting: Удаление&hellip;
  update:
    action: Обновить
    success: Обновлено
    waiting: Обновление&hellip;
  upgrade:
    action: Улучшить
    success: Улучшено
    waiting: Начинаем&hellip;
  generate:
    action: Сгенерировать
    success: Сгенерировано
    waiting: Генерация&hellip;

backupRestoreOperator:
  backupFilename: Имя файла бэкапа
  deleteTimeout:
    label: Таймаут удаления
    tip: Seconds to wait for a resource delete to succeed before removing finalizers to force deletion.
  deployment:
    rancherNamespace: Пространство имен Rancher ResourceSet
    size: Размер
    storage:
      label: Хранилище по умолчанию
      options:
        defaultStorageClass: 'Использовать класс хранилища по умолчанию ({name})'
        none: Нет хранилища по умолчанию
        pickPV: Использовать существующий постоянный том
        pickSC: Использовать существующий класс хранилища
        s3: использовать S3-совместимое хранилище
      persistentVolume:
        label: Persistent Volume
      storageClass:
        label: Класс хранилища
      tip: 'Настройка хранилища, где по умолчанию сохраняются все резервные копии. У вас будет возможность переопределить это для каждой резервной копии, но будет ограничено использованием S3-совместимого хранилища объектов.'
      warning: 'Этот {type} не имеет своей политики "Сохранить".  Ваши резервные копии могут быть потеряны, если объем изменяется или становится несвязанным.'
  encryption: Шифрование
  encryptionConfigName:
    backuptip: 'Любой секрет в пространстве имен <code>cattle-resource-system</code>, имеющий <code>encryption-provider-config.yaml</code> ключ. <br/> Содержимое этого файла необходимо для выполнения восстановления из этой резервной копии и не хранится в архиве Rancher.'
    label: Encryption Config Secret
    options:
      none: Хранить содержимое незашифрованной резервной копии
      secret: 'Шифрование резервных копий с помощью <a target="_blank" rel="noopener noreferrer nofollow" href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#understanding-the-encryption-at-rest-configuration">Encryption Config Secret</a> (Рекомендуется)'
    restoretip: 'Если резервная копия была выполнена с включенным шифрованием, секрет, содержащий тот же encryption-provider-config должны использоваться во время восстановления.'
    warning: 'Содержимое этого файла необходимо для выполнения восстановления из этой резервной копии и не хранится в архиве Rancher.'
  lastBackup: Последняя резервная копия
  nextBackup: Следующая резервная копия
  noResourceSet: вы должны задать ResourceSet в этом пространстве имен для создания резервной копии CR.
  prune:
    label: Prune
    tip: Удалить ресурсы, управляемые Rancher, которые отсутствуют в резервной копии. (Рекомендуется)
  resourceSetName: Набор ресурсов
  restoreFrom:
    default: Хранилище по умолчанию
    existing: Существующий конфиг резервной копии
    s3: S3-совместимое хранилище
  retentionCount:
    label: Количество повторов
    units: |-
      {count, plural,
        =1 { Файл }
        other { Файлов }
      }
  s3:
    bucketName: Имя бакета
    credentialSecretName: Секрет учетных данных
    endpoint: Endpoint
    endpointCA:
      label: Endpoint CA
      prompt: Endpoint CA должен быть закодирован в Base64
    folder: Папка
    insecureTLSSkipVerify: Пропустить проверки TLS
    region: Регион
    storageLocation: Хранилище
    titles:
      backupLocation: Источник резервной копии
      location: Хранилище
      s3: S3
  schedule:
    label: Расписание
    options:
      disabled: Одноразовое резервное копирование
      enabled: Периодическое резервное копирование
    placeholder: например, @midnight или 0 0 * * *
  storageSource:
    configureS3: Использовать S3-совместимое хранилище
    useBackup: Использовать s3 хранилище, указанное в CR резервной копии
    useDefault: Использовать хранилище по умолчанию, настроенное во время установки
  targetBackup: Целевое резервное копирование

catalog:
  app:
    managed: Управляемое
    section:
      lastOperation: Последняя операция
      notes: Заметки к выпуску
      openLogs: Смотреть логи
      readme: README чарта
      resources:
        label: Ресурсы
        busy: Соответствующие ресурсы появятся, когда {app} полностью установится.
      values: YAML значения
  chart:
    registry:
      label: Регистри контейнеров
      tooltip: Образы контейнеров извлекаются из регистри контейнеров кластера или, в противном случае, из параметра системного регистри контейнеров. Чтобы поменять это, введите или обновите регистри здесь
      custom:
        checkBoxLabel: Регистри контейнеров для образов контейнеров системы Rancher
        inputLabel: Регистри контейнеров
        placeholder: Домен и порт регистри, напр. registry.io:5000
    header:
      charts: Чарты
    info:
      appVersion: Версия приложения
      chartVersions:
        label: Версии чартов
        showMore: Показать больше
        showLess: Показать меньше
      home: Главная
      maintainers: Мэйнтейнеры
      related: Связанное
      chartUrls: Чарт
      keywords: Ключевые слова
    errors:
      clusterToolExists: Этот чарт имеет фиксированное пространство имен и имя. Подходящее <a href="{url}">приложение</a> было найдено и любые изменения будут внесены в него.
  charts:
    all: Все
    categories:
      all: Все категории
    certified:
      other: Другое
      partner: Партнер
      rancher: '{vendor}'
    deploysOnWindows: Развертывание на Windows
    windowsIncompatible: Только на Linux
    versionWindowsIncompatible: Версия только для Linux
    header: Чарты
    featuredCharts: Рекомендуемые чарты
    noCharts: 'Нет доступных чартов, вы добавляли какие-либо репозитории?'
    noWindows: Ваши репозитории не содержат чартов, способных развертываться в кластере с Windows нодами.
    noWindowsAndLinux: Ваши репозитории не содержат чартов, способных развертываться на кластере с worker нодами Windows и Linux.
    operatingSystems:
      all: Все операционные системы
      linux: Linux
      windows: Windows
    search: Фильтр
  install:
    action:
      goToUpgrade: Редактировать/Обновить
    appReadmeMissing: В этом графике нет никакой дополнительной информации.
    appReadmeTitle: Информация о чарте (Helm README)
    chart: Чарт
    error:
      requiresFound: '<a href="{url}">{name}</a> должна быть установлена перед установкой этого чарта.'
      requiresMissing: 'Для этого чарта требует другой чарт, с именем {name}, но он не найден.'
      insufficientCpu: 'Этот чарт требует {need, number} CPU ядер, но в кластере доступно только {have, number}.'
      insufficientMemory: 'Этот чарт требует {need} памяти, но в кластере доступно только {have}.'
      legacy:
        label: Это приложение {legacyType} и не может быть изменено здесь
        enableLegacy:
          prompt: Вам нужно будет включить Устаревшие функции для редактирования этого приложения
          goto: Перейти в настройки фича флагов
        navigate: Перейти в легаси приложения
        mcmNotSupported: Мульти-кластерные приложения не могут управляться через этот интерфейс
        category:
          legacy: Легаси
          mcm: Мульти-кластер
    header:
      install: 'Установить {name}'
      installGeneric: Установить чарт
      upgrade: 'Обновить {name}'
    helm:
      atomic: Atomic
      description:
        label: Описание
        placeholder: напр. назначение helm команды
      cleanupOnFail: Очистить при ошибке
      crds: Применять пользовательские определения ресурсов
      dryRun: Пробный запуск
      force: Принудительно
      historyMax:
        label: Оставлять последние
        unit: |-
          {value, plural,
            =1 { ревизию }
            other { ревизий }
          }
      hooks: Выполнить хуки чарта
      openapi: Валидировать OpenAPI схему
      resetValues: Сбросить значения
      timeout:
        label: Таймаут
        unit: |-
          {value, plural,
            =1 { секунда }
            other { секунд }
          }
      wait: Подождите
    namespaceIsInProject: "Пространство имен этого чарта, <code>{namespace}</code>, уже существует и не может быть добавлено в другой проект."
    project: Установить в проект
    section:
      chartOptions: Редактировать настройки
      valuesYaml: Редактировать YAML
      diff: Сравнить изменения
    slideIn:
      dock: Dock to shell
    steps:
      basics:
        label: Метаданные
        subtext: Установить метаданные приложению
        description: Этот процесс может помочь {action, select,
          install { создать }
          upgrade { улучшить }
          update { обновить }
          } {existing, select,
          true { приложение }
          false { чарт }
          }. Начните с установки некоторых основных сведений, используемых {vendor} для управления приложением.
        nsCreationDescription: "Чтобы установить приложение в новое пространство имен, введите его имя в поле Пространство имен и выберите его."
        createNamespace: "Будет создано пространство имен <code>{namespace}</code>."
      clusterTplVersion:
        label: Версия
        subtext: Выберите версию шаблона
        description: Выберите версия шаблона кластера
      clusterTplValues:
        label: Значения
        subtext: Изменить способ определения Кластера
        description: Настройка значений, используемых Helm, которые помогут определить кластер.
      helmValues:
        label: Значения
        subtext: Изменить, как работает приложение
        description: Настройка значений, используемых Helm, которые помогут определить приложение.
        chartInfo:
          button: Просмотреть информацию о чарте
          label: Информация о чарте
      helmCli:
        checkbox: Настройка параметров Helm перед установкой
        label: Helm параметры
        subtext: Изменение параметров развертывания приложения
        description: Указание дополнительных параметров развертывания
    version: Версия
    versions:
      current: '{ver} (Current)'
      linux: '{ver} (Linux-only)'
      windows: '{ver} (Windows-only)'
  operation:
    tableHeaders:
      action: Действие
      releaseName: Имя релиза
      releaseNamespace: Пространство имен релиза
  repo:
    action:
      refresh: Обновить
    all: Все
    gitBranch:
      label: Git ветка
      placeholder: напр. master
      defaultMessage: 'По умолчанию будет "master" если оставить пустым'
    gitRepo:
      label: URL Git репозитория
      placeholder: 'напр. https://github.com/your-company/charts.git'
    name:
      rancher-charts: '{vendor}'
      rancher-partner-charts: Партнеры
      rancher-rke2-charts: RKE2
      rancher-ui-plugins: Расширения Rancher

    target:
      git: Git репозиторий, содержащий определения Helm шаблонов или кластера
      http: http(s) URL к index, генерируемому Helm
      label: Адрес
    url:
      label: Index URL
      placeholder: 'напр. https://charts.rancher.io'
  tools:
    header: Инструменты кластера
    noTools: "Не найдено инструментов кластера"
    action:
      install: Установить
      upgrade: Улучшить/Редактировать
      edit: Редактировать
      remove: Удалить
      manage: Управлять
  os:
    versionIncompatible: "Эта версия не совместима с Windows нодами."
    chartIncompatible: "Этот чарт не совместим с Windows нодами."

changePassword:
  title: Поменять пароль
  cancel: Отменить
  deleteKeys:
    label: Удалить все существующие ключи API
  changeOnLogin:
    label: Попросить пользователя изменить свой пароль при следующем входе
  generatePassword:
    label: Генерировать случайный пароль
  currentPassword:
    label: Текущий пароль
  userGen:
    newPassword:
      label: Новый пароль
    confirmPassword:
      label: Подтверждение пароля
  randomGen:
    generated:
      label: Сгенерированный пароль
  newGeneratedPassword: Предложенный пароль
  errors:
    mismatchedPassword: Пароли не совпадают
    failedToChange: Ошибка при смене пароля
    failedDeleteKey: Ошибка при удалении ключа
    failedDeleteKeys: Ошибка при удалении ключей

chartHeading:
  overview: Обзор
  poweredBy: "Разработано:"

cis:
  addTest: Добавить Test ID
  alertNeeded: |-
    Оповещение должно быть включено в поле CIS чарта values.yaml.
    Требуется чтобы <a tabindex="0" href="{link}">{vendor} приложение мониторинга и оповещений </a> было установлено
    и Receivers и Routes были <a target="_blank" rel='noopener noreferrer nofollow' href='{docsBase}/how-to-guides/advanced-user-guides/monitoring-v2-configuration-guides/advanced-configuration/alertmanager'> настроены на отправку уведомлений.</a>
  alertOnComplete: Предупреждение о завершении сканирования
  alertOnFailure: Предупреждение о сбое сканирования
  benchmarkVersion: Версия бенчмарка
  clusterProvider: Провайдер кластера
  cronSchedule:
    label: Расписание
    placeholder: "напр. 0 * * * *"
  customConfigMap: Свой ConfigMap бенчмарка
  deleteBenchmarkWarning: |-
    {count, plural,
      =1 { Новые профили, использующие эту версию бенчмарка, больше не будут работать. }
      other { Любые профили, использующие эти версии бенчмарка, больше не будут работать}
    }
  deleteProfileWarning: |-
    {count, plural,
      =1 { Любые запланированные сканирования, использующие этот профиль, больше не будут работать. }
      other { Любое запланированное сканирование с использованием любого из этих профилей больше не будет работать. }
    }
  downloadAllReports: Скачать все сохраненные отчеты
  downloadLatestReport: Скачать последний отчет
  downloadReport: Скачать отчет
  maxKubernetesVersion: Максимально требуемая версия Kubernetes
  minKubernetesVersion: Минимальная требуемая версия Kubernetes
  noProfiles: Для этого типа кластера нет допустимых файлов ClusterScanProfiles.
  noReportFound: Отчет о сканировании не найден
  profile: Профиль
  reports: Отчеты
  retention: Повторных попыток
  scan:
    description: Описание
    fail: Неудача
    lastScanTime: Время последнего сканирования
    notApplicable: Н/Д
    number: Число
    pass: Успех
    remediation: Восстановление
    scanDate: Дата сканирования
    scanReport: Отчет сканирования
    skip: Пропустить
    total: Итого
    warn: Предупреждение
  scheduling:
    disable: Запустить разовое сканирование
    enable: Запустить сканирование по расписанию
  scoreWarning:
    label: Scan state for "warn" results
    protip: Сканирование без сбоев будет помечено как "Успех" по умолчанию, даже если некоторые тесты генерируют "Предупреждение". Это поведение можно изменить, выбрав в этом разделе опцию "Неудача".
  testID: Test ID
  testsSkipped: Тестов пропущено
  testsToSkip: Тестов для пропуска
  workerProfile: Профиль CIS Worker

cluster:
  addonChart:
    rancher-vsphere-cpi: Конфигурация vSphere CPI
    rancher-vsphere-csi: Конфигурация vSphere CSI
    rke2-calico: Конфигурация Calico
    rke2-calico-crd: Конфигурация Calico
    rke2-canal: Конфигурация Canal
    rke2-cilium: Конфигурация Cilium
    rke2-coredns: Конфигурация CoreDNS
    rke2-ingress-nginx: Конфигурация NGINX Ingress
    rke2-kube-proxy: Конфигурация Kube Proxy
    rke2-metrics-server: Конфигурация сервера метрик
    rke2-multus: Конфигурация Multus
  agentEnvVars:
    label: Переменные окружения агента
    detail: Добавьте дополнительные переменные окружения в контейнер агента. Чаще всего это используется при конфигурации HTTP-прокси.
    keyLabel: Имя переменной
  cloudProvider:
    aws:
      label: Amazon
    azure:
      label: Azure
    external:
      label: Сторонний
    gcp:
      label: Google
    rancher-vsphere:
      label: vSphere
      note: '<b>Важно:</b> Настройте облачный провайдер vSphere и провайдер хранилища на вкладке конфигурации аддонов.'
    harvester:
      label: Harvester
  copyConfig: Скопировать KubeConfig в буфер обмена
  copiedConfig: KubeConfig скопирован в буфер обмена
  custom:
    nodeRole:
      label: Роль ноды
      detail: Выберите, какие роли будет иметь данная нода в кластере. Кластер должен содержать как минимум одну ноду каждой роли.
    advanced:
      label: Расширенные настройки
      detail: Дополнительные настройки регистрации ноды. Часто требуется, чтобы эти значения отличались у каждой из зарегистрированных нод.
      nodeName: Имя ноды
      publicIp: Публичный IP ноды
      privateIp: Приватный IP ноды
      nodeLabel:
        title: Лейблы ноды
        label: Добавить лейбл
    registrationCommand:
      label: Команда регистрации
      linuxDetail: Запустить эту команду на каждой имеющейся машине под Linux, которую вы хотите зарегистрировать.
      windowsDetail: Запустить эту команду из PowerShell на каждой имеющейся машине под Windows, которую вы хотите зарегистрировать. Ноды под Windows могут быть только worker нодами.
      windowsNotReady: Кластер должен быть запущен и работать с Linux etcd, Control Plane и worker нодами, прежде чем отобразится команда регистрации для добавления worker нод под Windows.
      windowsWarning: Поды рабочей нагрузки, включая развернутые Rancher чарты, будут запланированы и на Linux, и на Windows нодах по умолчанию. Отредактируйте NodeSelector на чарте, чтобы разместить их на совместимой ноде.
      windowsDeprecatedForRKE1: На Windows прекращена поддержка RKE1. Рекомендуется переход на RKE2.
      insecure: "Небезопасно: Выберите это, чтобы пропустить TLS верификацию, если ваш сервер имеет самоподписанный сертификат."
  credential:
    banner:
      createCredential: |-
        {length, plural,
          =0 {Сначала необходимо создать учетные данные для связи с облачным провайдером}
          other {Создайте новые учетные данные}
        }
    selectExisting:
      label: Выбрать существующий
    select:
      option:
        new: Создать новый...
        none: Выбрать учетные данные...
    aws:
      accessKey:
        label: Ключ доступа
        placeholder: Ваш ключ доступа AWS
      defaultRegion:
        help: Регион, используемый по умолчанию при создании кластеров. Также используется в проверке указанных учетных данных.
        label: Регион по умолчанию
      secretKey:
        label: Секретный ключ
        placeholder: Ваш секретный ключ AWS
    azure:
      clientId:
        label: ID клиента
      clientSecret:
        label: Client Secret
      environment:
        label: Окружение
      subscriptionId:
        label: ID подписки
      tenantId:
        label: Tenant ID
    digitalocean:
      accessToken:
        help: Вставьте токен личного доступа для DigitalOcean со страницы <a href="https://cloud.digitalocean.com/settings/api/tokens" target="_blank" rel="noopener noreferrer nofollow">Applications & API</a>.
        label: Токен доступа
        placeholder: Ваш токен доступа DigitalOcean API
    label: Облачные учетные данные
    linode:
      accessToken:
        help: Вставьте токен личного доступа для Linode со страницы <a href="https://cloud.linode.com/profile/tokens" target="_blank" rel="noopener noreferrer nofollow">API Tokens</a>.
        label: Токен доступа
        placeholder: Ваш токен доступа Linode API
    name:
      label: Название учетных данных
      placeholder: Название для этих учетных данных (необязательно)
    s3:
      accessKey:
        label: Ключ доступа
        placeholder: Ваш ключ доступа API
      defaultRegion:
        label: Регион по умолчанию
        placeholder: "Необязательно: регион для использования по умолчанию"
      defaultBucket:
        label: Бакет по умолчанию
        placeholder: "Необязательно: бакет для использования по умолчанию"
      defaultEndpoint:
        label: Endpoint по умолчанию
        placeholder: "Необязательно: endpoint для использования по умолчанию"
      defaultFolder:
        label: Папка по умолчанию
        placeholder: "Необязательно: папка для использования по умолчанию"
      defaultEndpointCA:
        label: Endpoint CA сертификата по умолчанию
        placeholder: "Необязательно: CA сертификат по умолчанию, используемый для проверки endpoint"
      defaultSkipSSLVerify:
        label: Принимать любой сертификат (небезопасно)
      secretKey:
        label: Секретный ключ
        placeholder: Ваш секретный ключ API
    vmwarevsphere:
      server:
        label: vCenter или ESXi сервер
        placeholder: vcenter.domain.com
      port:
        label: Порт
      username:
        label: Имя пользователя
      password:
        label: Пароль
      note: 'Замечание: Бесплатная лицензия ESXi не поддерживает API доступ. Поддерживаются только серверы с действующими или ознакомительными лицензиями.'
    gcp:
      authEncodedJson:
        label: Сервисный аккаунт
        placeholder: JSON файл с закрытым ключом для сервисного аккаунта
        help: |-
          <p>Создайте <a href="https://console.cloud.google.com/projectselector/iam-admin/serviceaccounts" target="_blank" rel="noopener noreferrer nofollow">сервисный аккаунт</a> с закрытым ключом в формате JSON и добавьте JSON-файл сюда.
          Следующие IAM роли являются обязательными:</p>
          <ul>
          <li><b>Вычислительный движок:</b> Compute Viewer (roles/compute.viewer)</li>
          <li><b>Проект:</b> Viewer (roles/viewer)</li>
          <li><b>Движок Kubernetes:</b> Администратор движка Kubernetes (roles/container.admin)</li>
          <li><b>Сервисные аккаунты:</b> Пользователь сервисного аккаунта (roles/iam.serviceAccountUser)</li>
          </ul>
          Больше информации о ролях можете найти <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/iam-integration" target="_blank" rel="noopener noreferrer nofollow">здесь</a>.
    harvester:
      import: Импортированный Harvester
      namespace: Пространство имён
      cpu: CPU
      memory: Память
      disk: Диск
      image: Образ
      network: Имя сети
      sshUser: SSH пользователь
      userData:
        label: Шаблон данных пользователя
        title: "Данные пользователя:"
      networkData:
        label: Шаблон данных сети
        title: "Данные сети:"
      kubeconfigContent:
        label: KubeconfigContent
      placeholder: 'Пространство имён/Имя'
      cluster: Кластер
      affinity:
        namespaces:
          placeholder: например, default,system,base
  description:
    label: Описание кластера
    placeholder: Любой текст, который лучше описывает данный кластер
  harvester:
    importNotice: Импортировать Harvester кластеры через
    warning:
      label: Это Harvester кластер - включить Harvester feature flag для управления им
      state: Предупреждение
      cloudProvider:
        incompatible:
          Вы не можете выбрать облачный провайдер Harvester т.к. текущая версия Harvester не совместима с выбранной версией RKE2 Kubernetes, нажмите <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.suse.com/suse-harvester/support-matrix/all-supported-versions">здесь</a>, чтобы узнать, какие версии Kubernetes поддерживаются.
    clusterWarning: |-
      Есть {count, plural,
      =1 {1 Harvester кластер, который не отображен}
      other {# Harvester кластера/кластеров, которые не отображены}
      }
    registration:
      step1: "1. Перейдите на страницу <code>Расширенные / настройки</code> целевого Harvester UI."
      step2: '2. Найдите <code>cluster-registration-url</code> настройки и нажмите кнопку <code><i class="icon icon-actions" ></i></code> -> <code>Редактировать настройки</code>.'
      step3: "3. Введите приведенную ниже ссылку для регистрации и нажмите кнопку <code>Сохранить</code>."
      step4: "Ссылка для регистрации"
    machinePool:
      cpu:
        placeholder: например, 2
      memory:
        placeholder: например, 4
      disk:
        placeholder: например, 4
      namespace:
        placeholder: например, default
      image:
        placeholder: Пожалуйста, выберите образ
      network:
        placeholder: Пожалуйста, выберите сеть
      sshUser:
        placeholder: например, ubuntu
        toolTip: SSH пользователь для входа с выбранным образом операционной системы.
  haveOneOwner: Обязательно должен быть как минимум один участник с ролью владельца.
  import:
    warningBanner: 'Не импортируйте кластер, который уже был присоединен к другому экземпляру Rancher, т.к. это приведет к повреждению данных.'
    commandInstructions: 'Выполните команду <code>kubectl</code> ниже на существующем Kubernetes кластере, работающем на поддерживаемой версии Kubernetes, чтобы импортировать в {vendor}:'
    commandInstructionsInsecure: 'Если возникает ошибка &quot;certificate signed by unknown authority&quot;, это означает, что сборка {vendor} имеет самоподписанный или ненадежный SSL-сертификат. Вместо предыдущей выполните команду, приведенную ниже, чтобы пропустить проверку сертификата:'
    clusterRoleBindingInstructions: 'Если при создании некоторых ресурсов возникают ошибки разрешения доступа, возможно, ваш пользователь не имеет роли <code>cluster-admin</code>. Используйте следующую команду, чтобы применить её:'
    clusterRoleBindingCommand: 'kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user <your username from your kubeconfig>'
  explore: Обзор
  importAction: Импортировать существующий
  manageAction: Управление
  kubernetesVersion:
    label: Версия Kubernetes
    experimental: экспериментальная
    deprecated: устаревшая
    deprecatedPatches: Показать устаревшие версии патчей Kubernetes
    deprecatedPatchWarning: Рекоммендуется использовать последнюю версию патча для каждой минорной версии Kubernetes. Устаревшие версии патчей могут быть полезны при миграции.
  toolsTip: Используйте новый Cluster Tools для управления и установки Monitoring, Logging и других инструментов
  legacyWarning: Включен флаг устаревших функций, но не все устаревшие функции поддерживаются в Kubernetes 1.21+.
  log:
    connecting: Подключение…
    noData: Нет записей в журнале инициализации
  name:
    label: Имя кластера
    placeholder: Уникальное имя для данного кластера
  machineConfig:
    banner:
      updateInfo: Создайте новый пул для обновления конфигурации машин
    aws:
      sizeLabel: |-
        {apiName}: {cpu, plural,
        =1 {1 vCPU}
          other {# vCPU}
        } / {memory, number} GiB память / {storageSize, plural,
          =0 {EBS-Only}
          other {{storageSize, number} {storageUnit} {storageType}}
        }
    azure:
      acceleratedNetworking:
        label: Ускоренное сетевое взаимодействие
      availabilitySet:
        label: Группа доступности (без управления)
        description: Группы доступности используются, чтобы защитить приложения от сбоев оборудования в дата-центре Azure.
      availabilityZone:
        label: Зона доступности
        description: Зоны доступности защищают приложения от полных сбоев дата-центра Azure.
      dns:
        help: Уникальный DNS-лейбл для публичного IP-адреса.
        label: DNS-лейбл
      environment:
        label: Окружение
      faultDomainCount:
        help: Если группа доступности уже создана, количество доменов сбоя будет проигнорировано.
        label: Количество доменов сбоя
      image:
        help: Предоставление идентификатора ресурса ARM требует использования управляемого диска.
        label: Образ
      location:
        label: Расположение
      managedDisks:
        label: Использовать управляемые диски
      managedDisksSize:
        label: Размер управляемого диска
      nsg:
        help: При использовании управляемого Rancher или предоставлении существующей NSG, все ноды, использующие данный шаблон, будут использовать предоставленную NSG. Если NSG не задана, новая NSG будет создана для каждой ноды.
        label: Группа безопасности сети
      openPort:
        add: Добавить порт
        help: При использовании существующего NSG, открытые порты игнорируются.
        label: Открытый порт
      plan:
        label: План покупки
        placeholder: publisher:product:plan
      privateIp:
        label: Приватный IP-адрес
      publicIpOptions:
        header: Параметры публичного IP
        noPublic:
          label: Без публичного IP
        staticPublicIp:
          label: Статический публичный IP
      resourceGroup:
        label: Группа ресурсов
      size:
        label: Размер ВМ
        tooltip: При активации ускоренного сетевого взаимодействия, не все размеры доступны.
        supportsAcceleratedNetworking: Размеры, которые поддерживаются при ускоренном сетевом взаимодействии
        doesNotSupportAcceleratedNetworking: Размеры без ускоренного сетевого взаимодействия
        availabilityWarning: Выбранный размер ВМ недоступен в выбранном регионе.
        regionDoesNotSupportAzs: Зоны доступности не поддерживаются в данном регионе. Пожалуйста, выберите другой регион или используйте группу доступности вместо зоны доступности.
        regionSupportsAzsButNotThisSize: Выбранный регион не поддерживает зоны доступности для выбранного размера ВМ. Пожалуйста, выберите другой регион или размер ВМ.
        selectedSizeAcceleratedNetworkingWarning: Выбранный размер ВМ не поддерживает ускоренное сетевое взаимодействие. Пожалуйста, выберите другой размер ВМ или отключите ускоренное сетевое взаимодействие.
      sshUser:
        label: SSH имя пользователя
      storageType:
        label: Тип хранилища
        warning: Для StandardSSD_LRS требуются управляемые диски. Пожалуйста, выберите "Использовать управляемые диски" или выберите другой тип хранилища.
      subnet:
        label: Подсеть
      subnetPrefix:
        label: Префикс подсети
      updateDomainCount:
        help: Если группа доступности уже создана, количество доменов обновления будет проигнорировано.
        label: Количество доменов обновления
      usePrivateIp:
        label: Использовать приватный IP
      vnet:
        label: Виртуальная сеть
        placeholder: '[resourcegroup:]name'
      tags:
        label: Теги
    digitalocean:
      sizeLabel: |-
        {plan, select,
          s {Базовый: }
          g {Обычный: }
          gd {Обычный: }
          c {CPU: }
          m {Память: }
          so {Хранилище: }
          standard {Стандартный: }
          other {}
        }{memoryGb} GB, {vcpus, plural,
          =1 {# vCPU}
          other {# vCPU}
        }, {disk} GB диск ({value})
      tags:
        label: Droplet теги
        placeholder: например, my_server
    linode:
      typeLabel: |-
        {label}, {vcpus, plural,
          =1 {# vCPU}
          other {# vCPU}
        }, {disk} GB диск ({value})
    vsphere:
      hostOptions:
        any: Любой
      vAppOptions:
        label: Параметры vApp
        description: Выберите свойства окружения OVF
        disable: Не использовать vApp
        auto: Использовать vApp для конфигурации сети с сетевыми профилями протоколов
        manual: Предоставить пользовательскую конфигурацию vApp
        restoreType: Восстановить тип
        transport:
          label: Транспорт окружения OVF
          tooltip: com.vmware.guestInfo or iso
          placeholder: например, com.vmware.guestInfo
        protocol:
          label: IP-протокол vApp
          tooltip: IPv4 или IPv6
          placeholder: например, IPv4
        allocation:
          label: Политика распределения IP-адресов vApp
          tooltip: dhcp, fixed, transient или fixedAllocated
          placeholder: например, fixedAllocated
        properties:
          label: свойства vApp
          add: Добавить свойство
          keyPlaceholder: например, guestinfo.interface.0.ip.0.address
          valuePlaceholder: например, ip:VM Network, выражение или строка
      networks:
        label: Сети
        add: Добавить сеть
      guestinfo:
        label: Параметры конфигурации, используемые для guestinfo
        add: Добавить параметр
        keyPlaceholder: например, guestinfo.hostname
        valuePlaceholder: например, myrancherhost
      creationMethods:
        template: 'Развернуть из шаблона: Дата-центр'
        library: 'Развернуть из шаблона: Библиотека контента'
        vm: 'Клонировать существующую виртуальную машину'
        legacy: 'Установить из boot2docker ISO (устаревшее)'
      scheduling:
        label: Планирование
        description: Выберите гипервизор, на который будет назначена виртуальная машина
        dataCenter: Дата-центр
        resourcePool: Пул ресурсов
        dataStore: Хранилище данных
        folder: Папка
        host:
          label: Хост
          note: Хост для создания ВМ (оставьте пустым для автономного ESXi или кластера с DRS)
      instanceOptions:
        label: Свойства экземпляра
        description: Выберите размер и ОС виртуальной машины
        cpus: CPU
        memory: Память
        disk: Диск
        creationMethod: Метод создания
        template:
          label: Шаблон
          none: Шаблоны не найдены
        contentLibrary: Библиотека контента
        libraryTemplate: Библиотека шаблонов
        virtualMachine: Виртуальная машина
        osIsoUrl:
          label: URL до ISO ОС
          placeholder: 'По умолчанию: последний rancheros-vmware образ'
        cloudInit:
          label: Cloud Init
          placeholder: например, http://my_host/cloud-config.yml
          note: Cloud-init файл или url для установки в guestinfo
        cloudConfigYaml: Облачная конфигурация YAML
        os: Операционная система
      tags:
        label: Теги
        description: Теги позволяют добавить метаданные к объектам в vSphere inventory для упрощения поиска и сортировки этих объектов.
        addTag: Добавить тег
      customAttributes:
        label: Пользовательские атрибуты (устаревшее)
        description: Пользовательские атрибуты позволяют добавить метаданные к объектам в vSphere inventory для упрощения поиска и сортировки этих объектов.
        add: Добавить пользовательский атрибут
    amazonEc2:
      region: Регион
      zone: Зона
      instanceType: Тип экземпляра
      rootSize:
        placeholder: 'По умолчанию: 16'
        label: Размер корневого диска
        suffix: GB
      selectedNetwork:
        label: 'VPC/Подсеть'
        placeholder: Выберите VPC или подсеть
      iamInstanceProfile:
        label: Имя профиля экземпляра IAM
        tooltip: Поддержка облачного провайдера Kubernetes AWS требует соответствующего профиля экземпляра
      ami:
        label: AMI ID
        placeholder: 'По умолчанию: последний Ubuntu LTS'
      sshUser:
        label: Имя пользователя SSH для AMI
        placeholder: 'По умолчанию: ubuntu'
        tooltip: 'Имя пользователя, которое существует в выбранном AMI; будет использоваться для SSH-подключения к данной ноде.'
      securityGroup:
        title: Группа безопасности
        vpcId: '(сначала выберите VPC/подсеть)'
        mode:
          default: 'Стандартно: Автоматически создать и использовать группу безопасности "{defaultGroup}"'
          custom: 'Выберите одну или несколько существующих групп безопасности:'
      volumeType:
        label: Тип корневого EBS тома
        placeholder: 'По умолчанию: gp2'
      encryptEbsVolume: Зашифровать EBS том
      kmsKey:
        label: KMS ключ ARN
        text: 'У вас недостаточно прав для получения списка ключей KMS, но вы все равно сможете ввести ключ ARN, если вы его знаете.'
      requestSpotInstance: Запросить Spot-экземпляр
      spotPrice:
        label: Spot-цена
        placeholder: 'По умолчанию: 0.50'
        suffix: Долларов в час
      privateAddressOnly: Используйте только приватный адрес
      useEbsOptimizedInstance: Оптимизированный по EBS экземпляр
      httpEndpoint: Разрешить доступ к EC2 метаданным
      httpTokens: Использовать токены для метаданных
      tagTitle: EC2 теги
  addOns:
    dependencyBanner: Конфигурации аддонов могут отличаться для разных версий Kubernetes. Изменение версии Kubernetes может привести к сбросу значений, приведенных ниже.
    additionalManifest:
      title: Дополнительный манифест
      tooltip: 'Дополнительный YAML манифест Kubernetes для применения к кластеру при запуске'
  advanced:
    argInfo:
      title: Дополнительные Kubelet аргументы
      machineSelector:
        label: Добавить селектор машин
        listLabel: Добавить аргумент
        bannerLabel: 'Замечание: Будет использован только самый последний селектор, удовлетворяющий условию, и только аргументы из него. Аргументы из остальных селекторов, удовлетворяющих условию, не будут ни объединены, ни скомбинированы.'
        title: 'Для машин с лейблами совпадающими с:'
        subTitle: 'Использовать следующие аргументы Kubelet:'
        titleAlt:  |-
          {count, plural,
            =1 { Для всех машин использовать следующие аргументы Kubelet: }
            other { Для любых машин использовать следующие аргументы Kubelet: }
          }
        kubeControllerManagerTitle: Дополнительные аргументы диспетчера контроллеров
        kubeApiServerTitle: Дополнительные серверные аргументы API
        kubeSchedulerTitle: Дополнительные аргументы планировщика
    agentArgs:
      label: Вызывать ошибку, если параметры ядра отличаются от ожидаемых значений по умолчанию Kubelet
  banner:
    warning: 'Этот кластер содержит machineSelectorConfig. Данная форма не поддерживает его в полной мере. Используйте редактор YAML для управления полной конфигурацией.'
    os: 'Попытка добавить {newOS} worker ноду в кластер с одной или несколькими {existingOS} worker нодами: для некоторых установленных приложений может потребоваться обновление или удаление.'
    rke2-k3-reprovisioning: 'Внесение изменений в конфигурацию кластера может привести к reprovisioning нод. Больше информации вы можете найти в <a target="blank" href="{docsBase}/how-to-guides/new-user-guides/launch-kubernetes-with-rancher/rke1-vs-rke2-differences" target="_blank" rel="noopener nofollow">документации</a>.'
    desiredNodeGroupWarning: Доступно 0 нод для запуска агента кластера. Кластер не будет активирован, пока нет как минимум одной доступной ноды.

  rkeTemplateUpgrade: Доступно обновление для ревизии шаблона {name}

  availabilityWarnings:
    node: Нода {name} неактивна
    machine: Машина {name} неактивна

  detail:
    provisioner: Provisioner
    kubernetesVersion: Версия Kubernetes
    machineProvider: Провайдер машин
    machinePools: Машинные пулы
    machines: Машины
    rkeTemplate: RKE шаблон

  machinePool:
    name:
      label: Имя пула
      placeholder: По умолчанию будет сгенерировано случайным образом
    nodeTotals:
      label:
        controlPlane: '{count} Control Plane'
        etcd: '{count} etcd'
        worker: '{count} Worker'
      tooltip:
        controlPlane: |-
          {count, plural,
            =0 { Для работы кластера необходима как минимум одна нода Control Plane. }
            =1 { Кластер, имеющий только одну ноду Control Plane, не является отказоустойчивым. }
            other {}
          }
        etcd: |-
          {count, plural,
            =0 { Для работы кластера необходима как минимум одна etcd нода. }
            =1 { Кластер, имеющий только одну etcd ноду, не является отказоустойчивым. }
            =2 { Кластеры должны иметь нечетное количество нод. Кластер с 2 etcd нодами не является отказоустойчивым. }
            =3 {}
            =4 { Кластеры должны иметь нечетное количество нод. }
            =5 {}
            =6 { Кластеры должны иметь нечетное количество нод. }
            =7 {}
            other { Не рекомендуется использовать более 7 etcd нод. }
          }
        worker: |-
          {count, plural,
            =0 { Для работы кластера необходима как минимум одна worker нода. }
            =1 { Кластер, имеющий только одну worker ноду, не является отказоустойчивым. }
            other {}
          }
    quantity:
      label: Количество машин
    drain:
      header: Освобождение
      label: Освобождение перед удалением
    role:
      label: Роли
    labels:
      label: Лейблы нод Kubernetes
    noAccessBanner: "Недостаточно прав для просмотра конфигурации машинного пула."
    configNotFound: "Данная конфигурация машинного пула не найдена. Рекомендуем создать новый кластер с желаемой конфигурацией."
    noPoolsDisclaimer: Нет заданных машинных пулов, нажмите на плюс, чтобы добавить.
    autoReplace:
      label: Автоматическая замена
      toolTip: Если значение больше 0, ноды, недоступные в течение этого времени, будут автоматически удалены и заменены.
      unit: "Секунды"
  managementTimeout: Кластер станет доступным. Возможно, кластер уже создан. Рекомендуем проверить страницу кластеров прежде, чем пытаться создавать новый.
  memberRoles:
    removeMessage: 'Замечание: удаление пользоватей не приводит к удалению их доступа к проекту'
    addClusterMember:
      labelSelect: Выберите участника
      labelAdd: Добавить участника
      placeholder: Поиск участника для предоставления доступа к кластеру
      searchPlaceholder: Начните вводить для поиска
      noResults: Результатов не найдено
  privateRegistry:
    label: Включить регистри контейнеров на уровне кластера для образов системных контейнеров Rancher
    description: "Если включено, Rancher будет извлекать образы контейнеров из этого регистри во время выделения кластера. По умолчанию Rancher также будет использовать этот регистри при установке официальных Helm чарт приложений Rancher. Если отключен регистри контейнеров на уровне кластера, системные образы извлекаются из системного регистри по умолчанию, указанного в глобальных настройках."
    docsLinkRke2: "За помощью в конфигурации приватных зеркал регистри обратитесь к <a href=\"https://docs.rke2.io/install/containerd_registry_configuration/\" target=\"_blank\">документации</a> RKE2."
    docsLinkK3s: "За помощью в конфигурации приватных зеркал регистри обратитесь к <a href=\"https://docs.k3s.io/installation/private-registry\" target=\"_blank\">документации</a> K3s."
  provider:
    aliyunecs: Aliyun ECS
    aliyunkubernetescontainerservice: Alibaba ACK
    aliyun:  Alibaba ACK
    amazonec2: Amazon EC2
    amazoneks: Amazon EKS
    aws: Amazon
    azure: Azure
    azureaks: Azure AKS
    aks: Azure AKS
    azurekubernetesservice: Azure AKS
    baiducloudcontainerengine: Baidu CCE
    baidu: Baidu CCE
    cloudca: Cloud.ca
    cloudscale: Cloudscale
    custom: Custom
    digitalocean: DigitalOcean
    docker: Docker
    eks: Amazon EKS
    exoscale: Exoscale
    gcp: Google
    google: Google GCE
    googlegke: Google GKE
    gke: Google GKE
    harvester: Harvester
    huaweicce: Huawei CCE
    import: Generic
    imported: Imported
    k3s: K3s
    kubeAdmin: KubeADM
    linode: Linode
    linodelke: Linode LKE
    local: Local
    minikube: Minikube
    oci: Oracle OCI
    openstack: OpenStack
    opentelekomcloudcontainerengine: Open Telekom Cloud CCE
    otccce: Open Telekom Cloud CCE
    oracle: Oracle
    oracleoke: Oracle OKE
    otc: Open Telekom Cloud
    other: Other
    packet: Equinix Metal
    pinganyunecs: Pinganyun ECS
    pnap: phoenixNAP
    rackspace: RackSpace
    rancherkubernetesengine: RKE
    rke2: RKE2
    rke: RKE1
    rkeWindows: Windows (только RKE1)
    s3: S3-Compatible
    softlayer: IBM Cloud
    tencenttke: Tencent TKE
    upcloud: UpCloud
    vmwarevsphere: VMware vSphere
    zstack: ZStack
    machineinventoryselectortemplate: Elemental Cluster
  providerTag:
    rke2:
      harvester: '{tag}'
  providerGroup:
    create-custom1: Использовать существующие ноды и создать кластер с помощью RKE
    create-custom2: Использовать существующие ноды и создать кластер с помощью RKE2/K3s
    create-kontainer: Создать кластер во внешнем провайдере Kubernetes
    register-kontainer: Зарегистрировать существующий кластер во внешнем провайдере Kubernetes
    create-rke1: Сделать provision новых нод и создать кластер с помощью RKE
    create-rke2: Сделать provision новых нод и создать кластер с помощью RKE2/K3s
    create-template: Использовать шаблон каталога для создания кластера
    register-custom: Импортировать любой Kubernetes кластер
  rke2:
    snapshots:
      suffix: снапшотов на одну ноду
    systemService:
      rke2-coredns: 'CoreDNS'
      rke2-ingress-nginx: 'NGINX Ingress'
      rke2-kube-proxy: 'Kube Proxy'
      rke2-metrics-server: 'Сервер метрик'
      header: Системные сервисы
    cni:
      label: Сеть контейнеров
    cloudProvider:
      label: Облачный провайдер
      header: Конфигурация облачного провайдера
    security:
      header: Безопасность
    defaultPodSecurityPolicyTemplateName:
      label: Политика безопасности подов по умолчанию
    defaultPodSecurityAdmissionTemplateName:
      label: Допуск безопасности подов по умолчанию
    enableNetworkPolicy:
      label: Изоляция сети проекта
      warning: По умолчанию контроллер входящего трафика не сможет направлять запросы к подам на других нодах.
    workNode:
      label: Worker ноды
    controlPlaneConcurrency:
      label: Согласованность Control Plane
      toolTip: "Указывается либо фиксированное количество нод (например, 1) за раз, либо процент (например, 10%)"
    workerConcurrency:
      label: Согласованность Worker
      toolTip: "Указывается либо фиксированное количество нод (например, 1) за раз, либо процент (например, 10%)"
    drain:
      label: Освобождение нод
      toolTip: Освобождение превентивно удаляет поды на каждой ноде, чтобы на обновляемых нодах не было запущенных рабочих нагрузок. Обновление без освобождения выполняется быстрее и вызывает меньше изменений, но поды все равно могут быть перезапущены в зависимости от выполняемого обновления.
    deleteEmptyDir: "По умолчанию поды, использующие тома emptyDir, будут удалены при обновлении. Это может повлиять на операции, зависящие от томов emptyDir, сохраняющихся в течение жизненного цикла подов."
    address:
      tooltip: Сетевые значения кластера нельзя изменить после того, как кластер будет создан.
      header: Адресация
      clusterCidr:
        label: CIDR кластера
      serviceCidr:
        label: CIDR сервисов
      dns:
        label: DNS кластера
      domain:
        label: Домен кластера
      nodePortRange:
        label: Диапазон сервисных портов NodePort
      tlsSan:
        label: Альтернативные имена TLS
      fqdn:
        toolTip: FQDN, который будет разрешаться в исправные ноды Control Plane кластера.
      caCerts:
        label: CA сертификаты
        toolTip: Сертификаты, необходимые клиенту для успешной проверки действительности сертификата, возвращенного Endpoint.
      ipv6:
        warning: Похоже, вы используете IPv6 CIDR. Драйвер ноды может требовать дополнительной конфигурации для его поддержки.
        enable: Включить поддержку IPv6
    etcd:
      disableSnapshots:
        label: Автоматические снапшоты
      snapshotScheduleCron:
        label: Cron-расписание
      snapshotRetention:
        label: Оставлять последний
      exportMetric:
        label: Метрики
        false: Доступно только внутри кластера
        true: Доступно для публичного интерфейса
  k3s:
    systemService:
      coredns: 'CoreDNS'
      local-storage: 'Local Storage'
      metrics-server: 'Сервер метрик'
      servicelb: 'Klipper Service LB'
      traefik: 'Traefik Ingress'
  selectCredential:
    genericDescription: "{vendor} не имеет встроенной поддержки для этого драйвера. Мы сделали предположение, но обратитесь к документации драйвера, чтобы уточнить список полей, необходимых для аутентификации."
  snapshot:
    successTitle: Снапшот запущен
    errorTitle: "Ошибка создания снапшота {name}"
    successMessage: "Был запрошен снапшот для {name}"
    bulkSuccessTitle: Снапшот запущен
    bulkSuccessMessage: |-
      {count, plural,
        =1 { Был запрошен снапшот для 1 кластера }
        other {Был запрошен снапшот для {count} кластера/кластеров }
      }
    groupLabel: Расположение
    failed: "Произошла ошибка при выполнении снапшота от {time} "
    rke1:
      local: локально
      s3: s3
  tabs:
    ace: Авторизованный Endpoint
    addons: Конфигурация аддонов
    advanced: Расширенные настройки
    agentEnv: Переменные окружения агента
    basic: Основы
    cluster: Конфигурация кластера
    etcd: etcd
    log: Provisioning Log
    networking: Сеть
    machinePools: Машинные пулы
    machines: Машины
    memberRoles: Роли участников
    registry: Регистри
    upgrade: Стратегия обновления
    registration: Регистрация
  rotateCertificates:
    label: Ротация сертификатов
    modalTitle: Ротация сертификатов кластера
    services: Сервисы
    allServices: Ротация всех сертификатов сервисов
    selectService: Ротация отдельных сервисов
  toggle:
    v1: RKE1
    v2: RKE2/K3s
  validation:
    iamInstanceProfileName: Если выбран облачный провайдер Amazon, необходимо задать "Имя профиля экземпляра IAM" для каждого машинного пула

clusterIndexPage:
  hardwareResourceGauge:
    consumption: "{useful} из {total} {units} {suffix}"
    cores: CPU
    pods: Подов
    ram: Памяти
    used: Используется
    reserved: Зарезервировано
    units:
      cores: |-
        {count, plural,
        =1 {ядро}
        other {ядер}}
  header: Дашборд кластера
  resourceGauge:
    totalResources: Всего ресурсов
  sections:
    capacity:
      label: Мощность
    events:
      label: События
      resource:
        label: Ресурс
      date:
        label: Дата
    alerts:
      label: Оповещения
    clusterMetrics:
      label: Метрики кластера
    etcdMetrics:
      label: Etcd метрики
    k8sMetrics:
      label: Метрики компонентов Kubernetes
    gatekeeper:
      buttonText: Настроить Gatekeeper
      disabled: OPA Gatekeeper не настроен.
      label: OPA Gatekeeper нарушения ограничений
      noRows: Нет ограничений с нарушениями для показа.
    nodes:
      label: Нездоровые ноды
      noRows: Нет нездоровых нод, для показа.
    componentStatus:
      etcd: Etcd
      scheduler: Планировщик
      controller-manager: Контроллер менеджер

configmap:
  tabs:
    data:
      label: Данные
      protip: Используйте эту область для всех текстовых данных UTF-8
    binaryData:
      label: Двоичные данные

containerResourceLimit:
  cpuPlaceholder: напр. 1000
  gpuPlaceholder: напр. 1
  helpText: Задайте, сколько ресурсов контейнер может потреблять по умолчанию.
  helpTextDetail: Объем ресурсов, которые контейнер может потреблять по умолчанию.
  label: Предел ресурсов контейнера по умолчанию
  limitsCpu: Лимит CPU
  limitsGpu: NVIDIA GPU Ограничение/Резервирование
  limitsMemory: Лимит памяти
  memPlaceholder: напр. 128
  requestsCpu: Резервирование CPU
  requestsMemory: Резервирование памяти


resource:
  errors:
    update: "Ошибка обновления {name}"

cruResource:
  backToForm: вернуться к форме
  backBody: Вы потеряете все изменения, внесенные в YAML.
  cancelBody: Вы потеряете все изменения, внесенные в YAML.
  confirmBack: "Окей"
  confirmCancel: "Окей"
  reviewForm: "Продолжить редактирование YAML"
  reviewYaml: "Продолжить редактирование YAML"
  previewYaml: Редактировать как YAML
  showYaml: Просмотреть как YAML

detailText:
  collapse: Скрыть
  binary: '<Двоичные данные: {n, number} байт>'
  empty: '<Пусто>'
  unsupported: '<Значение не поддерживается интерфейсом, смотрите YAML>'
  plusMore: |-
    {n, plural,
      =1 {+ 1 символ}
      other {+ {n, number} символов}
    }

drainNode:
  action: 'Освободить'
  actionStop: 'Остановить освобождение'
  titleOne: Освободить {name}
  titleMultiple: 'Освободить {count} нод'
  deleteLocalData: Удалить пустые данные директории
  force: принудительно
  safe:
    label: Безопасно
    helpText: Если узел имеет автономные поды или эфемерные данные, то он будет закрыт, но не освобожден.
  gracePeriod:
    title: Льготный период для подов, чтобы завершить себя
    default: Использовать значения указанные в pod
    placeholder: напр. 30
    custom: "Игнорировать значения по умолчанию и выдать каждому поду:"
  timeout:
    title: "Таймаут освобождения"
    default: Продолжать пытаться вечно
    placeholder: напр. 60
    custom: "Сдаваться после:"

etcdInfoBanner:
  hasLeader: "Etcd имеет лидера:"
  leaderChanges: "Количество изменений лидера:"
  failedProposals: "Количество отклоненных предложений:"

fleet:
  dashboard:
    pageTitle: Дашборд непрерывной доставки (CD)
    menuLabel: Дашборд
    welcome: Добро пожаловать Fleet Continuous Delivery
    gitOpsScale: GitOps в масштабе.
    learnMore: Изучить подробнее.
    learnMoreLink: https://fleet.rancher.io
    noRepo: "У вас нет Git Репозиториев в ваших рабочих местах"
    getStarted: Приступить к работе
    thereIsMore: |-
      {count, plural,
      =1 { Есть еще одно рабочее пространство без репозиториев}
      other { Есть еще { count } рабочих пространств без репозиториев}
      }
    expandAll: Развернуть все
    collapseAll: Свернуть все
  cluster:
    summary: Сводка ресурсов
    nonReady: Неготовые бандлы
  clusters:
    harvester: |-
      Есть {count, plural,
      =1 { 1 скрытый Harvester кластер, который не может быть использован в непрерывной доставке (CD)}
      other { # скрытых Harvester кластеров, которые не могут быть использованы в непрерывной доставке (CD)}
      }
  tokens:
    harvester: |-
      {count, plural,
      =1 {1 токен скрыт так как он относится к Harvester кластеру, который не может быть использован в непрерывной доставке (CD)}
      other {# токенов скрыто так как они относятся к Harvester кластеру, который не может быть использован в непрерывной доставке (CD)}
      }
  bundles:
    resources: Ресурсы
    harvester: |-
      {count, plural,
      =1 {1 бандл скрыт так как он относится к Harvester кластеру, который не может быть использован в непрерывной доставке (CD)}
      other {# бандлов скрыто так как они относятся к Harvester кластеру, который не может быть использован в непрерывной доставке (CD)}
      }
  fleetSummary:
    noClustersGitRepo: Этот git репозиторий не связан ни с каким кластеров
    state:
      ready: 'Готово'
      info: 'Переходит'
      warning: 'Предупреждение'
      error: 'Ошибка'
      unknown: 'Неизвестно'
      notReady: Не готово
      waitApplied: Отложено
  gitRepo:
    createLocalBanner: При развертывании Git репозитория в локальное рабочее пространство вы не сможете выбрать целевой кластер или группу кластеров
    tabs:
      resources: Ресурсы
      unready: Не готово
    auth:
      label: Аутентификация
      git: Git Аутентификация
      helm: Helm Аутентификация
    caBundle:
      label: Сертификаты
      placeholder: "Вставьте один или несколько сертификатов, начинающихся с -----BEGIN CERTIFICATE----"
    paths:
      label: Пути
      placeholder: напр. /directory/in/your/repo
      addLabel: Добавить путь
      empty: Корневой репозиторий будет использоваться по умолчанию. Чтобы использовать одну или несколько различных директорий, добавьте их здесь.
    repo:
      label: URL репозитория
      placeholder: 'напр. https://github.com/rancher/fleet-examples.git'
      addRepo: Добавить репозиторий
      noRepos: Репозитории не были добавлены
    add:
      steps:
        repoInfo:
          label: Детали репозитория
          title: Укажите Git репозиторий для добавления в fleet
          subtext: 'Добавить детали репозитория'
          description: Fleet будет постоянно отслеживать изменения в Git репозитории указанном ниже и синхронизировать содержащиеся в нем ресурсы  you configure below and synchronise the resources contained in it to the configured targets.
        targetInfo:
          label: Детали цели
          title: Укажите цель для синхронизации этого репозитория
          subtext: 'Указать детали цели'
          description: Можно настроить, какие кластеры будут использоваться в качестве цели синхронизации с ресурсами репозитория.
    ref:
      label: Отслеживать
      branch: Ветку
      revision: Ревизию
      branchLabel: Имя ветки
      branchPlaceholder: напр. master
      revisionLabel: Хэш тега или коммита
      revisionPlaceholder: напр. v1.0.0
    serviceAccount:
      label: Имя сервис аккаунта
      placeholder: "Необязательно: Использовать сервис аккаунт в целевых кластерах"
    targetNamespace:
      label: Целевое пространство имен
      placeholder: "Необязательно: Требовать, чтобы все ресурсы были в одном пространстве имен"
    target:
      selectLabel: Цель
      advanced: Расширенный
      cluster: Кластер
      clusterGroup: Группа кластера
      label: Развернуть в
      labelLocal: Развернуть с
    targetDisplay:
      advanced: Расширенный
      cluster: "Кластер"
      clusterGroup: "Группа"
      all: Все
      none: Ничего
      local: Локальный
    tls:
      label: Верификация TLS сертификата
      verify: Требовать валидный сертификат
      specify: Укажите дополнительные сертификаты, которые будут приниматься
      skip: Принимать любой сертификат (не безопасно)
    warningTooltip:
      clusterGroup: В этой группе кластеров нет ни одного кластера
      cluster: Нет доступных кластеров
    workspace:
      label: Рабочее пространство
  clusterGroup:
    selector:
      label: Выбор кластера
      matchesAll: Соответствует всем {total, number} существующим кластерам
      matchesNone: Не соответствует с существующими кластерами
      matchesSome: |-
        {matched, plural,
          =1 {Соответствует 1 из {total, number} существующих кластеров: "{sample}"}
          {Совпадает {matched, number} из {total, number} существующих кластеров, включая "{sample}"}
        }
  fdc:
    loadingChart: Загрузка данных чарта...
    renderingChart: Отрисовка чарта...
    id: ID
    type: Тип
    state: Состояние
    cluster: Кластер
    error: Ошибка
    ready: Готов
    errors: Ошибки

footer:
  docs: Документация
  download: Скачать CLI
  forums: Форумы
  issue: Создать отчет об ошибке
  slack: Slack

gatekeeperConstraint:
  match:
    title: Совпадения
  tab:
    enforcementAction:
      title: Принудительные меры
    rules:
      title: Правила
      sub:
        labelSelector:
          addLabel: Добавить лэйбл
          title: Выбор лэйбла
    namespaces:
      sub:
        excludedNamespaces: Исключенные пространства имен
        namespaces: Пространства имен
        namespaceSelector:
          addNamespace: Добавить пространство имен
          title: Выбор пространства имен
        scope:
          title: Область
      title: Пространства имен
    parameters:
      addParameter: Добавить параметр
      editAsForm: Редактировать как форму
      editAsYaml: Редактировать как YAML
      title: Параметры
  template: Шаблон
  violations:
    title: Нарушения

gatekeeperIndex:
  poweredBy: OPA Gatekeeper
  unavailable: OPA + Gatekeeper не доступен в system-charts каталоге.
  violations: Нарушения

glance:
  created: Создано
  cpu: Использование CPU
  memory: Память
  nodes:
    total:
      label: |-
        {count, plural,
          =1 { Нода }
          other { Всего нод }
        }
  pods: Поды
  provider: Провайдер
  version: Версия Kubernetes
  monitoringDashboard: Дашборд мониторинга
  installMonitoring: Установить мониторинг
  v1MonitoringInstalled: Установлен мониторинг версии 1
  clusterInfo: Информация о кластере
  eventsTable: Полный список событий

clusterBadge:
  addLabel: Добавить значок кластера
  editLabel: Изменить значок кластера
  modal:
    title: Свой значок кластера
    checkbox: Показать значок для этого кластера
    description: Свое описание
    iconText: Текст иконки
    buttonAction: Применить
    badgeBgColor: Цвет фона значка
    badgeTextColor: Цвет текста значка
    badgeAsIcon: Настроить иконку кластера
    maxCharsTooltip: До двух символов
    previewTitle: "Иконка кластера и имя представления:"

grafanaDashboard:
  failedToLoad: Ошибка при загрузке графа
  reload: Перезагрузить
  grafana: Grafana

graphOptions:
  detail: Детали
  summary: Сводка
  refresh: Обновить
  range: Диапазон

growl:
  clearAll: Очистить все оповещения
  disconnectError:
    message: "Соединение до {url} неожиданно закрылось в {time}. Отключено после {tries} попыток переподключения. Проверьте ваше подключение и перезагрузите страницу"
    title: Websocket отключены
  connectError:
    message: "Соединение до {url} неожиданно закрылось в {time}. Попытка переподключения #{tries}."
    title: Websocket переподключение
  reconnected:
    message: "Соединение до {url} было восстановлено на попытке #{tries}."
    title: Websocket переподключены

hpa:
  detail:
    currentMetrics:
      header: Текущие метрики
      noMetrics: Нет текущих метрик
    metricHeader: '{source} Метрика'
  metricIdentifier:
    name:
      label: Имя метрики
      placeholder: напр. packets-per-second
    selector:
      label: Добавить выбор
  metricTarget:
    averageVal:
      label: Среднее значение
    quantity:
      label: Количество
    type:
      label: Тип
    utilization:
      label: Среднее использование
    value:
      label: Значение
  metrics:
    headers:
      metricName: Имя
      objectKind: Вид объекта
      objectName: Имя объекта
      quantity: Количество
      resource: Имя ресурса
      targetName: Имя цели
      value: Значение
    source: Источник
  objectReference:
    api:
      label: Версия API референта
      placeholder: напр. apps/v1beta1
    kind:
      label: Тип референта
      placeholder: напр. Развертывание
    name:
      label: Имя референта
      placeholder: напр. php-apache
  tabs:
    labels: Лэйблы
    metrics: Метрики
    target: Цель
    workload: Рабочая нагрузка
  types:
    cpu: CPU
    memory: Память
  warnings:
    custom: Для использования пользовательских метрик с НРА необходимо развернуть настраиваемый сервер метрик, такой как prometheus адаптер.
    external: Для использования внешних метрик с НРА необходимо развернуть внешний сервер метрик, такой как prometheus адаптер.
    noMetric: Для использования метрик ресурсов с НРА необходимо развернуть сервер метрик.
    resource: The selected target reference does not have the correct resource requests on the spec. Without this the HPA metric will have no effect.
  workloadTab:
    current: Текущие копии
    last: Время последнего масштабирования
    max: Максимум копий
    min: Минимум копий
    targetReference: Target Reference

import:
  title: Импортировать YAML
  defaultNamespace:
    label: Пространство имен по умолчанию
  success: |-
    Применено {count, plural,
    =1 {1 Ресурс}
    other {# Ресурсов}
    }

ingress:
  certificates:
    addCertificate: Добавить сертификат
    addHost: Добавить хост
    certificate:
      label: Certificate - Secret Name
      doesntExist: The selected certificate does not exist
    defaultCertLabel: Default Ingress Controller Certificate
    headers:
      certificate: Сертификат
      hosts: Хосты
    host:
      label: Хост
      placeholder: напр. example.com
    label: Сертификаты
    removeHost: Удалить
  defaultBackend:
    label: Бэкенд по умолчанию
    noServiceSelected: Бэкенд по умолчанию не настроен.
    port:
      label: Порт
      placeholder: напр. 80 или http
      notInt: Порт должен быть числом
      required: Требуется порт
    targetService:
      label: Целевой сервис
      doesntExist: Выбранный сервис не существует
      required: Требуется целевой сервис
    warning: "Предупреждение: Бэкенд по умолчанию используется глобально для всего кластера."
  ingressClass:
    label: Класс Ingress
  rules:
    addPath: Добавить путь
    addRule: Добавить правило
    headers:
      pathType: Тип пути
      path: Путь
      port: Порт
      target: Целевой сервис
      certificates: Сертификаты
    hostname: Имя хоста
    path:
      label: Путь
      placeholder: напр. /foo
    port:
      label: Порт
      placeholder: напр. 80 или http
    removePath: Удалить
    requestHost:
      label: Запросить хост
      placeholder: напр. example.com
    target:
      label: Целевой сервис
      doesntExist: Выбранный целевой сервис не существует
    title: Правила
  rulesAndCertificates:
    title: Правила и сертификаты
    defaultCertificate: По умолчанию
  target:
    default: По умолчанию
  rulesOrBackendSpecified: Необходимо указать Бэкенд по умолчанию или Правила

internalExternalIP:
  none: Ничего

istio:
  links:
    kiali:
      label: Kiali
      description: 'Visualization of services within a service mesh and how they are connected. For Kiali to display data, you need Prometheus installed. If you need a monitoring solution, install <a tabindex="0" href="{link}">{vendor} monitoring</a>.'
    jaeger:
      label: Jaeger
      description: Monitor and Troubleshoot microservices-based distributed systems.
    disabled: '{app} не установлено'
  cni: Enabled CNI
  customOverlayFile:
    label: Custom Overlay File
    tip: 'The <a target="_blank" rel="noopener noreferrer nofollow" href="https://istio.io/latest/docs/setup/additional-setup/customize-installation/#patching-the-output-manifest">overlay file</a> allows for additional configuration on top of the base {vendor} Istio installation. You can utilize the <a href="https://istio.io/latest/docs/reference/config/istio.operator.v1alpha1/" target="_blank" rel="noopener noreferrer nofollow" >IstioOperator API</a> to make changes and additions for all components and apply those changes via this overlay YAML file.'
  description: '{vendor} Istio helm chart installs a minimal Istio configuration for you to get started integrating with your applications. If you would like to get additional information about Istio, visit <a target="_blank" href="https://istio.io/latest/docs/concepts/what-is-istio" rel="noopener noreferrer nofollow">https://istio.io/latest/docs/concepts/what-is-istio/</a>'
  destinationRule:
    title:
      new: Add Destination Rule
      edit: Edit Destination Rule
      view: "Destination Rule: {name}"
    port:
      label: Порт
      placeholder: напр. 8080 или myport
    host:
      label: Введите хост
      error: Требуется хост.
    name:
      placeholder: напр. myrule
    loadBalancer:
      title: Балансировщик нагрузки
      label: Алгоритм
      detail: Настроить алгоритмы для балансировщика нагрузки
      simple:
        label: Использовать стандартные алгоритмы балансировки нагрузки
        roundRobin:
          label: Round Robin Policy
        leastConn:
          label: Least Request Load Balancer
        random:
          label: Случайный балансировщик нагрузки
        passthrough:
          label: Passthrough
      consistentHash:
        label: Use consistent hash-based load balancing for soft session affinity
        httpHeaderName:
          label: Имя HTTP заголовка
          placeholder: напр. end-user
          error: Имя HTTP заголовка обязательное поле.
        minimumRingSize:
          label: Минимальный размер кольца
          placeholder: напр. 1024
        httpCookie:
          name:
            label: Имя Cookie
            placeholder: напр. username
            error: Имя Cookie обязательное поле.
          path:
            label: Путь Cookie
            placeholder: напр. /
          ttl:
            label: TTL
            placeholder: напр. 0s
            error: TTL обязательное поле.
        mode:
          label: Режим хеширования
          header:
            label: Хэш на основе определенного заголовка НТТР
          cookie:
            label: Хэш на основе НТТР cookie
          sourceIp:
            label: Хэш на основе исходного IP адреса
    connectionPool:
      label: Пул подключений
      detail: Настройка объема подключений к вышестоящей службе
      http1MaxPendingRequests:
        label: Максимальное кол-во ожидающих запросов HTTP1
        placeholder: напр. 1024
        help: Максимальное число ожидающих НТТР запросов к месту назначения.
      http2MaxRequests:
        label: Максимальное кол-во запросов HTTP2
        placeholder: напр. 1024
        help: Максимальное число запросов к бекенду.
      maxRequestsPerConnection:
        label: Максимальное кол-во HTTP запросов на соединение
        placeholder: напр. 10
        help: Максимальное количество запросов на подключение к бэкенду. Установка этого параметра в 1 выключает keep alive.
      maxRetries:
        label: Максимальное кол-во повторных попыток HTTP
        placeholder: e.g. 1024
        help: Максимальное число повторных попыток, которые могут быть невыполненными для всех узлов в кластере в данный момент времени.
      connectTimeout:
        label: Таймаут TCP соединения
        placeholder: напр. 30ms
        help: Таймаут TCP соединения.
      maxConnections:
        label: Максимальное кол-во TCP соединений
        placeholder: напр. 1024
        help: Максимальное число HTTP1 /TCP соединений с конечным хостом.
    outlierDetection:
      label: Outlier Detection
      detail: Configure eviction of unhealthy hosts from the load balancing pool
      baseEjectionTime:
        label: Base Ejection Time
        placeholder: напр. 30s
        help: Minimum ejection duration. A host will remain ejected for a period equal to the product of minimum ejection duration and the number of times the host has been ejected.
      consecutiveErrors:
        label: Consecutive Errors
        placeholder: напр. 5
        help: Number of errors before a host is ejected from the connection pool.
      interval:
        label: Интервал
        placeholder: напр. 10s
        help: Time interval between ejection sweep analysis.
      maxEjectionPercent:
        label: Max Ejection Percent
        placeholder: напр. 10
        help: Maximum % of hosts in the load balancing pool for the upstream service that can be ejected.
    subsets:
      label: Подмножества
      noSubsets: Нет подмножеств
      addSubsetLabel: Добавить подмножество
      removeSubsetLabel: Удалить подмножество
      name:
        label: Имя
        placeholder: напр. v1
        error: Имя подмножества обязательное поле.
      labels:
        error: Введите хотя бы один лэйбл для подмножества.
    tls:
      label: TLS
      detail: Настройка параметров TLS для подключений к вышестоящей службе
      mode:
        label: Режим TLS
        none:
          label: Ничего
        istio:
          label: Istio Mutual - Secure connections to the upstream using mutual TLS by Istio
        disable:
          label: Disable - Do not setup a TLS connection to the upstream endpoint
        simple:
          label: Simple - Originate a TLS connection to the upstream endpoint
        mutual:
          label: Mutual - Secure connections to the upstream using mutual TLS by presenting client certificates for authentication
      clientCertificate:
        label: Сертификат клиента
        placeholder: напр. /etc/certs/myclientcert.pem
        error: Сертификат клиента обязательное поле.
      privateKey:
        label: Приватный ключ
        placeholder: напр. /etc/certs/client_private_key.pem
        error: Приватный ключ обязательное поле.
      caCertificates:
        label: CA Сертификаты
        placeholder: напр. /etc/certs/rootcacerts.pem
      sni:
        label: SNI
        placeholder: напр. nginx.example.com
      subjectAltNames:
        label: Subject Alternative Names
        placeholder: напр. example.com
        add: Add Subject Alternative Name
  egressGateway: Egress Gateway включен
  ingressGateway: Ingress Gateway включен
  istiodRemote: istiodRemote включен
  kiali: Kiali включен
  pilot: Pilot включен
  policy: Policy включен
  poweredBy: Разработано <a target="_blank" rel="noopener noreferrer nofollow" href='https://istio.io/latest/'>Istio</a>
  telemetry: Телеметрия включена
  titles:
    components: Компоненты
    customAnswers: Пользовательские ответы
    advanced: Расширенные настройки
    description: Описание
  tracing: Включен Jaeger Tracing (ограниченно)
  v1Warning: Пожалуйста, удалите текущую версию Istio в <code>istio-system</code> пространстве имен перед установкой этой версии.

labels:
  addLabel: Add Label
  addSetLabel: Add/Set Label
  addTag: Add Tag
  addTaint: Add Taint
  addAnnotation: Add Annotation
  labels:
    title: Labels
    description: Key/value pairs that are attached to objects which specify identifying attributes.
    fleetClusterTooltip: Label changes are made to the Management Cluster and synchronized to the Fleet Cluster
    show: Show System Label
    hide: Hide System Label
  annotations:
    title: Annotations

landing:
  clusters:
    title: Clusters
    provider: Provider
    kubernetesVersion: Kubernetes Version
    explorer: Explorer
    explore: Explore
    cores: |-
      {count, plural,
      =1 {core}
      other {cores}}
    cpuUsed: CPU Used
    memoryUsed: Memory Used
  seeWhatsNew: Learn more about the improvements and new capabilities in this version.
  whatsNewLink: "What's new in 2.7"
  learnMore: Learn More
  support: Support
  psps: PSPs
  deprecatedPsp: Pod Security Policies are deprecated as of Kubernetes v1.21, and have been removed in Kubernetes v1.25. You have one or more PodSecurityPolicy resource(s) in this cluster.
  community:
    title: Community Support
    docs: Docs
    forums: Forums
  commercial:
    title: Commercial Support
    body: Learn about commercial support
  landingPrefs:
    title: You can change what you see when you login via preferences
    userPrefs: Preferences
    body: "You can change where you land when you login"
    options:
      homePage: Take me to the home page
      lastVisited: Take me to the area I last visited
      custom: "Take me to cluster:"
  welcomeToRancher: 'Welcome to {vendor}'

logging:
  clusterFlow:
    noOutputsBanner: There are no cluster outputs in the selected namespace.
  flow:
    clusterOutputs:
      doesntExistTooltip: This cluster output doesn't exist
      label: Cluster Outputs
    matches:
      banner: Configure which container logs will be pulled from
      unsupportedConfig: This resource contains a match configuration that the form editor does not support. Please use YAML edit.
      label: Matches
      addSelect: Add Include Rule
      addExclude: Add Exclude Rule
      pods:
        title:
          include: Include Pods
          exclude: Exclude Pods
        keyLabel: Pod Label Key
        valueLabel: Pod Label Value
        addLabel: Add Pod
      nodes:
        title:
          include: Limit to specific nodes
          exclude: Exclude specific nodes
        placeholder: "Default: Any node"
      containerNames:
        title:
          include: Limit to specific container names
          exclude: Exclude specific container names
        placeholder: "Default: Any container"
      namespaces:
        title:
          include: Limit to specific namespaces
          exclude: Exclude specific namespaces
        placeholder: "Default: Any namespace"

    filters:
      label: Filters
    outputs:
      doesntExistTooltip: This output doesn't exist
      sameNamespaceError: Output must reside in same namespace as the flow.
      label: Outputs
  install:
    k3sContainerEngine: K3S Container Engine
    enableAdditionalLoggingSources: Enable enhanced cloud provider logging
    dockerRootDirectory: Docker Root Directory
    systemdLogPath: systemd Log Path
    tooltip: 'Some kubernetes distributions log to <code>journald</code>. In order to collect these logs the <code>systemdLogPath</code> needs to be defined. While the <code>/run/log/journal</code> directory is used by default, some Linux distributions do not default to this path.'
    url: '<a href="https://rancher.com/docs/rancher/v2.6/en/logging/helm-chart-options/" target="_blank" rel="noopener nofollow noreferrer">Learn more</a>'
    default: /run/log/journal
  elasticsearch:
    host: Host
    scheme: Scheme
    port: Port
    indexName: Index Name
    user: User
    password: Password from Secret
    caFile:
      label: CA File from Secret
    clientCert:
      label: Client Cert from Secret
      placeholder: Paste in the CA certificate
    clientKey:
      label: Client Key from Secret
      placeholder: Paste in the client key
    clientKeyPass: Client Key Pass from Secret
    verifySsl: Verify SSL
    sslVersion: SSL Version
  redis:
    host: Host
    port: Port
    dbNumber: Redis database number
    ttl: TTL for each key
    password: Password from Secret
    format:
      title: Format
      type: Type
  gelf:
    host: Host
    port: Port
    protocol: Protocol
    tls: Enable TLS
    tlsOptions:
      clientCert: Client Cert
      clientKey: Client Cert Key
      allCiphers: Allow any ciphers to be used
      tlsVersion: TLS version
      noVerify: Skip TLS verification
  kafka:
    brokers: Brokers
    defaultTopic: Default Topic
    saslOverSsl: SASL Over SSL
    scramMechanism: Scram Mechanism
    username: Username from Secret
    password: Password from Secret
    sslCaCert:
      label: CA Cert from Secret
      placeholder: Paste in the CA certificate
    sslClientCert:
      label: Cert from Secret
      placeholder: Paste in the client cert
    sslClientCertChain:
      label: Cert Chain from Secret
      placeholder: Paste in the client cert chain
    sslClientCertKey: Cert Key from Secret
  loki:
    url: URL
    tenant: Tenant
    username: User from Secret
    password: Password from Secret
    configureKubernetesLabels: Configure Kubernetes metadata in a Prometheus like format
    extractKubernetesLabels: Extract Kubernetes labels as Loki labels
    dropSingleKey: If a record only has 1 key, then just set the log line to the value and discard the key
    caCert: CA Cert from Secret
    cert: Cert from Secret
    key: Key from Secret
  awsElasticsearch:
    url: URL
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
  azurestorage:
    storageAccount: Account from Secret
    accessKey:  Access Key from Secret
    container: Container
    path: Path
    storeAs: Store As
  cloudwatch:
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
    endpoint: Endpoint
    region: Region
    logGroupName: Log Group Name
    logStreamName: Log Stream Name
  datadog:
    apiKey: API Key from Secret
    useSSL: Use SSL
    useCompression: Use Compression
    host: Host
  file:
    path: Path
  gcs:
    project: Project
    credentialsJson: Credentials from Secret
    bucket: Bucket
    path: Path
    overwriteExistingPath: Overwrite Existing Path
  kinesisStream:
    streamName: Stream Name
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
  logdna:
    apiKey: API Key
    hostname: Hostname
    app: App
  logz:
    url: URL
    port: Port
    token: Api Token from Secret
    enableCompression: Enable Compression
  newrelic:
    apiKey: API Key from Secret
    licenseKey: License Key from Secret
    baseURI: Base URI
  sumologic:
    endpoint: Endpoint from Secret
    sourceName: Source Name
  syslog:
    host: Host
    port: Port
    transport: Transport
    insecure: insecure
    trustedCaPath: CA Path from Secret
    format:
      title: Format
      type: Type
      addNewLine: Add New Line
      messageKey: Message Key
    buffer:
      title: Buffer
      tags: Tags
      chunkLimitSize: Chunk Limit Size
      chunkLimitRecords: Chunk Limit chunkLimitRecords
      totalLimitSize: Total Limit Size
      flushInterval: Flush Interval
      timekey: Timekey
      timekeyWait: Timekey Wait
      timekeyUseUTC: Timekey Use UTC
  s3:
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
    endpoint: Endpoint
    bucket: Bucket
    path: Path
    overwriteExistingPath: Overwrite Existing Path
  output:
    buffer:
      label: Output Buffer
    selectOutputs: Select Outputs
    selectBanner: Select to configure an output
    sections:
      target: Target
      access: Access
      certificate: Connection
      labels: Labels
      configuration: Configuration
  outputProviders:
    elasticsearch: Elasticsearch
    opensearch: OpenSearch
    redis: Redis
    splunkHec: Splunk
    kafka: Kafka
    forward: Fluentd
    gelf: GELF
    loki: Loki
    awsElasticsearch: Amazon Elasticsearch
    azurestorage: Azure Storage
    cloudwatch: Cloudwatch
    datadog: Datadog
    file: File
    gcs: GCS
    kinesisStream: Kinesis Stream
    logdna: LogDNA
    logz: LogZ
    newrelic: New Relic
    sumologic: SumoLogic
    syslog: Syslog
    s3: S3
    unknown: Unknown
  overview:
    poweredBy: Banzai Cloud
    clusterLevel: Cluster-Level
    namespaceLevel: Namespace-Level
  provider: Provider
  splunk:
    host: Host
    port: Port
    protocol: Protocol
    index: Index
    token: Token from Secret
    insecureSsl: Insecure SSL
    indexName: Index Name
    source: Source
    caFile: CA File from Secret
    caPath: CA Path from Secret
    clientCert: Client Cert from Secret
    clientKey: Client Key from Secret
  forward:
    host: Host
    port: Port
    sharedKey: Shared Key from Secret
    username: Username from Secret
    password: Password from Secret
    clientCertPath: Client Cert Path from Secret
    clientPrivateKeyPath: Client Private Key Path from Secret
    clientPrivateKeyPassphrase: Client Private Key Passphrase from Secret

longhorn:
  overview:
    title: Overview
    subtitle: "Powered By: <a href='https://github.com/longhorn' target='_blank' rel='noopener nofollow noreferrer'>Longhorn</a>"
    linkedList:
      longhorn:
        label: 'Longhorn'
        description: 'Manage storage system via UI'
        na: Resource Unavailable

neuvector:
  overview:
    title: Overview
    subtitle: "Powered by: <a href='https://github.com/neuvector' target='_blank' rel='noopener nofollow noreferrer'>NeuVector</a>"
    linkedList:
      neuvector:
        label: 'NeuVector'
        description: 'Full Lifecycle Container Security'
        na: Resource Unavailable

login:
  howdy: Howdy!
  welcome: Welcome to {vendor}
  loggedOut: You have been logged out.
  loginAgain: Log in again to continue.
  serverError:
    authFailedCreds: "Logging in failed: Check credentials, or your account may not be authorized to log in."
    authFailed: "Logging in failed: Your account may not be authorized to log in."
    unknown: "An unknown error occurred while attempting to login. Please contact your system administrator."
    invalidSamlAttrs: "Invalid saml attributes"
    noResponse: "No response received"
  error: An error occurred logging in. Please try again.
  clientError: Invalid username or password. Please try again.
  useLocal: Use a local user
  loginWithProvider: Log in with {provider}
  username: Username
  password: Password
  loggingIn: Logging in...
  loggedIn: Logged in
  loginWithLocal: Log in with Local User
  useProvider: Use a {provider} user
  useNonLocal: Use a non-local user
  remember:
    label: Remember Username

managementNode:
  customName: Custom Name

members:
  clusterMembers: Cluster Members
  clusterAndProject: Cluster and Project Members
  createActionLabel: Add
  clusterPermissions:
    noDescription: User created - no description
    label: Cluster Permissions
    description: Controls what access users have to the Cluster
    createProjects: Create Projects
    manageClusterBackups: Manage Cluster Backups
    manageClusterCatalogs: Manage Cluster Catalogs
    manageClusterMembers: Manage Cluster Members
    manageNavlinks: Manage Navlinks
    manageNodes: Manage Nodes
    manageStorage: Manage Storage
    viewAllProjects: View All Projects
    viewClusterCatalogs: View Cluster Catalogs
    viewClusterMembers: View Cluster Members
    viewNodes: View Nodes
    owner:
      label: Owner
      description: Owners have full control over the Cluster and all resources inside it.
    member:
      label: Member
      description: Members can manage the resources inside the Cluster but not change the Cluster itself.
    custom:
      label: Custom
      description: Choose individual roles for this user.
  localClusterWarning: "Caution: This is the cluster that Rancher is using as a data store. Only administrators should be given write access to this cluster. Users with write access to this cluster can use it to grant themselves access to any part of this installation."
  noRolesAssigned: There are no users assigned to this project.

membershipEditor:
  label: Members
  user: User
  role: Role

monitoring:
  accessModes:
    many: ReadWriteMany
    once: ReadWriteOnce
    readOnlyMany: ReadOnlyMany
  aggregateDefaultRoles:
    label: Aggregate to Default Kubernetes Roles
    tip: 'Adds labels to the ClusterRoles deployed by the Monitoring chart to <a target="_blank" rel="noopener nofollow noreferrer" href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles"> aggregate to the corresponding default k8s admin, edit, and view ClusterRoles.</a>'
  alerting:
    config:
      label: Alert Manager Config
    enable:
      label: Deploy Alertmanager
    secrets:
      additional:
        info: Secrets should be mounted at <pre class='inline-block m-0'>/etc/alertmanager/secrets/</pre>
        label: Additional Secrets
      existing: Choose an existing config secret
      info: |
        <span class="text-bold">Create default config</span>: A Secret containing your Alertmanager Config will be created in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace on deploying this chart under the name <pre class='inline-block m-0'>alertmanager-rancher-monitoring-alertmanager</pre>. By default, this Secret will never be modified on an uninstall or upgrade of this chart. <br />
        Once you have deployed this chart, you should edit the Secret via the UI in order to add your custom notification configurations that will be used by Alertmanager to send alerts. <br /> <br />
        <span class="text-bold">Choose an existing config secret</span>: You must specify a Secret that exists in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace. If the namespace does not exist, you will not be able to select an existing secret.
      label: Alertmanager Secret
      new: Create default config
      radio:
        label: Config Secret
    templates:
      keyLabel: File Name
      label: Template Files
      valueLabel: YAML Template
    title: Configure Alertmanager
  clusterType:
    label: Cluster Type
    placeholder: Select cluster type
  createDefaultRoles:
    label: Create Default Monitoring Cluster Roles
    tip: 'Creates <code>monitoring-admin</code>, <code>monitoring-edit</code>, and <code>monitoring-view</code> ClusterRoles that can be assigned to users to provide permissions to CRDs installed by the Monitoring chart.'
  etcdNodeDirectory:
    label: etcd Node Certificate Directory
    tooltip: 'For clusters that use RancherOS for the etcd nodes, this option should be set to <pre class=''inline-block m-0''>/opt/rke/etc/kubernetes/ssl</pre>. Hybrid environments that require specifying multiple certificate directories (e.g. an etcd plane composed of both RancherOS and Ubuntu hosts) are not supported.'
  grafana:
    storage:
      annotations: PVC Annotations
      className: Storage Class Name
      existingClaim: Use Existing Claim
      finalizers: PVC Finalizers
      label: Grafana Storage
      mode: Access Mode
      selector: Selector
      size: Size
      subpath: Use Subpath
      type: Persistent Storage Types
      types:
        existing: Enable With Existing PVC
        statefulset: Enable with StatefulSet Template
        template: Enable with PVC Template
      volumeName: Volume Name
    title: Configure Grafana
  hostNetwork:
    label: Use Host Network For Prometheus Operator
    tip: If you are using a managed Kubernetes cluster with custom CNI (e.g. Calico), you must enable this option to allow a managed control plane to contact the admission webhook exposed by Prometheus Operator to mutate or validate incoming PrometheusRules.
  overview:
    alertsList:
      ends:
        label: Ends At
      label: Active Alerts
      message:
        label: Message
      severity:
        label: Severity
      start:
        label: Starts At
    linkedList:
      alertManager:
        description: Active Alerts
        label: Alertmanager
      grafana:
        description: Metrics Dashboards
        label: Grafana
      na: Resource Unavailable
      prometheusPromQl:
        description: PromQL Graph
        label: Prometheus Graph
      prometheusRules:
        description: Configured Rules
        label: PrometheusRules
      prometheusTargets:
        description: Configured Targets
        label: Prometheus Targets
    subtitle: 'Powered By: <a href="https://github.com/coreos/prometheus-operator" target="_blank" rel="noopener noreferrer nofollow">Prometheus</a>'
    title: Dashboard
  prometheus:
    config:
      adminApi: Admin API
      evaluation: Evaluation Interval
      ignoreNamespaceSelectors:
        help: 'Ignoring Namespace Selectors allows Cluster Admins to limit teams from monitoring resources outside of namespaces they have permissions to but can break the functionality of Apps that rely on setting up Monitors that scrape targets across multiple namespaces, such as Istio.'
        label: Namespace Selectors
        radio:
          enforced: 'Use: Monitors can access resources based on namespaces that match the namespace selector field'
          ignored: 'Ignore: Monitors can only access resources in the namespace they are deployed in'
      limits:
        cpu: CPU Limit
        memory: Memory Limit
      requests:
        cpu: Requested CPU
        memory: Requested Memory
      resourceLimits: Resource Limits
      retention: Retention
      retentionSize: Retention Size
      scrape: Scrape Interval
    storage:
      className: Storage Class Name
      label: Persistent Storage for Prometheus
      mode: Access Mode
      selector: Selector
      selectorWarning: 'If you are using a dynamic provisioner (e.g. Longhorn), no Selectors should be specified since a PVC with a non-empty selector can''t have a PV dynamically provisioned for it.'
      size: Size
      volumeName: Volume Name
    title: Configure Prometheus
    warningInstalled: |
      Warning: Prometheus Operators are currently deployed. Deploying multiple Prometheus Operators onto one cluster is not currently supported. Please remove all other Prometheus Operator deployments from this cluster before trying to install this chart.
      If you are migrating from an older version of {vendor} with Monitoring enabled, please disable Monitoring on this cluster completely before attempting to install this chart.
  receiver:
    addReceiver: Add Receiver
    fields:
      name: Name
    tls:
      label: SSL
      caFilePath:
        label: CA File Path
        placeholder: e.g. ./ca-file.csr
      certFilePath:
        label: Cert File Path
        placeholder: e.g. ./cert-file.crt
      keyFilePath:
        label: Key File Path
        placeholder: e.g. ./key-file.pfx
      secretsBanner: The file paths below must be referenced in <pre class="inline-block m-0 p-0 vertical-middle">alertmanager.alertmanagerSpec.secrets</pre> when deploying the Monitoring chart. For more information see our <a href="{docsBase}/pages-for-subheaders/monitoring-v2-configuration" target="_blank" rel="noopener noreferrer nofollow">documentation</a>.
  projectMonitoring:
    detail:
      error: "Unable to fetch Dashboard values with status: "
    list:
      banner: Project Monitoring Configuration is stored in ProjectHelmChart resources
      empty:
        message: Project Monitoring has not been configured for any projects
        canCreate: Get started by clicking Create to add monitoring to a project
        cannotCreate: Contact the admin to add project monitoring
  route:
    label: Route
    fields:
      groupBy: Group By
      groupInterval: Group Interval
      groupWait: Group Wait
      receiver: Receiver
      repeatInterval: Repeat Interval
  routesAndReceivers: Routes and Receivers (Deprecated)
  monitors: Monitors
  projectMonitors: Project Monitoring
  alertmanagerConfig:
    description: Routes and receivers for project alerting and cluster alerting are configured within AlertmanagerConfig resources.
    empty: Alerts have not been configured for any accessible namespaces.
    getStarted: Get started by clicking Create to configure an alert.
    receiverTooltip: This route will direct alerts to the selected receiver, which must be defined in the same AlertmanagerConfig.
    deprecationWarning: The Route and Receiver resources are deprecated. Going forward, routes and receivers should not be managed as separate Kubernetes resources on this page. They should be configured as YAML fields in an AlertmanagerConfig resource.
    routeInfo: This form supports configuring one route that directs traffic to a receiver. Alerts can be directed to more receiver(s) by configuring child routes in YAML.
    receiverFormNames:
      create: Create Receiver in AlertmanagerConfig
      edit: Edit Receiver in AlertmanagerConfig
      editYaml: Edit AlertmanagerConfig
      detail: Receiver in AlertmanagerConfig
    disabledReceiverButton: The receiver form is available after the AlertmanagerConfig is created
    email:
      username: Auth Username
      password: Secret with Auth Password
    slack:
      apiUrl: Secret with Slack Webhook URL
    pagerDuty:
      routingKey: Secret with Routing Key
      serviceKey: Secret with Service Key
    opsgenie:
      apiKey: Secret with API Key
    webhook:
      url: URL
      urlSecret: URL Secret
      urlSecretTooltip: 'urlSecret takes precedence over url. One of urlSecret and url should be defined.'
    auth:
      bearerTokenSecret: Bearer Token Secret
      basicAuthUsername: Secret with Basic Auth Username
      basicAuthPassword: Secret with Basic Auth Password
  installSteps:
    uninstallV1:
      stepTitle: Uninstall V1
      stepSubtext: Uninstall Previous Monitoring
      warning1: V1 Monitoring is currently deployed. This needs to be uninstalled before V2 monitoring can be installed.
      warning2: <a target="blank" href="https://ranchermanager.docs.rancher.com/v2.6/how-to-guides/advanced-user-guides/monitoring-alerting-guides/migrate-to-rancher-v2.5+-monitoring#migrating-from-monitoring-v1-to-monitoring-v2" target='_blank' rel='noopener nofollow'>Learn more</a> about the migration steps to V2 Monitoring.
      promptDescription: <div class="mt-20 mb-20">You are attempting to uninstall V1 Monitoring. Please ensure you have read the migration steps.</div>
      success1: V1 monitoring successfully uninstalled.
      success2: Press Next to continue
  tabs:
    alerting: Alerting
    general: General
    grafana: Grafana
    prometheus: Prometheus
    projectMetrics: Project Metrics
  v1Warning: 'Monitoring is currently deployed from Cluster Manager. If you are migrating from an older version of {vendor} with monitoring enabled, please disable monitoring in Cluster Manager before attempting to install the new {vendor} Monitoring chart in Cluster Explorer.'

monitoringReceiver:
  addButton: Add {type}
  custom:
    label: Custom
    title: Custom Config
    info: The YAML provided here will be directly appended to your receiver within the Alertmanager Config Secret.
  email:
    label: Email
    title: Email Config
  opsgenie:
    label: Opsgenie
    title: Opsgenie Config
  pagerduty:
    label: PagerDuty
    title: PagerDuty Config
    info: "You can find additional info on creating an Integration Key for PagerDuty <a href='https://www.pagerduty.com/docs/guides/prometheus-integration-guide/' target='_blank' rel='noopener nofollow' class='flex-right'>here</a>."
  slack:
    label: Slack
    title: Slack Config
    info: "You can find additional info on creating Incoming Webhooks for Slack <a href='https://rancher.slack.com/apps/A0F7XDUAZ-incoming-webhooks' target='_blank' rel='noopener noreferrer nofollow'>here</a> ."
  webhook:
    label: Webhook
    title: Webhook Config
    urlTooltip: For some webhooks this a url that points to the service DNS
    modifyNamespace: If <pre class="inline-block m-0 p-0 vertical-middle">rancher-alerting-drivers</pre> default values were changed, please update the url below in the format http://&lt;new_service_name&gt;.&lt;new_namespace&gt.svc.&lt;port&gt/&lt;path&gt
    banner: To use MS Teams or SMS you will need to have at least one instance of <pre class="inline-block m-0 p-0 vertical-middle">rancher-alerting-drivers</pre> installed first.
    add:
      selectWebhookType: Select Webhook Type
      generic: Generic
      msTeams: MS Teams
      alibabaCloudSms: SMS
  auth:
    label: Auth
    authType: Auth Type
    username: Username
    password: Password
    none:
      label: None
    bearerToken:
      label: Bearer Token
      placeholder: e.g. secret-token
    basicAuth:
      label: Basic Auth
    bearerTokenFile:
      label: Bearer Token File
      placeholder: e.g. ./user_token
  tls:
    ca: Secret with CA
    cert: Secret with Client Cert
    key: Secret with Client Key
    serverName: Server Name
    serverNameTooltip: Used to verify the hostname for the targets.
  shared:
    proxyUrl:
      label: Proxy URL
      placeholder: e.g. http://my-proxy/
    sendResolved:
      label: Enable send resolved alerts

alertmanagerConfigReceiver:
  secretKeyId: Key Id from Secret
  name: Receiver Name
  addButton: Add Receiver
  receivers: Receivers
  namespaceWarning: Could not render the secret selector because no namespace was found to get secrets from.
  receiverTypes: "The following receiver types can be edited in forms: Email, Slack, PagerDuty, Opsgenie and Webhook. For other receiver types, edit the AlertmanagerConfig YAML."
  slack:
    webhookUrl: Webhook URL
    apiUrlTooltip: The secret's key that contains the Slack webhook URL. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
monitoringRoute:
  groups:
    label: Group By
    addGroupByLabel: Labels to Group Alerts By
    groupByTooltip: Add each label as a string in the format key:value. The special label ... will aggregate by all possible labels. If provided, the ... must be the only element in the list.
  info: This is the top-level Route used by Alertmanager as the default destination for any Alerts that do not match any other Routes. This Route must exist and cannot be deleted.
  interval:
    label: Group Interval
  matching:
    info: The root route has to match everything so matching cannot be configured.
    label: Match
    addMatcher: Add Matcher
    matchType: Match Type
    name: Name
    nameTooltip: Label to match
    value: Value
    valueTooltip: Label value to match
  receiver:
    type: Receiver Type
    add: Add Receiver
    label: Receiver
    oneOrMoreLabel: One or More Receivers
    addMatch: Add match
  regex:
    label: Match Regex
  repeatInterval:
    label: Repeat Interval
  wait:
    label: Group Wait

moveModal:
  title: Move to a new project?
  description: 'You are moving the following namespaces:'
  moveButtonLabel: Move
  targetProject: Target Project

nameNsDescription:
  name:
    label: Name
    placeholder: 'A unique name'
  namespace:
    label: Namespace
    placeholder: ''
  workspace:
    label: Workspace
    placeholder:
  description:
    label: Description
    placeholder: Any text you want that better describes this resource

namespace:
  containerResourceLimit: Container Resource Limit
  resourceQuotas: Resource Quotas
  project:
    label: Project
  resources: Resources
  enableAutoInjection: Enable Istio Auto Injection
  disableAutoInjection: Disable Istio Auto Injection
  move: Move
  total: Total
  workloads: Workloads
  label: Namespace
  selectNamespace: Select Namespace
  createNamespace: Create a New Namespace
  selectOrCreate: Select or Create a Namespace
  resourceStates:
    success: 'Active'
    info: 'Transitioning'
    warning: 'Warning'
    error: 'Error'
    unknown: 'Unknown'
    paused:
      stateName: 'Inactive'
      shortDescription: Deployment is paused
      longDescription: Deployment is paused. Pausing stops the controller from deploying revisions.

namespaceFilter:
  noMatchingOptions: No matching options
  more: "+{more}"
  selected:
    label: |-
      {total, plural,
      one {1 item selected}
      other {{total} items selected}
      }

namespaceList:
  selectLabel: Namespace
  addLabel: Add Namespace

navLink:
  name:
    label: Name
    placeholder: 'e.g. foo-bar'
  label:
    label: Display name
    placeholder: 'Text displayed for the link'
  tabs:
    link:
      label: Link type
      type:
        label: Link type
        service: Link to service
        url: Link to URL
      toURL:
        label: Destination URL
        placeholder: 'e.g. https://rancher.com'
      toService:
        service:
          label: Service (namespace/name)
          placeholder: 'e.g. cattle-system/rancher-webhook'
        path:
          label: Path
          placeholder: 'e.g. proxy/?orgId=1'
        port:
          label: Port
          placeholder: 'e.g. 80'
        scheme:
          label: Scheme
          placeholder: 'e.g. http'
    target:
      label: Window target
      option:
        blank: New window
        self: Replace window
        named: Custom named window
      namedValue:
        label: Window name
    group:
      label: Group
      group:
        label: Group name
        tooltip: Assign link to a group
      sideLabel:
        label: Link Label
      description:
        label: Link description
      iconSrc:
        label: Add image
networkpolicy:
  egress:
    label: Egress Rules
    enable: Configure egress rules to restrict outgoing traffic
    ruleLabel: Targets
    ruleHint: Outgoing traffic is only allowed to the configured targets
    portHint: Outgoing traffic is only allowed to connect to the configured ports
  ingress:
    label: Ingress Rules
    enable: Configure ingress rules to restrict incoming traffic
    ruleLabel: Sources
    ruleHint: Incoming traffic is only allowed from the configured sources
    portHint: Incoming traffic is only allowed to connect to the configured ports
  labelsAnnotations:
    label: Labels & Annotations
  rules:
    ruleLabel: Rule {index}
    addPort: Add allowed port
    type: Rule type
    ingress:
      add: Add allowed traffic source
    egress:
      add: Add allowed traffic target
    ports:
      label: Allowed ports
      port:
        label: Port
        placeholder: e.g. 8080
      protocol: Protocol
    ipBlock:
      label: IP block
      exceptions: Exceptions
      cidr:
        label: CIDR
        placeholder: e.g. 1.1.1.0/24
      addExcept: Add exception
      invalidCidr: "Invalid CIDR"
      invalidExceptionCidrs: "Invalid Exceptions: "
    podSelector:
      label: Pod Selector
    namespaceSelector:
      label: Namespace Selector
  config:
    label: Configuration
  selectors:
    label: Selectors
    hint: The NetworkPolicy is applied to the selected Pods
    matchingPods:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} pods}
          =1 {Matches 1 of {total, number} pods: "{sample}"}
          other {Matches {matched, number} of {total, number} existing pods, including "{sample}"}
        }
    matchingNamespaces:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} namespaces}
          =1 {Matches 1 of {total, number} namespaces: "{sample}"}
          other {Matches {matched, number} of {total, number} existing namespaces, including "{sample}"}
        }
node:
  list:
    pool: Pool
    noNodes: This pool is empty
    nodeTaint: Taints
    scaleDown: Scale Pool Down
    scaleUp: Scale Pool Up
    poolDescription:
      noSize: No Size
      noLocation: No Location
  detail:
    detailTop:
      containerRuntime: Container Runtime
      internalIP: Internal IP
      externalIP: External IP
      os: OS
      version: Version
    glance:
      consumptionGauge:
        used: Used
        amount: "{used} of {total} {unit}"
        cpu: CPU
        memory: MEMORY
        pods: PODS
      diskPressure: Disk Pressure
      kubelet: kubelet
      memoryPressure: Memory Pressure
      pidPressure: PID Pressure
    tab:
      conditions: Conditions
      images: Images
      metrics: Metrics
      info:
        label: Info
        key:
          architecture: Architecture
          bootID: Boot ID
          containerRuntimeVersion: Container Runtime Version
          kernelVersion: Kernel Version
          kubeProxyVersion: Kube Proxy Version
          kubeletVersion: Kubelet Version
          machineID: Machine ID
          operatingSystem: Operating System
          osImage: Image
          systemUUID: System UUID
      pods: Pods
      taints: Taints
  actions:
    downloadSSHKey: Download SSH Key
    downloadNodeConfig: Download Keys
    scaleDown: Scale Down
    forceDelete: Force Delete

persistentVolume:
  pluginConfiguration:
    label: Plugin configuration
  plugin:
    label: Volume Plugin
    inTree: in-tree plugin
    unsupported: (Unsupported)
  capacity:
    label: Capacity
  customize:
    label: Customize
    affinity:
      label: Node Selectors
      addLabel: Add Node Selector
    assignToStorageClass:
      label: Assign to Storage Class
    mountOptions:
      label: Mount Options
      addLabel: Add Option
    accessModes:
      label: Access Modes
      readWriteOnce: Single Node Read-Write
      readOnlyMany: Many Nodes Read-Only
      readWriteMany: Many Nodes Read-Write
  shared:
    partition:
      label: Partition
      placeholder: e.g. 1; 0 for entire device
    readOnly:
      label: Read Only
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    secretName:
      label: Secret Name
      placeholder: e.g. secret
    secretNamespace:
      label: Secret Namespace
      placeholder: e.g. default
    monitors:
      add: Add Monitor
  vsphereVolume:
    label: VMWare vSphere Volume
    volumePath:
      label: Volume Path
      placeholder: e.g. /
    storagePolicyName:
      label: Storage Policy Name
      placeholder: e.g. sp
    storagePolicyId:
      label: Storage Policy ID
      placeholder: e.g. sp1
  csi:
    label: CSI (Unsupported)
    suffix: (CSI)
    driver:
      label: Driver
      placeholder: e.g. driver.longhorn.io
    volumeHandle:
      label: Volume Handle
      placeholder: e.g. pvc-xxxx
    volumeAttributes:
      add: Add Volume Attribute
    nodePublishSecretName:
      label: Node Publish Secret Name
      placeholder: e.g. secret
    nodePublishSecretNamespace:
      label: Node Publish Secret Namespace
      placeholder: e.g. default
    nodeStageSecretName:
      label: Node Stage Secret Name
      placeholder: e.g. secret
    nodeStageSecretNamespace:
      label: Node Stage Secret Namespace
      placeholder: e.g. default
    controllerExpandSecretName:
      label: Controller Expand Secret Name
      placeholder: e.g. secret
    controllerExpandSecretNamespace:
      label: Controller Expand Secret Namespace
      placeholder: e.g. default
    controllerPublishSecretName:
      label: Controller Publish Secret Name
      placeholder: e.g. secret
    controllerPublishSecretNamespace:
      label: Controller Publish Secret Namespace
      placeholder: e.g. default
    drivers:
      disk-csi-azure-com: Azure Disk (CSI)
      file-csi-azure-com: Azure File (CSI)
      driver-longhorn-io: Longhorn (CSI)
      driver-harvesterhci-io: Harvester (CSI)
      nfs-csi-k8s-io: NFS (CSI)
      ebs-csi-aws-com: AWS Elastic Block Store (CSI)
      rbd-csi-ceph-com: Ceph RBD (CSI)
      org-gluster-glusterfs: GlusterFS (CSI)
      pd-csi-storage-gke-io: GCE Persistent Disk (CSI)
      cinder-csi-openstack-org: Cinder (CSI)
      pxd-portworx-com: Portworx (CSI)
      quobyte-csi: Quobyte (CSI)
      storageos: StorageOS (CSI)
      csi-vsphere-vmware-com: vSphere (CSI)
  cephfs:
    label: Ceph Filesystem (Unsupported)
    path:
      label: Path
      placeholder: e.g. /var
    user:
      label: User
      placeholder: e.g. root
    secretFile:
      label: Secret File
      placeholder: e.g. secret
  rbd:
    label: Ceph RBD (Unsupported)
    user:
      label: User
      placeholder: e.g. root
    keyRing:
      label: Key Ring
      placeholder: e.g. /etc/ceph/keyring
    pool:
      label: Pool
      placeholder: e.g. rbd
    image:
      label: Image
      placeholder: e.g. image
  fc:
    label: Fibre Channel (Unsupported)
    targetWWNS:
      add: Add Target WWN
    wwids:
      add: Add WWID
    lun:
      label: Lun
      placeholder: e.g. 2
  flexVolume:
    label: Flex Volume (Unsupported)
    driver:
      label: Driver
      placeholder: e.g. driver
    options:
      add: Add Option
  flocker:
    label: Flocker (Unsupported)
    datasetName:
      label: Dataset Name
      placeholder: e.g. dataset
    datasetUUID:
      label: Dataset UUID
      placeholder: e.g. uuid
  glusterfs:
    label: Gluster Volume (Unsupported)
    endpoints:
      label: Endpoints
      placeholder: e.g. glusterfs-cluster
    path:
      label: Path
      placeholder: e.g. kube-vol
  iscsi:
    label: iSCSI Target (Unsupported)
    initiatorName:
      label: Initiator Name
      placeholder: iqn.1994-05.com.redhat:1df7a24fcb92
    iscsiInterface:
      label: iSCSI Interface
      placeholder: e.g. interface
    chapAuthDiscovery:
      label: Chap Auth Discovery
    chapAuthSession:
      label: Chap Auth Session
    iqn:
      label: IQN
      placeholder: iqn.2001-04.com.example:storage.kube.sys1.xyz
    lun:
      label: Lun
      placeholder: e.g. 2
    targetPortal:
      label: Target Portal
      placeholder: e.g. portal
    portals:
      add: Add Portal
  cinder:
    label: Openstack Cinder Volume (Unsupported)
    volumeId:
      label: Volume ID
      placeholder: e.g. vol
  quobyte:
    label: Quobyte Volume (Unsupported)
    volume:
      label: Volume
      placeholder: e.g. vol
    user:
      label: User
      placeholder: e.g. root
    group:
      label: Group
      placeholder: e.g. abc
    registry:
      label: Registry
      placeholder: e.g. abc
  photonPersistentDisk:
    label: Photon Volume (Unsupported)
    pdId:
      label: PD ID
      placeholder: e.g. abc
  portworxVolume:
    label: Portworx Volume (Unsupported)
    volumeId:
      label: Volume ID
      placeholder: e.g. abc
  scaleIO:
    label: ScaleIO Volume (Unsupported)
    volumeName:
      label: Volume Name
      placeholder: e.g. vol-0
    gateway:
      label: Gateway
      placeholder: e.g. https://localhost:443/api
    protectionDomain:
      label: Protection Domain
      placeholder: e.g. pd01
    storageMode:
      label: Storage Mode
      placeholder: e.g. ThinProvisioned
    storagePool:
      label: Storage Pool
      placeholder: e.g. sp01
    system:
      label: System
      placeholder: e.g. scaleio
    sslEnabled:
      label: SSL Enabled
  storageos:
    label: StorageOS (Unsupported)
    volumeName:
      label: Volume Name
      placeholder: e.g. vol
    volumeNamespace:
      label: Volume Namespace
      placeholder: e.g. default
  nfs:
    label: NFS Share
    path:
      label: Path
      placeholder: e.g. /var
    server:
      label: Server
      placeholder: e.g. 10.244.1.4
  longhorn:
    label: Longhorn
    volumeHandle:
      label: Volume Handle
      placeholder: e.g. pvc-xxxx
    options:
      label: Options
      addLabel: Add
  local:
    label: Local
    path:
      label: Path
      placeholder: e.g. /mnt/disks/ssd1
  hostPath:
    label: HostPath
    pathOnTheNode:
      label: Path on the Node
      placeholder: /mnt/disks/ssd1
    mustBe:
      label: The Path on the Node must be
      anything: 'Anything: do not check the target path'
      directory: A directory, or create if it does not exist
      file: A file, or create if it does not exist
      existingDirectory: An existing directory
      existingFile: An existing file
      existingSocket: An existing socket
      existingCharacter: An existing character device
      existingBlock: An existing block device
  gcePersistentDisk:
    label: Google Persistent Disk
    persistentDiskName:
      label: Persistent Disk Name
      placeholder: e.g. abc
  awsElasticBlockStore:
    label: Amazon EBS Disk
    volumeId:
      label: Volume ID
      placeholder: e.g. volume1
  azureFile:
    label: Azure Filesystem
    shareName:
      label: Share Name
      placeholder: e.g. abc
  azureDisk:
    label: Azure Disk
    diskName:
      label: Disk Name
      placeholder: e.g. kubernetes-pvc
    diskURI:
      label: Disk URI
      placeholder: e.g. https://example.com/disk
    kind:
      label: Kind
      dedicated: Dedicated
      managed: Managed
      shared: Shared
    cachingMode:
      label: Caching Mode
      none: None
      readOnly: Read Only
      readWrite: Read Write
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    readOnly:
      label: Read Only

persistentVolumeClaim:
  name: Persistent Volume Claim Name
  accessModes: Access Modes
  accessModesOptions:
    singleNodeRW: Single-Node Read/Write
    manyNodeR: Many-Node Read-Only
    manyNodeRW: Many-Node Read/Write
  capacity: Capacity
  storageClass: Storage Class
  useDefault: Use the default class
  volumes: Persistent Volumes
  volumeName: Persistent Volume Name
  source:
    label: Source
    options:
      new: Use a Storage Class to provision a new Persistent Volume
      existing: Use an existing Persistent Volume
  expand:
    label: Expand
    notSupported: Storage class does not support volume expansion
    notBound: Only bound PVCs can be expanded
  volumeClaim:
    label: Volume Claim
    storageClass: Storage Class
    requestStorage: Request Storage
    persistentVolume: Persistent Volume
    tooltips:
      noStorageClass: You don't have permission to list Storage Classes, enter a name manually
      noPersistentVolume: You don't have permission to list Persistent Volumes, enter a name manually
  customize:
    label: Customize
    accessModes:
      readWriteOnce: Single Node Read-Write
      readOnlyMany: Many Nodes Read-Only
      readWriteMany: Many Nodes Read-Write
  status:
    label: Status

podDisruptionBudget:
  budget:
    label: Budget
  minAvailable:
    label: Min. available Pods
  maxUnavailable:
    label: Max. unavailable Pods


# Rancher Extensions
plugins:
  labels:
    builtin: Built-in
    experimental: Experimental
    third-party: Third-Party
    installing: Installing ...
    uninstalling: Uninstalling ...
  descriptions:
    experimental: This Extension is marked as experimental
    third-party: This Extension is provided by a Third-Party
    built-in: This Extension is built-in
  error:
    title: Error loading extension
    message: Could not load extension code
    generic: Extension error
    api: This Extension is not compatible with the Extensions API
    host: This Extension is not compatible with this application
    version: This Extension is not compatible with this version of Rancher
    load: An error occurred loading the code for this Extension
  success:
    title: Loaded extension {name}
    message: Extension was loaded successfully
  developer:
    label: Developer Load
    title: Developer Load Extension
    prompt: Load an extension from a URL
    fields:
      url: Extension URL
      name: Extension module name
      persist: Persist extension by creating custom resource
  info:
    detail: Detail
    versions: Versions
    versionError: Could not load version information
  empty:
    all: Extensions are neither installed nor available
    available: No Extensions available
    installed: No Extensions installed
    updates: No updates available for installed Extensions
  loadError: An error occurred loading the code for this extension
  helmError: "An error occurred installing the extension via Helm"
  manageRepos: Manage Repositories
  tabs:
    all: All
    available: Available
    installed: Installed
    updates: Updates
  title: Extensions
  version: "Version: {version}"
  install:
    label: Install
    title: Install Extension {name}
    prompt: "Are you sure that you want to install this Extension?"
    version: Version
    warnNotCertified: Please ensure that you are aware of the risks of installing Extensions from untrusted authors
  update:
    label: Update
    title: Update Extension {name}
    prompt: "Are you sure that you want to update this Extension?"
  rollback:
    label: Rollback
    title: Rollback Extension {name}
    prompt: "Are you sure that you want to rollback this Extension?"
  uninstall:
    label: Uninstall
    title: "Uninstall Extension: {name}"
    prompt: "Are you sure that you want to uninstall this Extension?"
  upgradeAvailable: A newer version of this Extension is available
  reload: Extensions changed - reload required
  safeMode:
    title: Extensions Safe Mode
    message: Extensions were not loaded
  setup:
    title: Extension support is not enabled
    prompt:
      cant: Automatic installation is not available - required Helm Charts could not be found
      can: You need to install the Extension Operator
    install:
      title: Enable Extension Support?
      prompt: This will install the Helm charts to enable Extension support
      airgap: The Rancher Extensions Repository provides extensions published by Rancher. Un-check if your Rancher installation is air-gapped
      addRancherRepo: Add the Rancher Extension Repository
    remove:
      label: Disable Extension Support
      title: Disable Extension Support?
      prompt: This will un-install the Helm charts that enable Extension support
      registry:
        title: Remove the Rancher Extensions Repository
        prompt: The Rancher Extensions Repository provides extensions published by Rancher
      crd:
        title: Remove the Rancher Extensions Custom Resource Definition
        prompt: There are one or more extensions installed - removing the CRD will require you to manually reinstall these extensions if you subsequently re-enable extensions support.
podSecurityAdmission:
  label: Pod Security Admission
  description: Define the admission control mode you want to use for the pod security
  version:
    placeholder: 'Version (default: latest)'
  exceptions:
    title: Exceptions
    description: Allow the creation of pods for specific Usernames, RuntimeClassNames, and Namespaces that would otherwise be prohibited due to the policies set above.
    placeholder: Enter a comma separated list of {exception}
prefs:
  title: Preferences
  theme:
    label: Theme
    light: Light
    auto: Auto
    dark: Dark
    autoDetail: Auto uses OS preference if available, or dark from {pm} to {am}
  language: Language
  landing:
    label: Login Landing Page
    vue: Cluster Explorer
    ember: Cluster Manager
  displaySettings:
    title: Display Settings
    detail: Change the way information is displayed in the UI.
  clusterToShow:
    label: Number of clusters to show in side menu
    value: |-
      {count, number}
  dateFormat:
    label: Date Format
  timeFormat:
    label: Time Format
  perPage:
    label: Table Rows per Page
    value: |-
      {count, number}
  keymap:
    label: YAML Editor Key Mapping
    sublime: 'Normal human'
    emacs: 'Emacs'
    vim: 'Vim'
  advFeatures:
    title: Advanced Features
    viewInApi: Enable "View in API"
    allNamespaces: Show system Namespaces managed by Rancher (not intended for editing or deletion)
    themeShortcut: Enable Dark/Light Theme keyboard shortcut toggle (shift+T)
    pluginDeveloper: Enable Extension developer features
  hideDesc:
    label: Hide All Type Descriptions
  helm:
    'true': Include Prerelease Versions
    'false': Show Releases Only
    label: Helm Charts

principal:
  loading: Loading&hellip;
  error: Unable to fetch principal info
  name: Name
  loginName: Username
  type: Type

probe:
  checkInterval:
    label: Check Interval
    placeholder: 'Default: 10'
  command:
    label: Command to run
    placeholder: e.g. cat /tmp/health
  failureThreshold:
    label: Failure Threshold
    placeholder: 'Default: 3'
  httpGet:
    headers:
      label: Request Headers
    path:
      label: Request Path
      placeholder: e.g. /healthz
    port:
      label: Check Port
      placeholder: e.g. 80
      placeholderDeux: e.g. 25
  initialDelay:
    label: Initial Delay
    placeholder: 'Default: 0'
  successThreshold:
    label: Success Threshold
    placeholder: 'Default: 1'
  timeout:
    label: Timeout
    placeholder: 'Default: 3'
  type:
    label: Type
    placeholder: Select a check type

project:
  membersEditOnly: Only permissions equal to or below those of the current user can be applied
  members:
    label: Members
  containerDefaultResourceLimit: Container Default Resource Limit
  vmDefaultResourceLimit: VM Default Resource Limit
  resourceQuotas: Resource Quotas
  haveOneOwner: There must be at least one member with the Owner role.
  psp:
    default: Cluster Default
    label: Pod Security Policy
    current: "{value} (Current)"


projectMembers:
  project:
    label: Project
  projectPermissions:
    label: Project Permissions
    description: Controls what access users have to the Project
    noDescription: User created - no description
    searchForMember: Search for a member to provide project access
    owner:
      label: Owner
      description: Owners have full control over the Project and all resources inside it.
    member:
      label: Member
      description: Members can manage the resources inside the Project but not change the Project itself.
    readOnly:
      label: Read Only
      description: Members can only view the resources inside the Project but not change the resources.
    custom:
      label: Custom
      description: Choose individual roles for this user.
    createNs: Create Namespaces
    configmapsManage: Manage Config Maps
    ingressManage: Manage Ingress
    projectcatalogsManage: Manage Project Catalogs
    projectroletemplatebindingsManage: Manage Project Members
    secretsManage: Manage Secrets
    serviceaccountsManage: Manage Service Accounts
    servicesManage: Manage Services
    persistentvolumeclaimsManage: Manage Volumes
    workloadsManage: Manage Workloads
    configmapsView: View Config Maps
    ingressView: View Ingress
    monitoringUiView: View Monitoring
    projectcatalogsView: View Project Catalogs
    projectroletemplatebindingsView: View Project Members
    secretsView: View Secrets
    serviceaccountsView: View Service Accounts
    servicesView: View Services
    persistentvolumeclaimsView: View Volumes
    workloadsView: View Workloads

projectNamespaces:
  createNamespace: Create Namespace
  createProject: Create Project
  label: Projects/Namespaces
  noNamespaces: There are no namespaces defined.
  noProjectNoNamespaces: All namespaces are in a project

prometheusRule:
  alertingRules:
    addLabel: Add Alert
    annotations:
      description:
        input: Description Annotation Value
        label: Description
      label: Annotations
      message:
        input: Message Annotation Value
        label: Message
      runbook:
        input: Runbook URL Annotation Value
        label: Runbook URL
      summary:
        input: Summary Annotation Value
        label: Summary
    bannerText: 'When firing alerts, the annotations and labels will be passed to the configured AlertManagers to allow them to construct the notification that will be sent to any configured Receivers.'
    for:
      label: Wait to fire for
      placeholder: '60'
    label: Alerting Rules
    labels:
      label: Labels
      severity:
        choices:
          critical: critical
          label: Severity Label Value
          none: none
          warning: warning
        label: Severity
    name: Alert Name
    removeAlert: Remove Alert
  groups:
    add: Add Rule Group
    groupRowLabel: Rule Group {index}
    groupInterval:
      label: Override Group Interval
      placeholder: '60'
    label: Rule Groups
    name: Group Name
    none: Please add at least one rule group that contains at least one alerting or one recording rule.
    removeGroup: Remove Group
    responseStrategy:
      label: Partial Response Strategy
  promQL:
    label: PromQL Expression
  recordingRules:
    addLabel: Add Record
    label: Recording Rules
    labels: Labels
    name: Time Series Name
    removeRecord: Remove Record

promptForceRemove:
  modalTitle: Are you sure?
  removeWarning: "There was an issue with deleting underlying infrastructure. If you proceed with this action, the Machine <b>{nameToMatch}</b> will be deleted from Rancher only. It's highly recommended to manually delete any referenced infrastructure."
  forceDelete: Force Delete
  confirmName: "Enter in the pool name below to confirm:"
  podRemoveWarning: "Force deleting pods does not wait for confirmation that the pod's processes have been terminated. This may result in <strong>data corruption or inconsistencies</strong>"

promptScaleMachineDown:
  attemptingToRemove: "You are attempting to delete {count} {type}"
  retainedMachine1: At least one Machine must exist for roles Control Plane and Etcd.
  retainedMachine2: <b>{ name }</b> will remain

promptRemove:
  title: Are you sure?
  andOthers: |-
    {count, plural,
    =0 {.}
    =1 { and <b>one other</b>.}
    other { and <b>{count} others</b>.}
    }
  attemptingToRemove: "You are attempting to delete the {type}"
  attemptingToRemoveAuthConfig: "You are attempting to disable this Auth Provider. <br><br> Be aware that cluster role template bindings, project role template bindings, global role bindings, users, tokens will be all deleted. <br><br> Are you sure you want to proceed?"
  protip: "Tip: Hold the {alternateLabel} key while clicking delete to bypass this confirmation"
  confirmName: "Enter <b>{nameToMatch}</b> below to confirm:"
  deleteAssociatedNamespaces: "Also delete the namespaces in this project:"
  willDeleteAssociatedNamespaces: "This will also delete all namespaces in the project: "
  confirmRelatedResource: "Deleting the {type} will remove all the resources on this particular {type} and this is not revertable, are you sure you want to continue deleting {names}?"

promptRemoveApp:
  removeCrd: "Delete the CRD associated with this app"

promptRestore:
  title: Restore Snapshot
  name: Name
  date: Date
  fromS3: Restore from S3
  label: Snapshot
  placeholder: Select a snapshot to restore
  notification:
    title: Restore Snapshot
    message: Restoring snapshot { selectedSnapshot } has started...

promptRollback:
  modalTitle: Roll Back {workloadName}
  dropdownTitle: Roll Back to Revision
  placeholder: Choose a Revision...
  attemptingToRollBack: Attempting to roll back workload...
  differences: Differences
  revisionOption: "Revision {revisionNumber}, created {revisionAge} {units} ago {currentLabel}"
  currentLabel: "(Current)"
  multipleWorkloadError: "Only one workload can be rolled back at a time."
  singleRevisionBanner: There are no revisions to roll back to.

promptSaveAsRKETemplate:
  title: Convert {cluster} to new RKE Template
  name: Cluster Template Name
  description: Create a new RKE cluster template and initial revision from the current cluster configuration.
  warning: This will modify the cluster, setting it up to use the newly created cluster template and revision. This can not be undone.

promptRotateEncryptionKey:
  title: Rotate Encryption Keys
  description: The last backup {name} was performed on {date}
  warning: Before proceeding, ensure a successful ETCD backup of the cluster has been completed.
  error: No backup found

rancherAlertingDrivers:
  msTeams: Enable Microsoft Teams
  sms: Enable SMS
  selectOne: You must select at least one of the options below.

rbac:
  roleBinding:
    noData: There are no members associated with this resource.
    user:
      label: User
    role:
      label: Role
    add: Add Member
  displayRole:
    fleetworkspace-admin: Admin
    fleetworkspace-member: Member
    fleetworkspace-readonly: Read-Only
  members:
    label: Members
  roletemplate:
    label: Roles
    newUserDefault:
      no: No
      tooltip: This does not affect any bindings to the role that already exist.
    locked:
      label: Locked
      yes: 'Yes: New bindings are not allowed to use this role'
      no: No
    tabs:
      grantResources:
        label: Grant Resources
        noApiGroupClusterScope: Core K8s API, Cluster Scoped
        noApiGroupNamespaceScope: Core K8s API, Namespaced
        deprecatedLabel: (deprecated)
        resourceOptionInfo: The resource options are not a complete list of every resource available in every Rancher-managed Kubernetes cluster. Resources and API groups may need to be manually entered in advanced use cases.
        tableHeaders:
          verbs: Verbs
          resources: Resource
          nonResourceUrls: Non-Resource URLs
          apiGroups: API Groups
    subtypes:
      GLOBAL:
        createButton: Create Global Role
        label: Global
        yes: "Yes: Default role for new users"
        defaultLabel: New User Default
      CLUSTER:
        createButton: Create Cluster Role
        label: Cluster
        yes: "Yes: Default role for new cluster creation"
        defaultLabel: Cluster Creator Default
      NAMESPACE:
        createButton: Create Project/Namespaces Role
        label: Project/Namespaces
        yes: "Yes: Default role for new project creation"
        defaultLabel: Project Creator Default
      RBAC_ROLE:
        label: Role
      RBAC_CLUSTER_ROLE:
        label: Cluster Role
      noContext:
        label: No Context
  globalRoles:
    notBound: 'No users bound <i class="icon icon-checkmark" style="margin-left: 5px"></i>'
    unableToCheck: Unable to check if any user is bound to the role(s). Please try again.
    waiting: |-
      {count, plural,
        =1 { Checking if there are any users bound to this role <i class="icon-spin icon icon-spinner" style="margin-left: 5px"></i> }
        other { Checking if there are any users bound to these roles <i class="icon-spin icon icon-spinner" style="margin-left: 5px"></i> }
      }
    usersBound: |-
      {count, plural,
        =1 { Caution: There is 1 user bound to the role(s) about to be deleted. Do you want to proceed? }
        other { Caution: There are {count} users bound to the role(s) about to be deleted. Do you want to proceed? }
      }
    types:
      global:
        label: Global Permissions
        description: |-
          Controls what access the {isUser, select,
          true {user}
          false {group}} has to administer the overall {appName} installation.
      custom:
        label: Custom
        description: 'Roles not created by {vendor}.'
      builtin:
        label: Built-in
        description: Additional roles to define more fine-grain permissions model.
    unknownRole:
      description: No description provided
    assignOnlyRole: This role is already assigned
    role:
      admin:
        label: Administrator
        description: Administrators have full control over the entire installation and all resources in all clusters.
      restricted-admin:
        label: Restricted Administrator
        description: Restricted Admins have full control over all resources in all downstream clusters but no access to the local cluster.
      user:
        label: Standard User
        description: Standard Users can create new clusters and manage clusters and projects they have been granted access to.
      user-base:
        label: User-Base
        description: User-Base users have login-access only.
      clusters-create:
        label: Create new Clusters
        description: Allows the user to create new clusters and become the owner of them.  Standard Users have this permission by default.
      clustertemplates-create:
        label: Create new RKE Cluster Templates
        description: Allows the user to create new RKE cluster templates and become the owner of them.
      authn-manage:
        label: Configure Authentication
        description: Allows the user to enable, configure, and disable all Authentication provider settings.
      catalogs-manage:
        label: Legacy Configure Catalogs
        description: Allows the user to add, edit, and remove management.cattle.io based catalogs resources.
      clusters-manage:
        label: Manage all Clusters
        description: Allows the user to manage all clusters, including ones they are not a member of.
      clusterscans-manage:
        label: Manage CIS Cluster Scans
        description: Allows the user to launch new and manage CIS cluster scans.
      kontainerdrivers-manage:
        label: Create new Cluster Drivers
        description: Allows the user to create new cluster drivers and become the owner of them.
      features-manage:
        label: Configure Feature Flags
        description: Allows the user to enable and disable custom features via feature flag settings.
      nodedrivers-manage:
        label: Configure Node Drivers
        description: Allows the user to enable, configure, and remove all Node Driver settings.
      nodetemplates-manage:
        label: Manage Node Templates
        description: Allows the user to define, edit, and remove Node Templates.
      podsecuritypolicytemplates-manage:
        label: Manage Pod Security Policies (PSPs)
        description: Allows the user to define, edit, and remove PSPs.
      roles-manage:
        label: Manage Roles
        description: Allows the user to define, edit, and remove Role definitions.
      settings-manage:
        label: Manage Settings
        description: 'Allows the user to manage {vendor} Settings.'
      users-manage:
        label: Manage Users
        description: Allows the user to create, remove, and set passwords for all Users.
      catalogs-use:
        label: Use Catalogs
        description: Allows the user to see and deploy Templates from the Catalog.  Standard Users have this permission by default.
      nodetemplates-use:
        label: Use Node Templates
        description: Allows the user to deploy new Nodes using any existing Node Templates.
      view-rancher-metrics:
        label: 'View {vendor} Metrics'
        description: Allows the user to view Metrics through the API.
      base:
        label: Login Access
      clustertemplaterevisions-create:
        label: Create RKE Template Revisions

resourceDetail:
  detailTop:
    annotations: Annotations
    created: Created
    deleted: Deleted
    description: Description
    endpoints: Endpoints
    labels: Labels
    namespaces: Namespaces
    ownerReferences: |-
      {count, plural,
      =1 {Owner}
      other {Owners}}
    hideLabels: Hide system labels
    showLabels: Show all labels
    hideAnnotations: |-
      {annotations, plural,
      =1 {Hide 1 annotation}
      other {Hide {annotations} annotations}}
    showAnnotations: |-
      {annotations, plural,
      =1 {Show 1 annotation}
      other {Show {annotations} annotations}}
    name: Name
  header:
    clone: "Clone from {subtype} {name}"
    create: Create {subtype}
    import: Import {subtype}
    edit: "{subtype} {name}"
    stage: "Stage from {subtype} {name}"
    view: "{subtype} {name}"
  masthead:
    age: Age
    restartCount: Pod Restarts
    defaultBannerMessage:
      error: This resource is currently in an error state, but there isn't a detailed message available.
      transitioning: This resource is currently in a transitioning state, but there isn't a detailed message available.
    sensitive:
      hide: Hide Sensitive Values
      show: Show Sensitive Values
    namespace: Namespace
    workspace: Workspace
    project: Project
    detail: Detail
    config: Config
    graph: Graph
    yaml: YAML
    managedWarning: |-
      This {type} is managed by {hasName, select,
        no {a {managedBy} app}
        yes {the {managedBy} app {appName}}}; changes made here will likely be overwritten the next time {managedBy} runs.
resourceList:
  head:
    create: Create
    createFromYaml: Create from YAML
    createResource: "Create {resourceName}"
  nsFiltering: "There are too many {resource}.<br>Please filter them by selecting a Namespace above."
  nsFilterToolTip: "There are too many resources, filtering is restricted to a single {mode}."
resourceLoadingIndicator:
  loading: Loading

resourceTable:
  groupBy:
    none: Flat List
    namespace: Group by Namespace
    project: Group by Project
    node: Group by Node
    cluster: Group by Cluster
  groupLabel:
    cluster: "<span>Cluster:</span> {name}"
    notInACluster: Not in a Cluster
    namespace: "<span>Namespace:</span> {name}"
    notInAMachinePool: "Not In A Deployment"
    machinePool: "<span>Pool:</span> {name}"
    notInANamespace: Not Namespaced
    notInAProject: Not in a Project
    project: "<span>Project:</span> {name}"
    notInAWorkspace: Not in a Workspace
    workspace: "<span>Workspace:</span> {name}"
    notInANodePool: "Not in a Pool"
    nodePool: "<span>Pool:</span> {name}"
    node: "<span>Node:</span> {name}"

resourceTabs:
  conditions:
    tab: Conditions
  events:
    tab: Recent Events
  related:
    tab: Related Resources
    from: Referred To By
    to: Refers To


resourceYaml:
  errors:
    namespaceRequired: This resource is namespaced, so a namespace must be provided.
  buttons:
    continue: Continue Editing
    edit: Edit YAML
    diff: Show Diff
    hideDiff: Hide Diff
    unified: Unified
    split: Split

secret:
  authentication: Authentication
  certificate:
    certificate: Certificate
    certificatePlaceholder: "Paste in the CA certificate, starting with -----BEGIN CERTIFICATE----"
    cn: Domain Name
    expires: Expires
    issuer: Issuer
    plusMore: "+ {n} more"
    privateKey: Private Key
    privateKeyPlaceholder: "Paste in the private key, typically starting with -----BEGIN RSA PRIVATE KEY-----"
  data: Data
  registry:
    address: Registry
    domainName: Registry Domain Name
    password: Password
    username: Username
  basic:
    password: Password
    username: Username
  ssh:
    keys: Keys
    public: Public Key
    publicPlaceholder: "Paste in your public key"
    private: Private Key
    privatePlaceholder: "Paste in your private key"
  serviceAcct:
    ca: CA Certificate
    token: Token
  customType: Custom Type
  type: Type
  types:
    'opaque': 'Opaque'
    'kubernetes.io/service-account-token': 'Svc Acct Token'
    'kubernetes.io/dockercfg': 'Registry'
    'kubernetes.io/dockerconfigjson': 'Registry'
    'kubernetes.io/basic-auth': 'HTTP Basic Auth'
    'kubernetes.io/ssh-auth': 'SSH Key'
    'kubernetes.io/tls': 'TLS Certificate'
    'bootstrap.kubernetes.io/token': 'Bootstrap Token'
    'istio.io/key-and-cert': 'Istio Certificate'
    'helm.sh/release.v1': 'Helm Release'
    'fleet.cattle.io/cluster-registration-values': 'Fleet Cluster'
    'provisioning.cattle.io/cloud-credential': 'Cloud Credential'
    'rke.cattle.io/auth-config': 'RKE Auth Config'
  initials:
    'opaque': 'O'
    'kubernetes.io/service-account-token': 'SAT'
    'kubernetes.io/dockercfg': 'R'
    'kubernetes.io/dockerconfigjson': 'R'
    'kubernetes.io/basic-auth': 'HTTP'
    'kubernetes.io/ssh-auth': 'SSH'
    'kubernetes.io/tls': 'TLS'
    'bootstrap.kubernetes.io/token': 'Boot'
    'istio.io/key-and-cert': 'Ist'
    'helm.sh/release.v1': 'Helm'
    'fleet.cattle.io/cluster-registration-values': 'F'
    'provisioning.cattle.io/cloud-credential': 'CC'
    's3': 'S3'
  relatedWorkloads: Related Workloads
  typeDescriptions:
    custom:
      description: Create a Secret with a custom type
    'kubernetes.io/basic-auth':
      description: 'Authentication with a username and password'
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#basic-authentication-secret
    'Opaque':
      description: Default type of Secret using key-value pairs
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#opaque-secrets
    'kubernetes.io/dockerconfigjson':
      description: Authenticated registry for pulling container images
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#docker-config-secrets
    'kubernetes.io/ssh-auth':
      description: Public key and private key for SSH authentication
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#ssh-authentication-secrets
    'kubernetes.io/tls':
      description: Store a certificate and key for TLS
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#tls-secrets

selectOrCreateAuthSecret:
  label: Authentication
  options:
    none: None
    basic: HTTP Basic Auth
    ssh: SSH Key
    aws: AWS/S3
    custom: Secret Name
  s3:
    accessKey: Access Key
    secretKey: Secret Key
  ssh:
    publicKey: Public Key
    privateKey: Private Key
  basic:
    username: Username
    password: Password
  namespaceGroup: "Namespace: {name}"
  chooseExisting: "Choose an existing secret:"
  createSsh: Create a SSH Key Secret
  createBasic: Create a HTTP Basic Auth Secret
  createS3: Create a S3-Compatible Auth Secret

serviceAccount:
  automount: Automount Service Account Token
  imagePullSecrets: Image Pull Secrets
  tabs:
    serviceAccount:
      label: Service Account

servicePorts:
  header:
    label: Port Rules
  rules:
    listening:
      label: Listening Port
      placeholder: e.g. 8080
    name:
      label: Port Name
      placeholder: e.g. myport
    node:
      label: Node Port
      placeholder: e.g. 30000
    protocol:
      label: Protocol
    target:
      label: Target Port
      placeholder: e.g. 80 or http

serviceTypes:
  clusterip: Cluster IP
  externalname: External Name
  headless: Headless
  loadbalancer: Load Balancer
  nodeport: Node Port

servicesPage:
  anyNode: Any Node
  labelsAnnotations:
    label: Labels & Annotations
  affinity:
    actionLabels:
      clientIp: ClientIP
      none: There is no session affinity configured.
    helpText: Map connections to a consistent target based on their source IP.
    label: Session Affinity
    timeout:
      label: Session Sticky Time
      placeholder: e.g. 10800
  externalName:
    define: External Name
    helpText: "External Name is intended to specify a canonical DNS name. This is a required field. To hardcode an IP address, use a Headless service."
    label: External Name
    placeholder: e.g. my.database.example.com
    input:
      label: DNS Name
  harvester:
    title: Add-on Config
    ipam:
      label: IPAM
    healthCheckPort:
      label: Health Check Port
    healthCheckSuccessThreshold:
      label: Health Check Success Threshold
      description: If the number of times the prober continuously detects an address successfully reaches the success threshold, then the backend server can start to forward traffic.
    healthCheckFailureThreshold:
      label: Health Check Failure Threshold
      description: The backend server will stop forwarding traffic if the number of health check failures reaches the failure threshold.
    healthCheckPeriod:
      label: Health Check Period
    healthCheckTimeout:
      label: Health Check Timeout
    healthCheckEnabled:
      label: Health Check
  ips:
    define: Service Ports
    clusterIpHelpText: The Cluster IP address must be within the CIDR range configured for the API server.
    external:
      label: External IPs
      placeholder: e.g. 1.1.1.1
      protip: List of IP addresses for which nodes in the cluster will also accept traffic for this service.
    input:
      label: Cluster IP
      placeholder: e.g. 10.43.xxx.xxx
    label: IP Addresses
    loadBalancer:
      label: Load Balancer
    loadBalancerIp:
      label: Load Balancer IP
      placeholder: e.g. 192.0.xxx.xxx
      helpText: If you specify a loadBalancerIP but your cloud provider does not support the feature, the loadBalancerIP field that you set is ignored.
  pods:
    label: Pods
  ports:
    label: Ports
  selectors:
    helpText: ""
    label: Selectors
    matchingPods:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} pods. If no selector is created, manual endpoints must be made.}
          =1 {Matches 1 of {total, number} pods: "{sample}"}
          other {Matches {matched, number} of {total, number} existing pods, including "{sample}"}
        }
  serviceTypes:
    clusterIp:
      abbrv: IP
      description: Exposes the service on a cluster-internal IP. Choosing this value makes the service only reachable from within the cluster. This is the default type.
      label: Cluster IP
    externalName:
      abbrv: EN
      description: "Maps the service to the contents of the `externalName` field (e.g. foo.bar.example.com), by returning a CNAME record with its value. No proxying of any kind is set up."
      label: External Name
    headless:
      abbrv: H
      description: Neither a cluster IP or load balancer is defined. These are used to interface with other service discovery mechanisms outside of Kubernetes implementation. A cluster IP is not allocated and kube-proxy does not handle these services.
      label: Headless
    loadBalancer:
      abbrv: LB
      description: Exposes the service externally using a cloud provider's load balancer.
      label: Load Balancer
    nodePort:
      abbrv: NP
      description: "Exposes the service on each node's IP at a static port (the `NodePort`). You'll be able to contact this type of service, from outside the cluster, by requesting `&lt;NodeIP&gt;:&lt;NodePort&gt;`."
      label: Node Port
  typeOpts:
    label: Service Type

setup:
  currentPassword: Bootstrap Password
  confirmPassword: Confirm New Password
  defaultPassword:
    intro: It looks like this is your first time visiting {vendor}; if you pre-set your own bootstrap password, enter it here.  Otherwise a random one has been generated for you.  To find it:<br/><br/>
    dockerPrefix: 'For a "docker run" installation:'
    dockerPs: 'Find your container ID with <code>docker ps</code>, then run:'
    dockerSuffix: ""
    helmPrefix: 'For a Helm installation, run:'
    helmSuffix: ""
  eula: By checking the box, you accept the <a href="https://rancher.com/eula" target="_blank" rel="noopener noreferrer nofollow">End User License Agreement & Terms & Conditions</a>
  newPassword: New Password
  newUserSetPassword: The first order of business is to set a strong password. We suggest using this random one generated just for you, but enter your own if you like.
  serverUrl:
    label: Server URL
    skip: Skip
    tip: What URL should be used for this {vendor} installation? All the nodes in your clusters will need to be able to reach this.
  setPassword: The first order of business is to set a strong password for the default <code>{username}</code> user. We suggest using this random one generated just for you, but enter your own if you like.
  telemetry: Allow collection of <a href="{docsBase}/faq/telemetry/" target="_blank" rel="noopener noreferrer nofollow">anonymous statistics</a> to help us improve {name}
  useManual: Set a specific password to use
  useRandom: Use a randomly generated password
  welcome: Welcome to {vendor}!

sortableTable:
  bulkActions:
    collapsed:
      label: Actions
  actionAvailability:
    selected: "{actionable} selected"
    some: "Affects {actionable} of {total}"
  noData: There are no rows which match your search query.
  noRows: There are no rows to show.
  noActions: No actions available
  paging:
    generic: |-
      {pages, plural,
      =0 {No Items}
      =1 {{count} {count, plural, =1 {Item} other {Items}}}
      other {{from} - {to} of {count} Items}}
    resource: |-
      {pages, plural,
      =0 {No {pluralLabel}}
      =1 {{count} {count, plural, =1 {{singularLabel}} other {{pluralLabel}}}}
      other {{from} - {to} of {count} {pluralLabel}}}
  search: Filter
  in: in
  addFilter: Add Filter
  filterFor: Filter for...
  selectCol: Select a column
  resetFilters: Reset
  add: Add
  tableHeader:
    noFilter: This column cannot be filtered by
    groupBy: Group by
    show: Show

storageClass:
  actions:
    setAsDefault: Set as Default
    resetDefault: Reset Default
  parameters:
    label: Parameters
  customize:
    label: Customize
    reclaimPolicy:
      label: Reclaim Policy
      delete: Delete volumes and underlying device when volume claim is deleted
      retain: Retain the volume for manual cleanup
    allowVolumeExpansion:
      label: Allow Volume Expansion
      enabled: Enabled
      disabled: Disabled
    volumeBindingMode:
      label: Volume Binding Mode
      now: Bind and provision a persistent volume once the PersistentVolumeClaim is created
      later: Bind and provision a persistent volume once a Pod using the PersistentVolumeClaim is created
    mountOptions:
      label: Mount Options
      addLabel: Add Option
  aws-ebs:
    title: Amazon EBS Disk
    volumeType:
      label: Volume Type
      gp2: GP2 - General Purpose SSD
      gp3: GP3 - General Purpose SSD
      io1: IO1 - Provisioned IOPS SSD
      st1: ST1 - Throughput-Optimized HDD
      sc1: SC1 - Cold-Storage HDD
      provisionedIops:
        label: Provisioned IOPS
        suffix: per second, per GB
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    availabilityZone:
      label: Availability Zone
      automatic: 'Automatic: Zones the cluster has a node in'
      manual: 'Manual: Choose specific zones'
      placeholder: us-east-1d, us-east-1c
    encryption:
      label: Encryption
      enabled: Enabled
      disabled: Disabled
    keyId:
      label: KMS Key ID for Encryption
      automatic: 'Automatic: Generate a key'
      manual: 'Manual: Use a specific key (full ARN)'
  azure-disk:
    title: Azure Disk
    storageAccountType:
      label: Storage Account Type
      placeholder: e.g. Standard_LRS
    kind:
      label: Kind
      shared: Shared (unmanaged disk)
      dedicated: Dedicated (unmanaged disk)
      managed: Managed
  azure-file:
    title: Azure File
    skuName:
      label: Sku Name
      placeholder: e.g. Standard_LRS
    location:
      label: Location
      placeholder: e.g. eastus
    storageAccount:
      label: Storage Account
      placeholder: e.g. azure_storage_account_name
  gce-pd:
    title: Google Persistent Disk
    volumeType:
      label: Volume Type
      standard: Standard
      ssd: SSD
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    availabilityZone:
      label: Availability Zone
      automatic: 'Automatic: Zones the cluster has a node in'
      manual: 'Manual: Choose specific zones'
      placeholder: us-east-1d, us-east-1c
    replicationType:
      label: Replication Type
      zonal: Zonal
      regional: Regional
  longhorn:
    title: Longhorn (CSI)
    addLabel: Add Parameter
  vsphere-volume:
    title: VMWare vSphere Volume
    diskFormat:
      label: Disk Format
      thin: Thin
      zeroedthick: Zeroed Thick
      eagerzeroedthick: Eager Zeroed Thick
    storagePolicyName:
      label: Storage Policy Name
      placeholder: e.g. gold
    datastore:
      label: Datastore
      placeholder: e.g. VSANDatastore
    hostFailuresToTolerate:
      label: Host Failures To Tolerate
      placeholder: e.g. 2
    cacheReservation:
      label: Cache Reservation
      placeholder: e.g. 20
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext3
  custom:
    addLabel: Add Parameter
  glusterfs:
    title: Gluster Volume
    restUrl:
      label: REST URL
      placeholder: e.g. http://127.0.0.1:8081
    restUser:
      label: REST User
      placeholder: e.g. admin
    restUserKey:
      label: REST User Key
      placeholder: e.g. password
    secretNamespace:
      label: Secret Namespace
      placeholder: e.g. default
    secretName:
      label: Secret Name
      placeholder: e.g. heketi-secret
    clusterId:
      label: Cluster ID
      placeholder: e.g. 630372ccdc720a92c681fb928f27b53f
    gidMin:
      label: GID MIN
      placeholder: e.g. 40000
    gidMax:
      label: GID MAX
      placeholder: e.g. 50000
    volumeType:
      label: Volume Type
      placeholder: "e.g. replicate:3"
  cinder:
    title: Openstack Cinder Volume
    volumeType:
      label: Volume Type
      placeholder: e.g. fast
    availabilityZone:
      label: Availability Zone
      automatic: "Automatic: Zones the cluster has a node in"
      manual:
        label: "Manual: Choose specific zones"
        placeholder: e.g. nova
  rbd:
    title: Ceph RBD
    monitors:
      label: Monitors
      placeholder: e.g. 10.16.153.105:6789
    adminId:
      label: Admin ID
      placeholder: e.g. kube
    adminSecretNamespace:
      label: Admin Secret Namespace
      placeholder: e.g. kube-system
    adminSecret:
      label: Admin Secret
      placeholder: e.g. Secret
    pool:
      label: Pool
      placeholder: e.g. kube
    userId:
      label: User ID
      placeholder: e.g. kube
    userSecretNamespace:
      label: User Secret Namespace
      placeholder: e.g. default
    userSecretName:
      label: User Secret Name
      placeholder: e.g. ceph-secret-user
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    imageFormat:
      label: Image Format
      placeholder: e.g. 2
    imageFeatures:
      label: Image Features
      placeholder: e.g. layering
  quobyte:
    title: Quobyte Volume
    quobyteApiServer:
      label: Quobyte API Server
      placeholder: "e.g. http://138.68.74.142:7860"
    registry:
      label: Registry
      placeholder: e.g. 138.68.74.142:7861
    adminSecretNamespace:
      label: Admin Secret Namespace
      placeholder: e.g. kube-system
    adminSecretName:
      label: Admin Secret Name
      placeholder: e.g. quobyte-admin-secret
    user:
      label: User
      placeholder: e.g. root
    group:
      label: Group
      placeholder: e.g. root
    quobyteConfig:
      label: Quobyte Config
      placeholder: e.g. BASE
    quobyteTenant:
      label: Quobyte Tenant
      placeholder: e.g. DEFAULT
  portworx-volume:
    title: Portworx Volume
    filesystem:
      label: Filesystem
      placeholder: e.g. ext4
    blockSize:
      label: Block Size
      placeholder: e.g. 32
    repl:
      label: Repl
      placeholder: e.g.1; 0 for entire device
    ioPriority:
      label: I/O Priority
      placeholder: e.g. low
    snapshotsInterval:
      label: Snapshots Interval
      placeholder: e.g. 70
    aggregationLevel:
      label: Aggregation Level
      placeholder: e.g. 0
    ephemeral:
      label: Ephemeral
      placeholder: e.g. true
  scaleio:
    title: ScaleIO Volume
    gateway:
      label: Gateway
      placeholder: e.g. https://192.168.99.200:443/api
    system:
      label: System
      placeholder: e.g. scaleio
    protectionDomain:
      label: Protection Domain
      placeholder: e.g. pd0
    storagePool:
      label: Storage Pool
      placeholder: e.g. sp1
    storageMode:
      label: StorageMode
      thin: Thin Provisioned
      thick: Thick Provisioned
    secretRef:
      label: Secret Ref
      placeholder: e.g. sio-secret
    readOnly:
      label: Read Only
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. xfs
  storageos:
    title: StorageOS
    pool:
      label: Pool
      placeholder: e.g. default
    description:
      label: Description
      placeholder: e.g. Kubernetes volume
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    adminSecretNamespace:
      label: Admin Secret Namespace
      placeholder: e.g. default
    adminSecretName:
      label: Admin Secret Name
      placeholder: e.g. storageos-secret
  no-provisioner:
    title: Local Storage
  deprecated:
    title: (Deprecated)
    warning: 'The {provisioner} in-tree plugin is deprecated: Find a CSI driver <a target="_blank" rel="noopener noreferrer nofollow" href="https://kubernetes-csi.github.io/docs/drivers.html">here.</a>'

tableHeaders:
  assuredConcurrencyShares: Assured Concurrency Shares
  accessKey: Access Key
  addressType: Address Type
  accessModes: Access Modes
  address: Address
  age: Age
  apiGroup: API Groups
  apikey: API Key
  available: Available
  attachedVM: Attached VM

  authRoles:
    globalDefault: New User Default
    clusterDefault: Cluster Creator Default
    projectDefault: Project Creator Default
  branch: Branch
  backupTarget: Backup Target
  builtIn: Built In
  bundlesReady: Bundles Ready
  bundleDeploymentsReady: Deployments
  builtin: Built-In
  chart: Chart
  capacity: Capacity
  current: Current
  clusterCreatorDefault: Cluster Creator Default
  clusterFlow: Cluster Flow
  clusterOutput: Cluster Output
  cluster: Cluster
  clusters: Clusters
  cluster-Name: Cluster
  clustersReady: Clusters Ready
  clusterGroups: Cluster Groups
  commit: Commit
  condition: Condition
  completions: Completions
  count: Count
  createdAt: Created At
  customVerbs: Custom Verbs
  description: Description
  expires: Expires
  cpu: CPU
  currentReplicas: Current Replicas
  date: Date
  data: Data
  default: Default
  desired: Desired
  defaultVersion: Default version
  destination: Target
  deployed: Deployed
  download: Download
  duration: Duration
  diskState: Disk State
  drivers: Drivers
  distinguisherMethod: Distinguisher Method
  effect: Effect
  endpoints: Endpoints
  firstSeen: First Seen
  fleetBundleType: Type
  flow: Flow
  fingerprint: Fingerprint
  gitRepos: Git Repos
  groups: Groups
  groupName: Group Name
  groupRoleNames: Group Role Names
  global-Default: Global-Default
  host: Host
  hostIp: Host IP
  holder: Holder
  hpaReference: Workload
  health: Health
  handSize: Hand Size
  ipAddress: IP Address
  id: ID
  iP: IP
  image: Image
  imageSize: Size
  ingressClass: Ingress Class
  ingressDefaultBackend: Default
  ingressTarget: Target
  internalExternalIp: External/Internal IP
  ipaddress: IP Address
  internalIpSameAsExternal: Same as External
  jobs: Jobs
  key: Key
  keys: Data
  labels: Labels
  lastUpdated: Last Updated
  lastSchedule: Last Schedule
  lastSeen: Last Seen
  loggingOutputProviders: Provider
  machines: Machines
  machineNodeName: Node
  manual: Manual
  matches: Matches
  matchingPrecedence: Matching Precedence
  maxKubernetesVersion: Max Kubernetes Version
  message: Message
  minKubernetesVersion: Min Kubernetes Version
  minReplicas: Minimum Replicas
  maxReplicas: Maximum Replicas
  missingPL: MissingPL
  memory: Memory
  monitored: Monitored
  name: Name
  nameDisplay: Display Name
  nameUnlinked: Name
  namespace: Namespace
  namespaceName: Name
  namespaceNameUnlinked: Name
  networkType: Type
  networkVlan: Vlan ID
  node: Node
  nodeName: Node Name
  nodesReady: Nodes Ready
  nodePort: Node Port
  object: Object
  operatingSystem: OS
  output: Output
  p95: 95%tile
  persistentVolumeClaim: Persistent Volume Claim
  persistentVolumeSource: Source
  phase: Phase
  progress: Progress
  podImages: Image
  podRestarts: Restarts
  pods: Pods
  pod-Selector: Pod-Selector
  providers: Providers
  providerID: Provider ID
  port: Port
  ports: Ports
  project: Project
  protocol: Protocol
  provider: Provider
  priorityLevel: Priority Level
  publicPorts: Public Ports
  queues: Queues
  queueLengthLimit: Queue Length Limit
  ram: RAM
  rbac:
    create: Create
    delete: Delete
    get: Get
    list: List
    patch: Patch
    update: Update
    watch: Watch
  ready: Ready
  reason: Reason
  receivers: Receivers
  receiverTypes: Receiver Types
  reclaimPolicy: Reclaim Policy
  registrationNamespace: Registration Namespace
  repo: Repo
  repositories: Repositories
  repoName: Repository Name
  reposReady: Repos Ready
  replicas: Replicas
  reqRate: Req Rate
  resource: Resource
  resources: Resources
  resourcesReady: Resources Ready
  restarts: Restarts
  restart: Restart Required
  role: Role
  roles: Roles
  routes: Routes
  routeConnectivity: Route Connectivity
  readyToUse: Ready To Use
  scale: Scale
  scope: Scope
  selector: Selector
  secrets: Secrets
  schedule: Schedule
  service: Service
  serviceAccounts: Service Accounts
  secret-Name: Secret-Name
  simpleName: Name
  simpleScale: Scale
  simpleType: Type
  size: Size
  started: Started
  state: State
  status: Status
  targetVm: Target VM
  storage_class_provisioner: Provisioner
  storage: Storage Size
  storageClass: Storage Class
  source: Source
  subject: Subject
  subType: Kind
  success: Success
  summary: Summary
  subobject: Subobject
  taints: Taints
  target: Target
  targetKind: Target Type
  targetPort: Target
  type: Type
  updated: Updated
  up-to-date: Up To Date
  upgrade: Upgradable
  url: URL
  users: Users
  userDisplayName: Display Name
  userId: ID
  userStatus: Status
  username: Local Username
  value: Value
  version: Version
  volume: Volume
  volumeMode: Volume Mode
  weight: Weight
target:
  router:
    label: Router
    placeholder: Select a router
  service:
    label: Service
    placeholder: Select a service
  title: Target
  version:
    label: Version
    placeholder: Select a version

user:
  detail:
    username: Username
    globalPermissions:
      label: Global Permissions
      description: Access to manage resources that affect the entire installation
      adminMessage: This user is an administrator and has all permissions
      tableHeaders:
        permission: Permission
    clusterRoles:
      label: Cluster Roles
      description: Roles granted to this user for individual clusters
      tableHeaders:
        cluster: Cluster
    projectRoles:
      label: Project Roles
      description: Roles granted to this user for individual projects
      tableHeaders:
        project: Project
    generic:
      tableHeaders:
        role: Role
        granted: Granted
  edit:
    credentials:
      label: Credentials
      username:
        label: Username
        placeholder: e.g. jsmith
        exists: 'Username is already in use. Please choose a new username'
      displayName:
        label: Display Name
        placeholder: e.g. John Smith
      userDescription:
        label: Description
        placeholder: e.g. This account is for John Smith
  list:
    errorRefreshingGroupMemberships: Error refreshing group memberships
validation:
  noUpperCase: 'Alphanumeric characters in "{key}" must be lowercase'
  arrayLength:
    between: '"{key}" should contain between {min} and {max} {max, plural, =1 {item} other {items}}'
    exactly: '"{key}" should contain {count, plural, =1 {# item} other {# items}}'
    max: '"{key}" should contain at most {count} {count, plural, =1 {item} other {items}}'
    min: '"{key}" should contain at least {count} {count, plural, =1 {item} other {items}}'
  boolean: '"{key}" must be a boolean value.'
  chars: '"{key}" contains {count, plural, =1 {an invalid character} other {# invalid characters}}: {chars}'
  cluster:
    name: Cluster name cannot be 'local' or take the form 'c-xxxxx'
  conflict: |-
    This resource has been modified since you started editing it, and some of those modifications conflict with your changes.
    This screen has been updated to reflect the current values on the cluster. Review and reapply the changes you wanted to make, then Save again.
    Conflicting {fieldCount, plural, =1 {field} other {fields}}: {fields}
  custom:
    missing: 'No validator exists for { validatorName }! Does the validator exist in custom-validators? Is the name spelled correctly?'
  dns:
    doubleHyphen: '"{key}" Cannot contain two or more consecutive hyphens'
    hostname:
      empty: '"{key}" must be at least one character'
      emptyLabel: '"{key}" cannot contain two consecutive dots'
      endDot: '"{key}" cannot end with a dot'
      endHyphen: '"{key}" cannot end with a hyphen'
      startDot: '"{key}" cannot start with a dot'
      startHyphen: '"{key}" cannot start with a hyphen'
      startNumber: '"{key}" cannot start with a number'
      tooLong: '"{key}" cannot be longer than {max} characters'
      tooLongLabel: '"{key}" cannot contain a section longer than {max} characters'
    label:
      endDot: '"{key}" cannot end with a dot'
      startDot: '"{key}" cannot start with a dot'
      emptyLabel: '"{key}" cannot be empty'
      endHyphen: '"{key}" cannot end with a hyphen'
      startHyphen: '"{key}" cannot start with a hyphen'
      startNumber: '"{key}" cannot start with a number'
      tooLongLabel: '"{key}" cannot be more than {max} characters'
  flowOutput:
    both: Requires "Output" or "Cluster Output" to be selected.
    global: Requires "Cluster Output" to be selected.
  output:
    logdna:
      apiKey: Required an "Api Key" to be set.
  invalidCron: Invalid cron schedule
  k8s:
    name: Must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name', or '123-abc').
    identifier:
      emptyLabel: '"{key}" cannot have an empty key'
      emptyPrefix: '"{key}" cannot have an empty prefix'
      endLetter: '"{key}" must end with a letter or number'
      startLetter: '"{key}" must start with a letter or number'
      tooLongKey: '"{key}" cannot have a key longer than {max} characters'
      tooLongPrefix: '"{key}" cannot have a prefix longer than {max} characters'
  minLength: '"{key}" must contain more than {min} characters'
  maxLength: '"{key}" must contain less than {max} characters'
  minValue: '"{key}" must be higher than {min}'
  maxValue: '"{key}" must be lower than {max}'
  betweenLengths: '"{key}" must contain between {min} and {max} characters'
  betweenValues: '"{key}" must be between {min} and {max}'
  noSchema: No schema found to validate
  noType: No type to validate
  number:
    requiredInt: '"{key}" must be integer'
    between: '"{key}" should be between {min} and {max}'
    exactly: '"{key}" should be exactly {val}'
    max: '"{key}" should be at most {val}'
    min: '"{key}" should be at least {val}'
  podAffinity:
    affinityTitle: Pod Affinity
    antiAffinityTitle: Pod Anti-Affinity
    requiredDuringSchedulingIgnoredDuringExecution: required rules
    preferredDuringSchedulingIgnoredDuringExecution: preferred rules
    topologyKey: Rule [{index}] of {group} {rules} - Topology key is required.
    matchExpressions:
      operator: Rule [{index}] of {group} {rules} - operator must be one of 'In', 'NotIn', 'Exists', 'DoesNotExist'
      valueMustBeEmpty: Rule [{index}] of {group} {rules} - value must be empty if operator is 'Exists' or 'DoesNotExist'
      valuesMustBeDefined: Rule [{index}] of {group} {rules} - value must be defined if operator is 'In' or 'NotIn'
  port: A port must be a number between 1 and 65535.
  path: '"{key}" must be an absolute path'
  prometheusRule:
    noEdit: This Prometheus Rule may not be edited due to invalid characters in name.
    groups:
      required: At least one rule group is required.
      singleAlert: A rule may contain alert rules or recording rules but not both.
      valid:
        name: 'Name is required for rule group {index}.'
        rule:
          alertName: 'Rule group {groupIndex} rule {ruleIndex} requires a Alert Name.'
          expr: 'Rule group {groupIndex} rule {ruleIndex} requires a PromQL Expression.'
          labels: 'Rule group {groupIndex} rule {ruleIndex} requires at least one label. Severity is recommended.'
          recordName: 'Rule group {groupIndex} rule {ruleIndex} requires a Time Series Name.'
        singleEntry: 'At least one alert rule or one recording rule is required in rule group {index}.'
  required: '"{key}" is required'
  invalid: '"{key}" is invalid'
  requiredOrOverride: '"{key}" is required or must allow override'
  roleTemplate:
    roleTemplateRules:
      missingVerb: You must specify at least one verb for each resource grant
      missingResource: You must specify a Resource for each resource grant
      missingApiGroup: You must specify an API Group for each resource grant
      missingOneResource: You must specify at least one Resource, Non-Resource URL or API Group for each resource grant
  service:
    externalName:
      none: External Name is required on an ExternalName Service.
    ports:
      name:
        required: 'Port Rule [{position}] - Name is required.'
      nodePort:
        requiredInt: 'Port Rule [{position}] - Node Port must be integer values if included.'
        between: 'Port Rule [{position}] - Node Port must be between 1 and 65535'
      port:
        required: 'Port Rule [{position}] - Port is required.'
        requiredInt: 'Port Rule [{position}] - Port must be integer values if included.'
        between: 'Port Rule [{position}] - Port must be between 1 and 65535'
      targetPort:
        between: 'Port Rule [{position}] - Target Port must be between 1 and 65535'
        iana: 'Port Rule [{position}] - Target Port must be an IANA Service Name or Integer'
        ianaAt: 'Port Rule [{position}] - Target Port '
        required: 'Port Rule [{position}] - Target Port is required'
  setting:
    serverUrl:
      https: server-url must be https.
  stringLength:
    between: '"{key}" should be between {min} and {max} {max, plural, =1 {character} other {characters}}'
    exactly: '"{key}" should be {count, plural, =1 {# character} other {# characters}}'
    max: '"{key}" should be at most {count} {count, plural, =1 {character} other {characters}}'
    min: '"{key}" should be at least {count} {count, plural, =1 {character} other {characters}}'
  targets:
    missingProjectId: A target must have a project selected.
  monitoring:
    route:
      match: At least one Match or Match Regex must be selected
      interval: '"{key}" must be of a format with digits followed by a unit i.e. 1h, 2m, 30s'
  tab: "One or more fields in this tab contain a form validation error"

wizard:
  previous: Previous
  finish: Finish
  next: Next
  step: "Step {number}"
  edit: Edit
  create: Create
  view: View
wm:
  connection:
    connected: Connected
    connecting: Connecting&hellip;
    disconnected: Disconnected
    error: Error
  containerLogs:
    clear: Clear
    containerName: "Container: {label}"
    download: Download
    follow: Follow
    noData: There are no log entries to show in the current range.
    noMatch: No lines match the current filter.
    previous: Use Previous Container
    range:
      all: Everything
      hours: |-
        {value, number}
        {value, plural,
        =1 {Hour}
        other {Hours}
        }
      label: Show the last
      lines: "{value, number} Lines"
      minutes: |-
        {value, number} {value, plural,
        =1 {Minute}
        other {Minutes}
        }
    search: Filter
    timestamps: Show Timestamps
    wrap: Wrap Lines
  containerShell:
    clear: Clear
    containerName: "Container: {label}"
  kubectlShell:
    title: "Kubectl: {name}"

workload:
  container:
    command:
      addEnvVar: Add Variable
      args: Arguments
      as: as
      command: Command
      env: Environment Variables
      fromResource:
        key:
          label: Key
          placeholder: "e.g. metadata.labels['<KEY>']"
        name:
          label: Variable Name
          placeholder: "e.g. FOO"
        prefix: Prefix
        source:
          label: Source
          placeholder: e.g. my-container
        secret: Secret
        configMap: ConfigMap
        containerName: Container Name
        type: Type
        value:
          label: Value
          placeholder: e.g. bar
      tty: TTY
      workingDir: WorkingDir
      stdin: Stdin
    containerName: Container Name
    healthCheck:
      checkInterval: Check Interval
      command:
        command: Command to run
      failureThreshold: Failure Threshold
      httpGet:
        headers: Request Headers
        path: Request Path
        port: Check Port
      initialDelay: Initial Delay
      livenessProbe: Liveness Check
      livenessTip: Containers will be restarted when this check is failing.  Not recommended for most uses.
      noHealthCheck: "There is not a Readiness Check, Liveness Check or Startup Check configured."
      readinessProbe: Readiness Checks
      readinessTip: Containers will be removed from service endpoints when this check is failing.  Recommended.
      startupProbe: Startup Check
      startupTip: Containers will wait until this check succeeds before attempting other health checks.
      successThreshold: Success Threshold
      timeout: Timeout
      kind:
        none:  None
        HTTP:  HTTP request returns a successful status (200-399)
        HTTPS: HTTPS request returns a successful status
        tcp:   TCP connection opens successfully
        exec:  Command run inside the container exits with status 0
    image: Container Image
    imagePullPolicy: Pull Policy
    imagePullSecrets: Pull Secrets
    init: Init Container
    lifecycleHook:
      postStart:
        label: PostStart
        add: Add PostStart Hook
      preStop:
        label: PreStop
        add: Add PreStop Hook
      exec:
        title: Exec
        add: Add command to execute
        command:
          label: Command
          placeholder: "e.g. sh -c 'sleep 10'"
      httpGet:
        title: HttpGet
        add: Create HTTP request
        host:
          label: Host IP
          placeholder: e.g. 172.17.0.2
        path:
          label: Path
          placeholder: e.g. app/bin/endpoint?param=value
        port:
          label: Port
          placeholder: e.g. 3000
        scheme:
          label: Scheme
          placeholder: e.g. HTTP
      httpHeaders:
        title: HTTP Headers
        name:
          label: Name
          placeholder: e.g. accept-ranges
        value:
          label: Value
          placeholder: e.g. bytes
      tcpSocket:
        title: TCPSocket
        add: Open a TCP socket
        host:
          label: Host
          placeholder: e.g. 192.168.0.1
        port:
          label: Port
          placeholder: e.g. 80
    name: Container Name
    noResourceLimits: There are no resource requirements configured.
    noPorts: There are no ports configured.
    noServiceAccess: You do not have permission to create or manage services
    ports:
      createService: Service Type
      noCreateService: Do not create a service
      containerPort: Private Container Port
      hostIP: Host IP
      hostPort: Public Host Port
      name: Name
      protocol: Protocol
      listeningPort: Listening Port
    removeContainer: Remove Container
    addContainer: Add Container
    security:
      addCapabilities: Add Capabilities
      addGroupIDs: Add Group IDs
      allowPrivilegeEscalation:
        label: Privilege Escalation
        'false': No
        'true': "Yes: container can gain more privileges than its parent process"
      dropCapabilities: Drop Capabilities
      fsGroup: Filesystem Group
      hostIPC: Use Host IPC Namespace
      hostPID: Use Host PID Namespace
      podFsGroup: Pod Filesystem Group
      privileged:
        label: Privileged
        'false': No
        'true': "Yes: container has full access to the host"
      readOnlyRootFilesystem:
        label: Read-Only Root Filesystem
        'false': No
        'true': "Yes: container has a read-only root filesystem"
      runAsGroup: Run as Group ID
      runAsNonRoot:
        label: Run as Non-Root
        'false': No
        'true': "Yes: container must run as a non-root user"
      runAsNonRootOptions:
        noOption: "No"
        yesOption: "Yes: containers must run as non-root-user"
      runAsUser: Run as User ID
      shareProcessNamespace: Share single process namespace
      supplementalGroups: Additional Group IDs
      sysctls: Sysctls
      sysctlsKey: Name
    standard: Standard Container
    terminationState: "Last state: Terminated with {lsExitCode}: {lsDescription}, started: {lsStartedAt}, finished: {lsFinishedAt}"
    titles:
      pods: Pods
      container: Container
      command: Command
      containers: Containers
      env: Environment Variables
      events: Events
      general: General
      healthCheck: Health Check
      image: Image
      lifecycle: Lifecycle Hooks
      networking: Networking
      networkSettings: Network Settings
      podAnnotations: Pod Annotations
      podLabels: Pod Labels
      metrics: Metrics
      podScheduling: Pod Scheduling
      nodeScheduling: Node Scheduling
      ports: Ports
      resources: Resources
      securityContext: Security Context
      status: Status
      volumeClaimTemplates: Volume Claim Templates
      upgrading: Scaling and Upgrade Policy
  cronSchedule: Schedule
  detail:
    services: Services
    ingresses: Ingresses
    cannotViewServices: Could not list Services due to lack of permission.
    cannotFindServices: Could not find any Services that select Pods from this workload.
    serviceListCaption: "The following Services select Pods from this workload:"
    cannotViewIngresses: Could not list Ingresses due to lack of permission.
    cannotFindIngresses: Could not find any Ingresses that forward traffic to Services that select Pods in this workload.
    ingressListCaption: "The following Ingresses forward traffic to Services that select Pods from this workload:"
    cannotViewIngressesBecauseCannotViewServices: Could not find relevant relevant Ingresses due to lack of permission to view Services.
    pods:
      title: Pods
  detailTop:
    node: Node
    podIP: Pod IP
    podRestarts: Pod Restarts
    workload: Workload
    pods: Pods by State
    runs: Runs
  gaugeStates:
    succeeded: Successful
    running: Running
    failed: Failed
  hideTabs: 'Hide Advanced Options'
  job:
    activeDeadlineSeconds:
      label: Active Deadline
      tip: The duration that the job may be active before the system tries to terminate it.
    backoffLimit:
      label: Back Off Limit
      tip: The number of retries before marking this job failed.
    completions:
      label: Completions
      tip: The number of successfully finished pods the job should be run with.
    failedJobsHistoryLimit:
      label: Failed Job History Limit
      tip: The number of failed finished jobs to retain.
    parallelism:
      label: Parallelism
      tip: The maximum number of pods the job should run at any given time.
    startingDeadlineSeconds:
      label: Starting Deadline Seconds
      tip: The deadline in seconds for starting the job if it misses scheduled time
    successfulJobsHistoryLimit:
      label: Successful Job History Limit
      tip: The number of successful finished jobs to retain.
    suspend: Suspend
  list:
    errorCannotScale: Failed to scale {workloadName} {direction, select, up { up } down { down } }
  metrics:
    pod: Pod Metrics
    metricsView: Metrics View
  networking:
    dnsPolicy:
      label: DNS Policy
      options:
        clusterFirst: Cluster First
        clusterFirstWithHostNet: Cluster First With Host Network
        default: Default
        none: None
      placeholder: Select a Policy...
    hostAliases:
      add: Add Alias
      keyLabel: IP Address
      keyPlaceholder: e.g. 1.1.1.1
      label: Host Aliases
      tip: Additional /etc/hosts entries to be injected in the container.
      valueLabel: Hostname
      valuePlaceholder: "e.g. foo.com, bar.com"
    hostname:
      label: Hostname
      placeholder: e.g. web
    nameservers:
      add: Add Nameserver
      label: Nameservers
      placeholder: e.g. 1.1.1.1
    networkMode:
      label: Network Mode
      options:
        hostNetwork: Host Network
        normal: Normal
      placeholder: Select a Mode...
    dns: DNS
    resolver:
      label: Resolver Options
      add: Add Option
    searches:
      add: Add Search Domain
      label: Search Domains
      placeholder: e.g. mycompany.com
    subdomain:
      label: Subdomain
      placeholder: e.g. web
  normanWarning: It looks like this workload was created in the legacy Rancher UI. You may need to manually delete any services that were automatically created for it.
  validation:
    containers: Containers
    containerImage: Container {name} - "Container Image" is required.
  replicas: Replicas
  showTabs: 'Show Advanced Options'
  scheduling:
    activeDeadlineSeconds: Pod Active Deadline
    activeDeadlineSecondsTip: The duration that the pod may be active before the system tries to mark it failed and kill associated containers.
    affinity:
      addNodeSelector: Add Node Selector
      anyNode: Run pods on any available node
      affinityTitle: Run pods on nodes with pods matching these selectors
      antiAffinityTitle: Run pods on nodes without pods matching these selectors
      affinityOption: Affinity
      antiAffinityOption: Anti-Affinity
      matchExpressions:
        addRule: Add Rule
        doesNotExist: is not set
        exists: is set
        greaterThan: ">"
        in: in list
        inNamespaces: "Pods in these namespaces:"
        key: Key
        lessThan: <
        namespaces: Namespaces
        notIn: not in list
        operator: Operator
        value: Value
        weight: Weight
      noPodRules: There are no pod scheduling rules configured.
      nodeName: Node Name
      priority: Priority
      preferAny: "Prefer any of:"
      preferred: Preferred
      required: Required
      requireAny: "Require any of:"
      schedulingRules: Run pods on node(s) matching scheduling rules
      specificNode: Run pods on specific node(s)
      thisPodNamespace: This pod's namespace
      topologyKey:
        label: Topology Key
        placeholder: e.g. failure-domain.beta.kubernetes.io/zone
      type: Type
      weight:
        label: Weight
        placeholder: Must be a weight between 1 and 100
    priority:
      className: Priority Class Name
      priority: Priority
    terminationGracePeriodSeconds: Termination Grace Period
    terminationGracePeriodSecondsTip: The duration that the pod needs to terminate gracefully.
    titles:
      advanced: Advanced
      nodeScheduling: Node Scheduling
      nodeSelector: Nodes with these labels
      podScheduling: Pod Scheduling
      priority: Priority
      tab: Scheduling
      tolerations: Tolerations
      limits: Limits and Reservations
    tolerations:
      addToleration: Add Toleration
      effect: Effect
      effectOptions:
        all: All
        noExecute: NoExecute
        noSchedule: "NoSchedule,"
        preferNoSchedule: PreferNoSchedule
      labelKey: Label Key
      operator: Operator
      operatorOptions:
        equal: =
        exists: Exists
      tolerationSeconds: Toleration Seconds
      value: Value
  serviceAccountName:
    label: Service Account Name
    createMessage: The service name [ {name} ] does not exist in this namespace, you will need to create it manually.
  serviceName: Service Name
  storage:
    subtypes:
      secret: Secret
      configMap: ConfigMap
      hostPath: Bind-Mount
      persistentVolumeClaim: Persistent Volume Claim
      createPVC: Create Persistent Volume Claim
      csi: CSI
      nfs: NFS
      awsElasticBlockStore: Amazon EBS Disk
      azureDisk: Azure Disk
      azureFile: Azure File
      gcePersistentDisk: Google Persistent Disk
      driver.longhorn.io: Longhorn
      vsphereVolume: VMWare vSphere Volume
      emptyDir: Empty Dir
    addClaim: Add Claim
    addMount: Add Mount
    addVolume: Add Volume
    selectVolume: Select Volume
    noVolumes: Volumes will appear here after they are added in the Pod tab
    certificate: Certificate
    csi:
      diskName: Disk Name
      diskURI: Disk URI
      cachingMode:
        label: Caching Mode
        options:
          none: None
          readOnly: Read Only
          readWrite: Read Write
      kind:
        label: Kind
        options:
          dedicated: Dedicated
          managed: Managed
          shared: Shared
      drivers:
        driver.longhorn.io: Longhorn
      fsType: Filesystem Type
      shareName: Share Name
      secretName: Secret Name
      volumeID: Volume ID
      partition: Partition
      pdName: Persistent Disk Name
      storagePolicyID: Storage Policy ID
      storagePolicyName: Storage Policy Name
      volumePath: Volume Path
    defaultMode: Default Mode
    driver: driver
    hostPath:
      label: The Path on the Node must be
      options:
        default: 'Anything: do not check the target path'
        directoryOrCreate: A directory, or create if it doesn't exist
        directory: An existing directory
        fileOrCreate: A file, or create if it doesn't exist
        file: An existing file
        socket: An existing socket
        charDevice: An existing character device
        blockDevice: An existing block device
    mountPoint: Mount Point
    nodePath: Path on Node
    optional:
      label: Optional
      'no': 'No'
      'yes': 'Yes'
    path: Path
    readOnly: Read Only
    server: Server

    subPath: Sub Path in Volume
    title: 'Storage'
    volumeName: Volume Name
    volumePath: Volume Path
    emptyDir:
      medium:
        label: Medium
        default: Node's Default Medium
        memory: Memory
      sizeLimit:
        label: Size Limit
        placeholder: "e.g. 300"
  typeDescriptions:
    apps.daemonset: DaemonSets run exactly one pod on every eligible node. When new nodes are added to the cluster, DaemonSets automatically deploy to them. Recommended for system-wide or vertically-scalable workloads that never need more than one pod per node.
    apps.deployment: Deployments run a scalable number of replicas of a pod distributed among the eligible nodes. Changes are rolled out incrementally and can be rolled back to the previous revision when needed. Recommended for stateless & horizontally-scalable workloads.
    apps.statefulset: StatefulSets manage stateful applications and provide guarantees about the ordering and uniqueness of the pods created. Recommended for workloads with persistent storage or strict identity, quorum, or upgrade order requirements.
    batch.cronjob: CronJobs create Jobs, which then run Pods, on a repeating schedule. The schedule is expressed in standard Unix cron format, and uses the timezone of the Kubernetes control plane (typically UTC).
    batch.job: Jobs create one or more pods to reliably perform a one-time task by running a pod until it exits successfully. Failed pods are automatically replaced until the specified number of completed runs has been reached. Jobs can also run multiple pods in parallel or function as a batch work queue.
    pod: Pods are the smallest deployable units of computing that you can create and manage in Kubernetes. A Pod is a group of one or more containers, with shared storage and network resources, and a specification for how to run the containers.
  upgrading:
    activeDeadlineSeconds:
      label: Pod Active Deadline
      tip: The duration the pod may be active before the system will try to mark it failed and kill associated containers.
    concurrencyPolicy:
      label: Concurrency
      options:
        allow: Allow CronJobs to run concurrently
        forbid: Skip next run if current run hasn't finished
        replace: Replace run if current run hasn't finished
    maxSurge:
      label: Max Surge
      tip: The maximum number of pods allowed beyond the desired scale at any given time.
    maxUnavailable:
      label: Max Unavailable
      tip: The maximum number of pods which can be unavailable at any given time.
    minReadySeconds:
      label: Minimum Ready
      tip: The minimum duration a pod should be ready without containers crashing for it to be considered available.
    podManagementPolicy:
      label: Pod Management Policy
    progressDeadlineSeconds:
      label: Progress Deadline
      tip: The minimum duration to wait for a deployment to progress before marking it failed.
    revisionHistoryLimit:
      label: Revision History Limit
      tip: The number of old ReplicaSets to retain for rollback.
    strategies:
      labels:
        delete: "On Delete: New pods are only created when old pods are manually deleted."
        recreate: "Recreate: Kill ALL pods, then start new pods."
        rollingUpdate: "Rolling Update: Create new pods, until max surge is reached, before deleting old pods. Don't stop more pods than max unavailable."
    terminationGracePeriodSeconds:
      label: Termination Grace Period
      tip: The duration the pod needs to terminate successfully.
    title: Upgrading
  tabs:
    labels:
      deployment: Deployment
      pod: Pod
      containers: Containers

harvesterManager:
  manage: Manage
  cluster:
    label: Harvester Clusters
    none: There are no Harvester Clusters
    learnMore: Learn more about Harvester from the <a target="_blank" href="https://harvesterhci.io/" rel="noopener noreferrer nofollow">Harvester Web Site</a> or read the the <a target="_blank" href="https://docs.harvesterhci.io/" rel="noopener noreferrer nofollow">Harvester Docs</a>
    description: Harvester is a modern Hyperconverged infrastructure (HCI) solution built for bare metal servers using enterprise-grade open source technologies including Kubernetes, Kubevirt and Longhorn.
  plugins:
    loadError: Error loading harvester plugin

##############################
# Model Properties
##############################
model:
  account:
    kind:
      admin: Admin
      agent: Agent
      project: Environment
      registeredAgent: Registered Agent
      service: Service
      user: User
  "catalog.cattle.io.app":
    firstDeployed: First Deployed
    lastDeployed: Last Deployed
  authConfig:
    description:
      ldap: LDAP
      saml: SAML
      oauth: OAuth
      oidc: OIDC
    name:
      keycloak: Keycloak (SAML)
      keycloakoidc: Keycloak (OIDC)
    provider:
      system: System
      local: Local
      multiple: Multiple
      activedirectory: ActiveDirectory
      azuread: AzureAD
      github: GitHub
      keycloak: Keycloak
      ldap: LDAP
      openldap: OpenLDAP
      shibboleth: Shibboleth
      ping: Ping Identity
      adfs: ADFS
      okta: Okta
      freeipa: FreeIPA
      googleoauth: Google
      oidc: OIDC
      keycloakoidc: Keycloak

  cluster:
    name: Cluster Name
  ingress:
    displayKind: L7 Ingress
  machine:
    role:
      controlPlane: Control Plane
      etcd: etcd
      worker: Worker
  openldapconfig:
    domain:
      help: Only users below this base will be used.
      label: User Search Base
      placeholder: "e.g. ou=Users,dc=mycompany,dc=com"
    server:
      label: Hostname or IP Address
    serviceAccountPassword:
      label: Service Account Password
    serviceAccountUsername:
      label: Service Account Username
  projectMember:
    role:
      member: Member
      owner: Owner
      readonly: Read-Only
      restricted: Restricted
  service:
    displayKind:
      generic: Service
      loadBalancer: L4 Balancer

typeDescription:
  # Map of
  # type: Description to be shown on the top of list view describing the type.
  #       Should fit on one line.
  #       If you link to anything external, it MUST have
  #       target="_blank" rel="noopener noreferrer nofollow"
  branding: "Branding allows administrators to globally re-brand the UI by customizing the Rancher product name, logos and color scheme."
  chart: "All charts have at least one version that is installable on clusters with Linux and Windows nodes unless otherwise indicated."
  cis.cattle.io.clusterscanbenchmark: A benchmark version is the name of benchmark to run using kube-bench as well as the valid configuration parameters for that benchmark.
  cis.cattle.io.clusterscanprofile: A profile is the configuration for the CIS scan, which is the benchmark versions to use and any specific tests to skip in that benchmark.
  cis.cattle.io.clusterscan: A scan is created to trigger a CIS scan on the cluster based on the defined profile. A report is created after the scan is completed.
  cis.cattle.io.clusterscanreport: A report is the result of a CIS scan of the cluster.
  management.cattle.io.feature: Feature Flags allow certain {vendor} features to be toggled on and off.  Features that are off by default should be considered experimental functionality.
  cluster.x-k8s.io.machine: A Machine encapsulates the configuration of a Kubernetes Node. Use this view to see what happens after updating a cluster.
  cluster.x-k8s.io.machinedeployment: A Machine Deployment orchestrates deployments via templates over a collection of Machine Sets (similar to a Deployment). Use this view to see what happens after updating a cluster.
  cluster.x-k8s.io.machineset: A Machine Set ensures the desired number of Machine resources are up and running at all times (similar to a ReplicaSet). Use this view to see what happens after updating a cluster.
  resources.cattle.io.backup: A backup is created to perform one-time backups or schedule recurring backups based on a ResourceSet.
  resources.cattle.io.restore: A restore is created to trigger a restore to the cluster based on a backup file.
  resources.cattle.io.resourceset: A resource set defines which CRDs and resources to store in the backup.
  monitoring.coreos.com.servicemonitor: A service monitor defines the group of services and the endpoints that Prometheus will scrape for metrics. This is the most common way to define metrics collection.
  monitoring.coreos.com.podmonitor: A pod monitor defines the group of pods that Prometheus will scrape for metrics. The common way is to use service monitors, but pod monitors allow you to handle any situation where a service monitor wouldn't work.
  monitoring.coreos.com.prometheusrule: A Prometheus Rule resource defines both recording and/or alert rules. A recording rule can pre-compute values and save the results. Alerting rules allow you to define conditions on when to send notifications to AlertManager.
  monitoring.coreos.com.prometheus: A Prometheus server is a Prometheus deployment whose scrape configuration and rules are determined by selected ServiceMonitors, PodMonitors, and PrometheusRules and whose alerts will be sent to all selected Alertmanagers with the custom resource's configuration.
  monitoring.coreos.com.alertmanager: An alert manager is deployment whose configuration will be specified by a secret in the same namespace, which determines which alerts should go to which receiver.
  node: The base Kubernetes Node resource represents a virtual or physical machine which hosts deployments. To manage the machine lifecycle, if available, go to Cluster Management.
  catalog.cattle.io.clusterrepo: 'A chart repository is a Helm repository or {vendor} git based application catalog. It provides the list of available charts in the cluster.'
  catalog.cattle.io.clusterrepo.local: ' A chart repository is a Helm repository or {vendor} git based application catalog. It provides the list of available charts in the cluster. Cluster Templates are deployed via Helm charts.'
  catalog.cattle.io.operation: An operation is the list of recent Helm operations that have been applied to the cluster.
  catalog.cattle.io.app: An installed application is a Helm 3 chart that was installed either via our charts or through the Helm CLI.
  logging.banzaicloud.io.clusterflow: Logs from the cluster will be collected and logged to the selected Cluster Output.
  logging.banzaicloud.io.clusteroutput: A cluster output defines which logging providers that logs can be sent to and is only effective when deployed in the namespace that the logging operator is in.
  logging.banzaicloud.io.flow: A flow defines which logs to collect and filter as well as which output to send the logs. The flow is a namespaced resource, which means logs will only be collected from the namespace that the flow is deployed in.
  logging.banzaicloud.io.output: An output defines which logging providers that logs can be sent to. The output needs to be in the same namespace as the flow that is using it.
  group.principal: Assigning global roles to a group only works with external auth providers that support groups. Local authorization does not support groups.

typeLabel:
  management.cattle.io.token: |-
    {count, plural,
      one { API Key }
      other { API Keys }
    }
  cis.cattle.io.clusterscan: |-
    {count, plural,
      one { Scan }
      other { Scans }
    }
  cis.cattle.io.clusterscanprofile: |-
    {count, plural,
      one { Profile }
      other { Profiles }
    }
  cis.cattle.io.clusterscanbenchmark: |-
    {count, plural,
      one { Benchmark Version }
      other { Benchmark Versions }
    }
  catalog.cattle.io.operation: |-
    {count, plural,
      one { Recent Operation }
      other { Recent Operations }
    }
  catalog.cattle.io.app: |-
    {count, plural,
      one { Installed App }
      other { Installed Apps }
    }
  catalog.cattle.io.clusterrepo: |-
    {count, plural,
      one { Repository }
      other { Repositories }
    }
  catalog.cattle.io.repo: |-
    {count, plural,
      one { Namespaced Repo }
      other { Namespaced Repos }
    }
  chartinstallaction: |-
    {count, plural,
      one { App }
      other { Apps }
    }
  chartupgradeaction: |-
    {count, plural,
      one { App }
      other { Apps }
    }
  cloudcredential: |-
    {count, plural,
      one { Cloud Credential }
      other { Cloud Credentials }
    }
  endpoints: |-
    {count, plural,
      one { Endpoint }
      other { Endpoints }
    }
  fleet.cattle.io.cluster: |-
    {count, plural,
      =1 { Cluster }
      other {Clusters }
    }
  fleet.cattle.io.clustergroup: |-
    {count, plural,
      one { Cluster Group }
      other {Cluster Groups }
    }
  fleet.cattle.io.gitrepo: |-
    {count, plural,
      one { Git Repo }
      other {Git Repos }
    }
  management.cattle.io.authconfig: |-
    {count, plural,
      one { Authentication Provider }
      other { Authentication Providers }
    }
  management.cattle.io.clusterroletemplatebinding: |-
    {count, plural,
      one { Cluster Member }
      other { Cluster Members }
    }
  management.cattle.io.feature: |-
    {count, plural,
      one { Feature Flag }
      other { Feature Flags }
    }
  management.cattle.io.setting: |-
    {count, plural,
      one { Setting }
      other { Settings }
    }
  management.cattle.io.fleetworkspace: |-
    {count, plural,
      one { Workspace }
      other { Workspaces }
    }
  policy.poddisruptionbudget: |-
    {count, plural,
      one { Pod Disruption Budget }
      other { Pod Disruption Budgets }
    }
  limitrange: |-
    {count, plural,
      one { Limit Range }
      other { Limit Ranges }
    }
  resourcequota: |-
    {count, plural,
      one { Resource Quota }
      other { Resource Quotas }
    }
  # pruh-mee-thee-eyes https://www.prometheus.io/docs/introduction/faq/#what-is-the-plural-of-prometheus
  monitoring.coreos.com.prometheus: |-
    {count, plural,
      one { Prometheus }
      other { Prometheis }
    }
  helm.cattle.io.projecthelmchart: |-
    {count, plural,
      one { Project Monitor }
      other { Project Monitors }
    }
  monitoring.coreos.com.servicemonitor: |-
    {count, plural,
      one { Service Monitor }
      other { Service Monitors }
    }
  monitoring.coreos.com.alertmanager: |-
    {count, plural,
      one { Alertmanager }
      other { Alertmanagers }
    }
  monitoring.coreos.com.alertmanagerconfig: |-
    {count, plural,
      one { AlertmanagerConfigs }
      other { AlertmanagerConfigs }
    }
  monitoring.coreos.com.podmonitor: |-
    {count, plural,
      one { Pod Monitor }
      other { Pod Monitors }
    }
  monitoring.coreos.com.prometheusrule: |-
    {count, plural,
      one { PrometheusRule }
      other { PrometheusRules }
    }
  monitoring.coreos.com.thanosruler: |-
    {count, plural,
      one { Thanos Rule }
      other { Thanos Rules }
    }
  monitoring.coreos.com.receiver: |-
    {count, plural,
      one { Receiver }
      other { Receivers }
    }
  monitoring.coreos.com.route: |-
    {count, plural,
      one { Route }
      other { Routes }
    }
  'management.cattle.io.cluster': |-
    {count, plural,
      one { Mgmt Cluster }
      other { Mgmt Clusters }
    }
  'cluster.x-k8s.io.cluster': |-
    {count, plural,
      one { CAPI Cluster }
      other { CAPI Clusters }
    }
  'provisioning.cattle.io.cluster': |-
    {count, plural,
      one { Cluster }
      other { Clusters }
    }
  management.cattle.io.user: |-
    {count, plural,
      one { User }
      other { Users}
    }
  namespace: |-
    {count, plural,
      one { Namespace }
      other { Namespaces }
    }
  node: |-
    {count, plural,
      one { Node }
      other { Nodes }
    }
  event: |-
    {count, plural,
      one { Event }
      other { Events }
    }
  apps.deployment: |-
    {count, plural,
      one { Deployment }
      other { Deployments }
    }
  batch.cronjob: |-
    {count, plural,
      one { CronJob }
      other { CronJobs }
    }
  apps.daemonset: |-
    {count, plural,
      one { DaemonSet }
      other { DaemonSets }
    }
  batch.job: |-
    {count, plural,
      one { Job }
      other { Jobs }
    }
  apps.statefulset: |-
    {count, plural,
      one { StatefulSet }
      other { StatefulSets }
    }
  pod: |-
    {count, plural,
      one { Pod }
      other { Pods }
    }
  autoscaling.horizontalpodautoscaler: |-
    {count, plural,
      one { HorizontalPodAutoscaler }
      other { HorizontalPodAutoscalers }
    }
  networking.k8s.io.ingress: |-
    {count, plural,
      one { Ingress }
      other { Ingresses }
    }
  networking.k8s.io.networkpolicy: |-
    {count, plural,
      one { Network Policies }
      other { Network Policies }
    }
  service: |-
    {count, plural,
      one { Service }
      other { Services }
    }
  persistentvolume: |-
    {count, plural,
      one { PersistentVolume }
      other { PersistentVolumes }
    }
  storage.k8s.io.storageclass: |-
    {count, plural,
      one { StorageClass }
      other { StorageClasses }
    }
  configmap: |-
    {count, plural,
      one { ConfigMap }
      other { ConfigMaps }
    }
  persistentvolumeclaim: |-
    {count, plural,
      one { PersistentVolumeClaim }
      other { PersistentVolumeClaims }
    }
  secret: |-
    {count, plural,
      one { Secret }
      other { Secrets }
    }
  apiregistration.k8s.io.apiservice: |-
    {count, plural,
      one { APIService }
      other { APIServices }
    }
  apiextensions.k8s.io.customresourcedefinition: |-
    {count, plural,
      one { CustomResourceDefinition }
      other { CustomResourceDefinitions }
    }
  flowcontrol.apiserver.k8s.io.flowschema: |-
    {count, plural,
      one { FlowSchema }
      other { FlowSchemas }
    }
  flowcontrol.apiserver.k8s.io.prioritylevelconfiguration: |-
    {count, plural,
      one { PriorityLevelConfiguration }
      other { PriorityLevelConfigurations }
    }
  apps.replicaset: |-
    {count, plural,
      one { ReplicaSet }
      other { ReplicaSets }
    }
  coordination.k8s.io.lease: |-
    {count, plural,
      one { Lease }
      other { Leases }
    }
  serviceaccount: |-
    {count, plural,
      one { ServiceAccount }
      other { ServiceAccounts }
    }
  discovery.k8s.io.endpointslice: |-
    {count, plural,
      one { EndpointSlice }
      other { EndpointSlices }
    }
  admissionregistration.k8s.io.mutatingwebhookconfiguration: |-
    {count, plural,
      one { MutatingWebhookConfiguration }
      other { MutatingWebhookConfigurations }
    }
  admissionregistration.k8s.io.validatingwebhookconfiguration: |-
    {count, plural,
      one { ValidatingWebhookConfiguration }
      other { ValidatingWebhookConfigurations }
    }
  group.principal: |-
    {count, plural,
      one { Group }
      other { Groups }
    }
  token: |-
    {count, plural,
      one { API Key }
      other { API Keys }
    }
  workload: |-
    {count, plural,
      one { Workload }
      other { Workloads }
    }
  harvesterhci.io.management.cluster: |-
    {count, plural,
      one { Harvester Cluster }
      other { Harvester Clusters }
    }
  harvesterhci.io.cloudtemplate: |-
    {count, plural,
      one { Cloud Config Template }
      other { Cloud Config Templates }
    }
  fleet.cattle.io.content: |-
    {count, plural,
      one { Content }
      other { Contents }
    }
  fleet.cattle.io.bundle: |-
    {count, plural,
      one { Bundle }
      other { Bundles }
    }
  fleet.cattle.io.bundledeployment: |-
    {count, plural,
      one { ClusterRegistration }
      other { ClusterRegistrations }
    }
  k3s.cattle.io.addon: |-
    {count, plural,
      one { Addon }
      other { Addons }
    }
  management.cattle.io.apiservice: |-
    {count, plural,
      one { APIService }
      other { APIServices }
    }
  management.cattle.io.catalog: |-
    {count, plural,
      one { APIService }
      other { APIServices }
    }
  fleet.cattle.io.clusterregistration: |-
    {count, plural,
      one { Catalog }
      other { Catalogs }
    }
  management.cattle.io.dynamicschema: |-
    {count, plural,
      one { DynamicSchema }
      other { DynamicSchemas }
    }
  management.cattle.io.globalrolebinding: |-
    {count, plural,
      one { GlobalRoleBinding }
      other { GlobalRoleBindings }
    }
  management.cattle.io.kontainerdriver: |-
    {count, plural,
      one { KontainerDriver }
      other { KontainerDrivers }
    }
  management.cattle.io.nodedriver: |-
    {count, plural,
      one { NodeDriver }
      other { NodeDrivers }
    }
  management.cattle.io.podsecuritypolicytemplate: |-
    {count, plural,
      one { PodSecurityPolicyTemplate }
      other { PodSecurityPolicyTemplates }
    }
  management.cattle.io.userattribute: |-
    {count, plural,
      one { UserAttribute }
      other { UserAttributes }
    }
  management.cattle.io.catalogtemplate: |-
    {count, plural,
      one { CatalogTemplate }
      other { CatalogTemplates }
    }
  management.cattle.io.catalogtemplateversion: |-
    {count, plural,
      one { CatalogTemplateVersion }
      other { CatalogTemplateVersions }
    }
  management.cattle.io.cisbenchmarkversion: |-
    {count, plural,
      one { CisBenchmarkVersion }
      other { CisBenchmarkVersions }
    }
  management.cattle.io.cisconfig: |-
    {count, plural,
      one { CisConfig }
      other { CisConfigs }
    }
  management.cattle.io.clusteralertgroup: |-
    {count, plural,
      one { ClusterAlertGroup }
      other { ClusterAlertGroups }
    }
  management.cattle.io.clusteralertrule: |-
    {count, plural,
      one { ClusterAlertRule }
      other { ClusterAlertRules }
    }
  management.cattle.io.clusterregistrationtoken: |-
    {count, plural,
      one { ClusterRegistrationTokens }
      other { ClusterRegistrationTokens }
    }
  management.cattle.io.node: |-
    {count, plural,
      one { Node }
      other { Nodes }
    }
  management.cattle.io.projectalertgroup: |-
    {count, plural,
      one { ProjectAlertGroup }
      other { ProjectAlertGroups }
    }
  management.cattle.io.projectalertrule: |-
    {count, plural,
      one { ProjectAlertRule }
      other { ProjectAlertRules }
    }
  management.cattle.io.rkeaddon: |-
    {count, plural,
      one { RkeAddon }
      other { RkeAddons }
    }
  management.cattle.io.rkek8sserviceoption: |-
    {count, plural,
      one { RkeK8sServiceOption }
      other { RkeK8sServiceOptions }
    }
  management.cattle.io.rkek8ssystemimage: |-
    {count, plural,
      one { RkeK8sSystemImage }
      other { RkeK8sSystemImages }
    }
  rbac.authorization.k8s.io.clusterrolebinding: |-
    {count, plural,
      one { ClusterRoleBinding }
      other { ClusterRoleBindings }
    }
  rbac.authorization.k8s.io.clusterrole: |-
    {count, plural,
      one { ClusterRole }
      other { ClusterRoles }
    }
  rbac.authorization.k8s.io.rolebinding: |-
    {count, plural,
      one { RoleBinding }
      other { RoleBindings }
    }
  rbac.authorization.k8s.io.role: |-
    {count, plural,
      one { Role }
      other { Roles }
    }
  scheduling.k8s.io.priorityclass: |-
    {count, plural,
      one { PriorityClasse }
      other { PriorityClasses }
    }
  storage.k8s.io.csinode: |-
    {count, plural,
      one { CSINode }
      other { CSINodes }
    }
  cluster.x-k8s.io.machinedeployment: |-
    {count, plural,
      one { MachineDeployment }
      other { MachineDeployments }
    }
  cluster.x-k8s.io.machineset: |-
    {count, plural,
      one { MachineSet }
      other { MachineSets }
    }
  cluster.x-k8s.io.machine: |-
    {count, plural,
      one { Machine }
      other { Machines }
    }
  fleet.cattle.io.clusterregistrationtoken: |-
    {count, plural,
      one { Cluster Registration Token }
      other { Cluster Registration Tokens }
    } 

action:
  clone: Clone
  disable: Disable
  download: Download YAML
  edit: Edit Config
  editYaml: Edit YAML
  enable: Enable
  openLogs: View Logs
  refresh: Refresh
  remove: Delete
  view: View Config
  viewInApi: View in API
  viewYaml: View YAML
  activate: Activate
  deactivate: Deactivate
  show: Show
  hide: Hide
  copy: Copy
  unassign: 'Unassign'
  uninstall: Uninstall
  redeploy: Redeploy
  addSidecar: Add Sidecar
  rollback: Rollback
  openShell: Execute Shell
  runNow: Run Now
  suspend: Suspend
  resume: Resume

unit:
  sec: secs
  min: mins
  hour: |-
    {count, plural,
      one { hour }
      other { hours }
    }
  day: |-
    {count, plural,
      one { day }
      other { days }
    }
workloadPorts:
  addPort: Add Port
  remove: Remove
  addHost: Add Host

podAffinity:
  addLabel: Add Pod Selector

keyValue:
  keyPlaceholder: e.g. foo
  valuePlaceholder: e.g. bar
  protip: 'Paste lines of <em>key=value</em> or <em>key: value</em> into any key field for easy bulk entry'

registryMirror:
  header: Mirrors
  toolTip: 'Mirrors can be used to redirect requests for images from one registry to come from a list of endpoints you specify instead.  For example docker.io could redirect to your internal registry instead of ever going to DockerHub.'
  addLabel: Add Mirror
  description: Mirrors define the names and endpoints for private registries. The endpoints are tried one by one, and the first working one is used.

registryConfig:
  header: Registry Authentication
  toolTip: 'When an image needs to be pulled from the given registry hostname, this information will be used to verify the identity of the registry and authenticate to it.'
  addLabel: Add Registry
  description: "Define the TLS and credential configuration for each registry hostname and mirror."

##############################
### Advanced Settings
##############################

advancedSettings:
  label: Settings
  subtext: Typical users will not need to change these. Proceed with caution, incorrect values can break your {appName} installation. Settings which have been customized from default settings are tagged 'Modified'.
  show: Show
  hide: Hide
  none: None
  modified: Modified
  edit:
    label: Edit Setting
    changeSetting: "Change Setting:"
    trueOption: "True"
    falseOption: "False"
    value: Value
    useDefault: Use the default value
    invalidJSON: Invalid JSON - please check and correct your input before saving
  descriptions:
    'cacerts': "CA Certificates needed to verify the server's certificate."
    'password-min-length': 'Define minimum characters required for an user password.'
    'cluster-defaults': 'Override RKE Defaults when creating new clusters.'
    'engine-install-url': 'Default Docker engine installation URL (for most node drivers).'
    'engine-iso-url': 'Default OS installation URL (for vSphere driver).'
    'engine-newest-version': 'The newest supported version of Docker at the time of this release.  A Docker version that does not satisfy supported docker range but is newer than this will be marked as untested.'
    'engine-supported-range': 'Semver range for supported Docker engine versions.  Versions which do not satisfy this range will be marked unsupported in the UI.'
    'ingress-ip-domain': 'Wildcard DNS domain to use for automatically generated Ingress hostnames. <ingress-name>.<namespace-name>.<ip address of ingress controller> will be added to the domain.'
    'server-url': 'Default {appName} install url. Must be HTTPS. All nodes in your cluster must be able to reach this.'
    'system-default-registry': 'Private registry to be used for all Rancher System Container Images. If no value is specified, the default registry for the container runtime is used. For Docker and containerd, the default is `docker.io`.'
    'ui-index': 'HTML index location for the Cluster Manager UI.'
    'ui-dashboard-index': 'HTML index location for the {appName} UI.'
    'ui-offline-preferred': 'Controls whether UI assets are served locally by the server container or from the remote URL defined in the ui-index and ui-dashboard-index settings. The `Dynamic` option will use local assets in production builds of {appName}.'
    'ui-pl': 'Private-Label company name.'
    'telemetry-opt': 'Telemetry reporting opt-in.'
    'auth-user-info-max-age-seconds': 'The maximum age of a users auth tokens before an auth provider group membership sync will be performed.'
    'auth-user-info-resync-cron': 'Default cron schedule for resyncing auth provider group memberships.'
    'cluster-template-enforcement': 'Non-admins will be restricted to launching clusters via preapproved RKE Templates only.'
    'auth-user-session-ttl-minutes': 'Custom TTL (in minutes) on a user auth session.'
    'auth-token-max-ttl-minutes': 'Max TTL (in minutes) for all authentication tokens. When set to 0, the token never expires.'
    'kubeconfig-generate-token': 'Automatically generate tokens for users when a kubeconfig is requested.'
    'kubeconfig-token-ttl-minutes': 'TTL used for tokens generated via the CLI. Deprecated: This setting will be removed, and kubeconfig-default-token-ttl-minutes will be used for all kubeconfig tokens.'
    'kubeconfig-default-token-ttl-minutes': 'TTL (in minutes) applied on all kubeconfig tokens. When set to 0, the token never expires.'
    'rke-metadata-config': 'Configure RKE metadata refresh parameters.'
    'ui-banners': 'Classification banner is used to display a custom fixed banner in the header, footer, or both.'
    'custom-notifications': Edit custom notifications
    'ui-consent-banner': 'Banner is used to display a custom consent banner presented to users during login.'
    'ui-default-landing': 'The default page users land on after login.'
    'brand': Folder name for an alternative theme defined in '/assets/brand'
    'hide-local-cluster': Hide the local cluster
  editHelp:
    'ui-banners': This setting takes a JSON object containing 3 root parameters; <code>banner</code>, <code>showHeader</code>, <code>showFooter</code>. <code>banner</code> is an object containing; <code>textColor</code>, <code>background</code>, and <code>text</code>, where <code>textColor</code> and <code>background</code> are any valid CSS color value.
  enum:
    'ui-default-landing':
      ember: Cluster Manager
      vue: Cluster Explorer
    'telemetry-opt':
      prompt: Prompt
      in: Opt-in to Telemetry
      out: Opt-out of Telemetry
    'ui-offline-preferred':
      dynamic: Dynamic
      true: Local
      false: Remote
    'harv-ui-source':
      auto: 'Auto'
      bundled: 'Bundled'
      external: 'External'
    'harv-log-level':
      info: Info
      debug: Debug
      trace: Trace

featureFlags:
  label: Feature Flags
  warning: |-
    Feature flags allow {vendor} to gate certain features behind flags.
    Features that are off by default should be considered experimental functionality.
    Some features require a restart of the {vendor} server to change.
    This will result in a short outage of the API and UI, but not affect running clusters or workloads.
  promptActivate: Please confirm that you want to activate the feature flag "{flag}"
  promptDeactivate: Please confirm that you want to deactivate the feature flag "{flag}"
  restartRequired: "Note: Updating this feature flag requires a restart"
  restart:
    title: Waiting for Restart
    wait: This may take a few moments

performance:
  label: UI Performance Settings
  settingName: Performance
  experimental: This setting is experimental and may be removed or updated in future versions.
  incrementalLoad:
    label: Incremental Loading
    setting: You can configure the threshold above which incremental loading will be used.
    description: |-
      When enabled, resources will appear more quickly, but it may take slightly longer to load the entire set of resources. This setting only applies to resources that come from the Kubernetes API
    checkboxLabel: Enable incremental loading
    inputLabel: Resource Threshold
  manualRefresh:
    label: Manual Refresh
    setting: You can configure a threshold above which manual refresh will be enabled.
    buttonTooltip: Refresh list
    description: |-
      When enabled, list data will not auto-update but instead the user must manually trigger a list-view refresh. This setting only applies to resources that come from the Kubernetes API
    checkboxLabel: Enable manual refresh of data for lists
    inputLabel: Resource Threshold
  websocketNotification:
    label: Websocket Notifications
    description: |-
      When checked, websocket notifications will not appear when the UI detects a disconnection.
    checkboxLabel: Disable websocket notifications
  gc:
    label: Resource Garbage Collection
    description: The UI will cache kuberentes resources locally to avoid having to re-fetch them. In some cases this can lead to a large amount of data stored in the browser. Enable this setting to periodically remove them.
    checkboxLabel: Enable Garbage Collection
    whenRun:
      description: Update when garbage collection runs
      intervalCheckBox:
        label: Run garbage collection periodically
      interval:
        inputLabel: Run every
      route:
        description: Run garbage collection on page change
        inputLabel: Page Change
    howRun:
      description: Update how garbage collection runs
      age:
        description: "Resource types musn't have been accessed within this period to be considered for garbage collection."
        inputLabel: Resource Age
      count:
        description: Resource types must exceed this amount to be considered for garbage collection.
        inputLabel: Resource Count
  nsFiltering:
    label: Require Namespace Filtering
    description: When there are too many resources to show in a list, require the user to select a single namespace and only fetch resources from within it.
    checkboxLabel: Enable Required Namespace Filtering
    count:
      inputLabel: Resource Threshold
      description: The threshold above which filtering by a namespace is required

banner:
  label: Fixed Banners
  settingName: Banners
  headerBanner: Header Banner
  footerBanner: Footer Banner
  loginScreenBanner: Login Screen Banner
  text: Text
  buttonText: Accept Button Text
  textColor: Text Color
  background: Background Color
  showHeader: Show Banner in Header
  showFooter: Show Banner in Footer
  showConsent: Show Consent Banner on Login Screen
  showAsDialog:
    defaultButtonText: Accept
    label: Show Login Consent as a modal dialog
    tooltip: Show a modal dialog on the login screen that must be accepted by a user before they can login
  bannerAlignment:
    label: Text Alignment
    leftOption: Left
    centerOption: Center
    rightOption: Right
  bannerDecoration:
    label: Text Decoration
    bannerBold: Bold
    bannerItalic: Italic
    bannerUnderline: Underline
  bannerFontSize:
    label: 'Font Size'
  consent: Consent Banner
  consentFootnote: "Tip: Use \\n character for line break"

branding:
  label: Branding
  directoryName: Brand Asset Directory Name
  logos:
    label: Logo
    tip: 'Upload a logo to replace the Rancher logo in the top-level navigation header. Image height should be 21 pixels with a max width of 200 pixels. Max file size is 20KB. Accepted formats: JPEG, PNG, SVG.'
    lightPreview: Light Theme Preview
    darkPreview: Dark Theme Preview
    uploadLight: Upload Light Logo
    uploadDark: Upload Dark Logo
    useCustom: Use a Custom Logo
  favicon:
    label: Favicon
    tip: 'Upload an icon to replace the Rancher favicon in the browser tab. Max file size is 20KB'
    preview: Favicon Preview
    upload: Upload Favicon
    useCustom: Use a Custom Favicon
  options:
    default: Default Rancher Theme
    suse: SUSE Theme
    custom: Define a Custom Theme
  uiPL:
    label: Private Label
  color:
    label: Primary Color
    tip: You can override the primary color used throughout the UI with a custom color of your choice.
    useCustom: Use a Custom Color
  linkColor:
    label: Link Color
    tip: You can override the link color used throughout the UI with a custom color of your choice.
    useCustom: Use a Custom Link Color
    example: Link Example
notifications:
  header: Custom notifications
  menuLabel: 'Custom Notifications'
  loginError:
    header: Login Failed Banner
    showCheckboxLabel: Show custom login error
    messageLabel: Text to display
resourceQuota:
  label: Resource Quotas
  headers:
    limit: Limit
    namespaceDefaultLimit: Namespace Default Limit
    projectLimit: Project Limit
    projectResourceAvailability: Project Resource Availability
    resourceType: Resource Type
  helpText: Configure how much of the resources the namespace as a whole can consume.
  helpTextDetail: The amount of resources the namespace as a whole can consume.
  configMaps: Config Maps
  limitsCpu: CPU Limit
  limitsMemory: Memory Limit
  persistentVolumeClaims: Persistent Volume Claims
  pods: Pods
  replicationControllers: Replication Controllers
  requestsCpu: CPU Reservation
  requestsMemory: Memory Reservation
  requestsStorage: Storage Reservation
  secrets: Secrets
  services: Services
  servicesLoadBalancers: Services Load Balancers
  servicesNodePorts: Service Node Ports
  namespaceLimit:
    label: Namespace Limit
  projectLimit:
    label: Project Limit
    cpuPlaceholder: e.g. 2000
    memoryPlaceholder: e.g. 2048
    storagePlaceholder: e.g. 50
    unitlessPlaceholder: e.g. 50
  namespaceDefaultLimit:
    label: Namespace Default Limit
    cpuPlaceholder: e.g. 500
    memoryPlaceholder: e.g. 1024
    storagePlaceholder: e.g. 10
    unitlessPlaceholder: e.g. 10
  add:
    label: Add Resource
  tooltip:
    reserved: 'Other Namespaces:'
    namespace: 'This Namespace:'
    available: 'Available:'
    max: 'Total:'
customLinks:
  displayTitle: Links
  label: Home Links
  description: 'Configure the links to display on the home page. You can define your own custom links as well as show or hide default links.'
  restoreDefaults: 'Restore Defaults'
  addLink: Add Link
  restoreSuccess: Default URLs have been restored.
  settings:
    default: Default Links
    custom: Custom Links
    keyLabel: Display Text
    valueLabel: URL
    showLabel: Show
  defaults:
    docs:       Docs
    forums:     Forums
    slack:      Slack
    issues:     File an Issue
    getStarted: Get Started
    commercialSupport: Commercial Support



##############################
### Support Page
##############################

support:
  community:
    title: SUSE Rancher provides world-class support
    linksTitle: Community Support
    learnMore: Find out more about SUSE Rancher Support
    pricing: Contact us for pricing
  subscription:
    haveSupport: Already have support?
    addSubscription: Add a Subscription ID
    removeSubscription: Remove your Subscription ID
    addTitle: Add your SUSE Subscription ID
    addLabel: "Please enter a valid Subscription ID:"
    removeTitle: Remove your ID?
    removeBody: "Note: This will not affect your subscription."

  suse:
    title: "Great News - You're covered"
    editBrand: Customize UI Theme
    access:
      title: Get Support
      text: Login to SUSE Customer Center to access support for your subscription
      action: SUSE Customer Center
      aws:
        generateConfig: Generate Support Config
        text: 'Login to SUSE Customer Center to access support for your subscription. Need to open a new support case? Download a support config file below.'
  promos:
    one:
      title: 24x7 Support
      text: We provide tightly defined SLAs, and offer round the clock support options.
    two:
      title: Issue Resolution
      text: Run SUSE Rancher products with confidence, knowing that the developers who built them are available to quickly resolve issues.
    three:
      title: Troubleshooting
      text: We focus on uncovering the root cause of any issue, whether it is related to Rancher Labs products, Kubernetes, Docker or your underlying infrastructure.
    four:
      title: Innovate with Freedom
      text: Take advantage of our certified compatibility with a wide range of Kubernetes providers, operating systems, and open source software.

embedding:
  retry: Retry
  unavailable: Cluster Manager UI is not available

v1ClusterTools:
  monitoring:
    label: Monitoring (Legacy)
    description: 'Legacy V1 monitoring. V1 Monitoring is deprecated since Rancher 2.5.0. <a target="blank" href="https://ranchermanager.docs.rancher.com/v2.6/how-to-guides/advanced-user-guides/monitoring-alerting-guides/migrate-to-rancher-v2.5+-monitoring#migrating-from-monitoring-v1-to-monitoring-v2">Learn more</a> about the migration steps to V2 Monitoring.'
  logging:
    label: Logging (Legacy)
    description: 'Legacy V1 logging. V1 Logging is deprecated since Rancher 2.5.0. <a target="blank" href="https://ranchermanager.docs.rancher.com/v2.6/integrations-in-rancher/logging/migrate-to-rancher-v2.5+-logging">Learn more</a> about migrating to V2 Logging.'
  istio:
    label: Istio (Legacy)
    description: 'Legacy V1 Istio. Istio v1.5 has been deprecated since Rancher 2.5.0. <a target="blank" href="https://ranchermanager.docs.rancher.com/v2.6/pages-for-subheaders/istio#migrate-from-previous-istio-version">Learn more</a> about migrating to the latest version.'

legacy:
  alerts: Alerts
  apps: Apps
  catalogs: Catalogs
  configMaps: Config Maps
  configuration: Configuration
  globalDnsEntries: Global DNS Entries
  globalDnsProviders: Global DNS Providers
  notifiers: Notifiers
  monitoring: Monitoring
  psps: Pod Security Policies
  secrets: Secrets

  project:
    label: Project
    select: "Use the Project/Namespace filter at the top of the page to select a Project in order to see legacy Project features."

serverUpgrade:
  title: "{vendor} Server Changed"
  message: "The page reloaded because the version of {vendor} running on your server changed."

volumeClaimTemplate:
  add:
    label: Add Claim Template

manager:
  cloudCredentials:
    label: Cloud Credentials
  drivers:
    label: Drivers
  rkeTemplates:
    label: RKE Templates
  nodeTemplates:
    label: Node Templates

auth:
  config:
    label: Auth Provider
vncConsole:
  error:
    message: Web VNC console connection is disconnected
